2021-02-25 00:00:02 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: wos_crawl)
2021-02-25 00:00:02 [scrapy.utils.log] INFO: Versions: lxml 4.6.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.6.9 (default, Oct  8 2020, 12:12:24) - [GCC 8.4.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1i  8 Dec 2020), cryptography 3.3.1, Platform Linux-4.15.0-132-generic-x86_64-with-Ubuntu-18.04-bionic
2021-02-25 00:00:02 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2021-02-25 00:00:02 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wos_crawl',
 'COOKIES_ENABLED': False,
 'DOWNLOAD_DELAY': 5,
 'LOG_FILE': 'crawler.log',
 'NEWSPIDER_MODULE': 'wos_crawl.spiders',
 'RETRY_HTTP_CODES': [500, 503, 504, 400, 403, 404, 408],
 'RETRY_TIMES': 3,
 'SPIDER_MODULES': ['wos_crawl.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/88.0.4324.104 Safari/537.36'}
2021-02-25 00:00:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2021-02-25 00:00:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-02-25 00:00:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-02-25 00:00:02 [py.warnings] WARNING: /home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/pipelines/media.py:135: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2021-02-25 00:00:02 [scrapy.middleware] INFO: Enabled item pipelines:
['wos_crawl.pipelines.fileDown']
2021-02-25 00:00:02 [scrapy.core.engine] INFO: Spider opened
2021-02-25 00:00:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 00:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 00:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 00:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 00:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 149
2021-02-25 00:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 00:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 00:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 00:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 144
2021-02-25 00:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 00:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 00:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 00:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 00:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 00:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 00:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 00:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 00:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 00:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 00:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 00:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 144
2021-02-25 00:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 00:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 00:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 00:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 149
2021-02-25 00:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 00:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 00:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 00:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 00:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 00:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 00:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 00:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 149
2021-02-25 00:00:08 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v16/n2/p131-141/> from <GET https://www.sci-hub.ren/10.3354/ame016131>
2021-02-25 00:00:16 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595> from <GET https://www.sci-hub.ren/10.2113/96.7.1595>
2021-02-25 00:00:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.5327/Z2317-48892013000300004> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-02-25 00:00:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/ame021161> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 00:00:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> from <GET https://www.sci-hub.ren/10.1360/02yd0178>
2021-02-25 00:00:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.3354/meps07087> (referer: None)
2021-02-25 00:00:48 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 00:00:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 00:00:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.2485/jhtb.20.339> (referer: None)
2021-02-25 00:00:50 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 00:00:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 00:00:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/ame048123> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 00:00:55 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> from <GET https://www.sci-hub.ren/10.1344/105.000001770>
2021-02-25 00:00:56 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf> from <GET https://www.sci-hub.ren/10.1344/105.000002051>
2021-02-25 00:01:02 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 00:01:10 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page> from <GET https://www.sci-hub.ren/10.5139/IJASS.2014.15.4.419>
2021-02-25 00:01:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.7306/gq.1131> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 00:01:26 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-319-24987-2%5C_6>
2021-02-25 00:01:28 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-319-24987-2%5C_26>
2021-02-25 00:01:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1007/978-3-319-04364-7%5C_131> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 00:01:34 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.5209/rev%5C_JIGE.2015.v41.n3.51568>
2021-02-25 00:01:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v16/n2/p131-141/> (referer: None)
2021-02-25 00:01:36 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 00:01:36 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 149
2021-02-25 00:01:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595> (failed 1 times): 403 Forbidden
2021-02-25 00:01:48 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf> from <GET https://www.sci-hub.ren/10.5327/Z2317-48892013000300004>
2021-02-25 00:01:53 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> from <GET https://www.sci-hub.ren/10.3354/ame021161>
2021-02-25 00:01:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> from <GET http://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm>
2021-02-25 00:02:02 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 00:02:14 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://paleoitalia.org> from <GET https://www.sci-hub.ren/10.4435/BSPI.2016.09>
2021-02-25 00:02:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> from <GET https://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770>
2021-02-25 00:02:34 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html> from <GET https://www.sci-hub.ren/10.3391/ai.2016.11.3.04>
2021-02-25 00:02:35 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page> from <GET http://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page>
2021-02-25 00:02:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf> (failed 1 times): Could not open CONNECT tunnel with proxy 59.36.10.52:3128 [{'status': 500, 'reason': b'Internal Server Error'}]
2021-02-25 00:02:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/ame048123> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 00:02:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-25 00:02:46 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 00:02:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 00:02:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-25 00:02:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 00:02:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 00:03:02 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 00:03:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.7306/gq.1131> (referer: None)
2021-02-25 00:03:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 00:03:05 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 00:03:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595> (failed 2 times): 403 Forbidden
2021-02-25 00:03:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1007/978-3-319-04364-7%5C_131> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 00:03:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.14241/asgp.2016.011> (referer: None)
2021-02-25 00:03:21 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 00:03:21 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 00:03:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-25 00:03:22 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 00:03:22 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 00:03:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://bjg.siteoficial.ws/2013/n.3/d.pdf> from <GET https://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf>
2021-02-25 00:03:35 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://paleoitalia.org> from <GET http://www.sci-hub.ren/http://paleoitalia.org>
2021-02-25 00:03:38 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> from <GET https://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm>
2021-02-25 00:03:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 00:03:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> (referer: None)
2021-02-25 00:03:48 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 00:03:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 149
2021-02-25 00:03:59 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.aquaticinvasions.net/2016/issue3.html> from <GET https://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html>
2021-02-25 00:04:02 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 00:04:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page> (referer: None)
2021-02-25 00:04:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 00:04:08 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 149
2021-02-25 00:04:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-02-25 00:04:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.1055/s-0036-1596638> (referer: None)
2021-02-25 00:04:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 00:04:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 149
2021-02-25 00:04:23 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/> from <GET https://www.sci-hub.ren/10.3354/meps12300>
2021-02-25 00:04:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/ame048123> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 00:04:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359> from <GET https://www.sci-hub.ren/10.3389/fmicb.2013.01359>
2021-02-25 00:04:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595> (failed 3 times): 403 Forbidden
2021-02-25 00:04:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://paleopolis.rediris.es/cg/18/08/index.html> from <GET https://www.sci-hub.ren/10.4267/2042/68182>
2021-02-25 00:04:52 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-319-04364-7%5C_131>
2021-02-25 00:05:02 [scrapy.extensions.logstats] INFO: Crawled 11 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 00:05:11 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://paleoitalia.org/> from <GET https://www.sci-hub.ren/http://paleoitalia.org>
2021-02-25 00:05:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/meps12741> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 00:05:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 1 times): 404 Not Found
2021-02-25 00:05:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://bjg.siteoficial.ws/2013/n.3/d.pdf> (referer: None)
2021-02-25 00:05:18 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 00:05:18 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 00:05:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://bjg.siteoficial.ws/2013/n.3/d.pdf> (referer: None)
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/python.py", line 353, in __next__
    return next(self.data)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/python.py", line 353, in __next__
    return next(self.data)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/wos_crawl/wos_crawl/spiders/wos_spider.py", line 39, in parse
    detail_url_list = response.xpath('//*[@id="buttons"]/ul/li[2]/a/@onclick')
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/http/response/__init__.py", line 120, in xpath
    raise NotSupported("Response content isn't text")
scrapy.exceptions.NotSupported: Response content isn't text
2021-02-25 00:05:22 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> from <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/>
2021-02-25 00:05:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.4072/rbp.2018.3.01> (referer: None)
2021-02-25 00:05:43 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 00:05:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 00:05:51 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html> from <GET https://www.sci-hub.ren/10.1051/bsgf/2018019>
2021-02-25 00:05:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.aquaticinvasions.net/2016/issue3.html> (referer: None)
2021-02-25 00:05:54 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 00:05:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 00:05:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.5027/andgeoV46n1-3029> (referer: None)
2021-02-25 00:05:55 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 00:05:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 144
2021-02-25 00:05:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/> (failed 1 times): 403 Forbidden
2021-02-25 00:06:02 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 00:06:09 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359> from <GET http://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359>
2021-02-25 00:06:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595> (failed 4 times): 403 Forbidden
2021-02-25 00:06:15 [scrapy.core.engine] DEBUG: Crawled (403) <GET http://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595> (referer: None)
2021-02-25 00:06:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 00:06:15 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 00:06:15 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 http://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595>: HTTP status code is not handled or not allowed
2021-02-25 00:06:17 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/> from <GET https://www.sci-hub.ren/10.3354/ame048123>
2021-02-25 00:06:19 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://paleopolis.rediris.es/cg/18/08/index.html> from <GET http://www.sci-hub.ren/http://paleopolis.rediris.es/cg/18/08/index.html>
2021-02-25 00:06:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://paleoitalia.org/> (referer: None)
2021-02-25 00:06:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 00:06:33 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 00:06:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 2 times): 404 Not Found
2021-02-25 00:06:47 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/> from <GET http://www.sci-hub.ren/>
2021-02-25 00:06:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/meps12741> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 00:07:01 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://www.int-res.com/abstracts/ame/v82/n3/p253-264/> from <GET https://www.sci-hub.ren/10.3354/ame01895>
2021-02-25 00:07:02 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 00:07:14 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://doi.org/10.3390/min9100000> from <GET https://www.sci-hub.ren/10.3390/min9100000>
2021-02-25 00:07:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 00:07:26 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-030-21614-6%5C_12>
2021-02-25 00:07:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/> (failed 2 times): 403 Forbidden
2021-02-25 00:07:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.5027/andgeoV47n1-3177> (referer: None)
2021-02-25 00:07:34 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 00:07:34 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 00:07:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html> (referer: None)
2021-02-25 00:07:35 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 00:07:35 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 00:07:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359> (referer: None)
2021-02-25 00:07:40 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 00:07:40 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 00:07:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.1089/ast.2019.2067> (referer: None)
2021-02-25 00:07:45 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded file from <GET https://cyber.bban.top/MTAuMTA4OS9hc3QuMjAxOS4yMDY3/10.1089%40ast.2019.2067.pdf?download=true> referred in <None>
2021-02-25 00:07:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.sci-hub.ren/10.1089/ast.2019.2067>
{'file_urls': ['https://cyber.bban.top/MTAuMTA4OS9hc3QuMjAxOS4yMDY3/10.1089%40ast.2019.2067.pdf?download=true'],
 'files': [{'checksum': '808358d065f4915b2156f3de1d6a1a24',
            'path': '000582254100001.pdf',
            'status': 'uptodate',
            'url': 'https://cyber.bban.top/MTAuMTA4OS9hc3QuMjAxOS4yMDY3/10.1089%40ast.2019.2067.pdf?download=true'}],
 'name': '000582254100001'}
2021-02-25 00:08:00 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://paleopolis.rediris.es/cg/18/08/index.html> from <GET https://www.sci-hub.ren/http://paleopolis.rediris.es/cg/18/08/index.html>
2021-02-25 00:08:02 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 4 pages/min), scraped 1 items (at 1 items/min)
2021-02-25 00:08:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.1155/2020/6959532> (referer: None)
2021-02-25 00:08:03 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded file from <GET https://cyber.bban.top/MTAuMTE1NS8yMDIwLzY5NTk1MzI=/10.1155%402020%406959532.pdf?download=true> referred in <None>
2021-02-25 00:08:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.sci-hub.ren/10.1155/2020/6959532>
{'file_urls': ['https://cyber.bban.top/MTAuMTE1NS8yMDIwLzY5NTk1MzI=/10.1155%402020%406959532.pdf?download=true'],
 'files': [{'checksum': '6c02fcee70c30afc9791e2e93ddc95f4',
            'path': '000588326000002.pdf',
            'status': 'uptodate',
            'url': 'https://cyber.bban.top/MTAuMTE1NS8yMDIwLzY5NTk1MzI=/10.1155%402020%406959532.pdf?download=true'}],
 'name': '000588326000002'}
2021-02-25 00:08:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 3 times): 404 Not Found
2021-02-25 00:08:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 00:08:10 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-25 00:08:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 00:08:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf> (failed 3 times): User timeout caused connection failure: Getting https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf took longer than 180.0 seconds..
2021-02-25 00:08:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://doi.org/10.3390/min9100000> from <GET http://www.sci-hub.ren/https://doi.org/10.3390/min9100000>
2021-02-25 00:08:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-25 00:08:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://www.int-res.com/abstracts/ame/v82/n3/p253-264/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 00:08:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/> (failed 3 times): 403 Forbidden
2021-02-25 00:09:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 00:09:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-25 00:09:02 [scrapy.extensions.logstats] INFO: Crawled 23 pages (at 2 pages/min), scraped 2 items (at 1 items/min)
2021-02-25 00:09:03 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> from <GET https://www.sci-hub.ren/10.1111/1758-2229.12916>
2021-02-25 00:09:17 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429> from <GET https://www.sci-hub.ren/10.1111/gbi.12429>
2021-02-25 00:09:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.7306/gq.1547> (referer: None)
2021-02-25 00:09:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://paleopolis.rediris.es/cg/18/08/index.html> (referer: None)
2021-02-25 00:09:21 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 4 times): 404 Not Found
2021-02-25 00:09:21 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (referer: None)
2021-02-25 00:09:21 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.scichina.com/2004/yk/yd/0404/yd0347.stm>: HTTP status code is not handled or not allowed
2021-02-25 00:09:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf> (failed 4 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-02-25 00:09:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-02-25 00:09:49 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 00:09:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-25 00:09:52 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/> (failed 4 times): 403 Forbidden
2021-02-25 00:09:52 [scrapy.core.engine] DEBUG: Crawled (403) <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/> (referer: None)
2021-02-25 00:09:52 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 http://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/>: HTTP status code is not handled or not allowed
2021-02-25 00:09:55 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> from <GET http://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916>
2021-02-25 00:10:02 [scrapy.extensions.logstats] INFO: Crawled 27 pages (at 4 pages/min), scraped 2 items (at 0 items/min)
2021-02-25 00:10:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429> (referer: None)
2021-02-25 00:10:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://www.int-res.com/abstracts/ame/v82/n3/p253-264/> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 00:10:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> (referer: None)
2021-02-25 00:10:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://www.int-res.com/abstracts/ame/v82/n3/p253-264/> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 00:10:55 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://www.sci-hub.ren/https://www.int-res.com/abstracts/ame/v82/n3/p253-264/> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 00:10:56 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.sci-hub.ren/https://www.int-res.com/abstracts/ame/v82/n3/p253-264/>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-25 00:11:02 [scrapy.extensions.logstats] INFO: Crawled 29 pages (at 2 pages/min), scraped 2 items (at 0 items/min)
2021-02-25 00:11:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/meps12741> (failed 3 times): User timeout caused connection failure: Getting https://www.sci-hub.ren/10.3354/meps12741 took longer than 180.0 seconds..
2021-02-25 00:11:44 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/10.3354/meps12741> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 00:11:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/10.3354/meps12741>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-25 00:12:02 [scrapy.extensions.logstats] INFO: Crawled 29 pages (at 0 pages/min), scraped 2 items (at 0 items/min)
2021-02-25 00:12:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/https://doi.org/10.3390/min9100000> (failed 1 times): User timeout caused connection failure: Getting https://www.sci-hub.ren/https://doi.org/10.3390/min9100000 took longer than 180.0 seconds..
2021-02-25 00:12:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://doi.org/10.3390/min9100000> (referer: None)
2021-02-25 00:12:48 [scrapy.core.engine] INFO: Closing spider (finished)
2021-02-25 00:12:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 27,
 'downloader/exception_type_count/scrapy.core.downloader.handlers.http11.TunnelError': 1,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 20,
 'downloader/exception_type_count/twisted.internet.error.TimeoutError': 3,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 3,
 'downloader/request_bytes': 44006,
 'downloader/request_count': 105,
 'downloader/request_method_count/GET': 105,
 'downloader/response_bytes': 2387948,
 'downloader/response_count': 78,
 'downloader/response_status_count/200': 27,
 'downloader/response_status_count/301': 9,
 'downloader/response_status_count/302': 30,
 'downloader/response_status_count/403': 8,
 'downloader/response_status_count/404': 4,
 'elapsed_time_seconds': 765.748623,
 'file_count': 2,
 'file_status_count/uptodate': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 2, 24, 16, 12, 48, 67783),
 'httperror/response_ignored_count': 3,
 'httperror/response_ignored_status_count/403': 2,
 'httperror/response_ignored_status_count/404': 1,
 'item_scraped_count': 2,
 'log_count/DEBUG': 175,
 'log_count/ERROR': 16,
 'log_count/INFO': 23,
 'log_count/WARNING': 1,
 'memusage/max': 79495168,
 'memusage/startup': 68059136,
 'response_received_count': 30,
 'retry/count': 30,
 'retry/max_reached': 9,
 'retry/reason_count/403 Forbidden': 6,
 'retry/reason_count/404 Not Found': 3,
 'retry/reason_count/scrapy.core.downloader.handlers.http11.TunnelError': 1,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 15,
 'retry/reason_count/twisted.internet.error.TimeoutError': 3,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 2,
 'scheduler/dequeued': 105,
 'scheduler/dequeued/memory': 105,
 'scheduler/enqueued': 105,
 'scheduler/enqueued/memory': 105,
 'spider_exceptions/NotSupported': 1,
 'start_time': datetime.datetime(2021, 2, 24, 16, 0, 2, 319160)}
2021-02-25 00:12:48 [scrapy.core.engine] INFO: Spider closed (finished)
2021-02-25 04:00:01 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: wos_crawl)
2021-02-25 04:00:01 [scrapy.utils.log] INFO: Versions: lxml 4.6.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.6.9 (default, Oct  8 2020, 12:12:24) - [GCC 8.4.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1i  8 Dec 2020), cryptography 3.3.1, Platform Linux-4.15.0-132-generic-x86_64-with-Ubuntu-18.04-bionic
2021-02-25 04:00:01 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2021-02-25 04:00:01 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wos_crawl',
 'COOKIES_ENABLED': False,
 'DOWNLOAD_DELAY': 5,
 'LOG_FILE': 'crawler.log',
 'NEWSPIDER_MODULE': 'wos_crawl.spiders',
 'RETRY_HTTP_CODES': [500, 503, 504, 400, 403, 404, 408],
 'RETRY_TIMES': 3,
 'SPIDER_MODULES': ['wos_crawl.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/88.0.4324.104 Safari/537.36'}
2021-02-25 04:00:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2021-02-25 04:00:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-02-25 04:00:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-02-25 04:00:01 [py.warnings] WARNING: /home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/pipelines/media.py:135: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2021-02-25 04:00:01 [scrapy.middleware] INFO: Enabled item pipelines:
['wos_crawl.pipelines.fileDown']
2021-02-25 04:00:01 [scrapy.core.engine] INFO: Spider opened
2021-02-25 04:00:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 04:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 04:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 149
2021-02-25 04:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 04:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 149
2021-02-25 04:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 04:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 149
2021-02-25 04:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 04:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 04:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 04:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 04:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 04:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 04:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 04:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 04:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 04:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 04:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 04:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 04:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 04:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 04:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 04:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 04:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 04:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 04:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 04:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 04:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 04:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 04:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 04:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 149
2021-02-25 04:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 04:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 144
2021-02-25 04:00:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v16/n2/p131-141/> from <GET https://www.sci-hub.ren/10.3354/ame016131>
2021-02-25 04:00:09 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> from <GET https://www.sci-hub.ren/10.3354/ame021161>
2021-02-25 04:00:14 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595> from <GET https://www.sci-hub.ren/10.2113/96.7.1595>
2021-02-25 04:00:31 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf> from <GET https://www.sci-hub.ren/10.5327/Z2317-48892013000300004>
2021-02-25 04:00:31 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> from <GET https://www.sci-hub.ren/10.1360/02yd0178>
2021-02-25 04:00:35 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/> from <GET https://www.sci-hub.ren/10.3354/ame048123>
2021-02-25 04:00:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/meps07087> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-02-25 04:00:59 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> from <GET https://www.sci-hub.ren/10.1344/105.000001770>
2021-02-25 04:01:00 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf> from <GET https://www.sci-hub.ren/10.1344/105.000002051>
2021-02-25 04:01:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 04:01:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.2485/jhtb.20.339> (referer: None)
2021-02-25 04:01:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 04:01:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 04:01:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.7306/gq.1131> (referer: None)
2021-02-25 04:01:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 04:01:05 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 04:01:11 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page> from <GET https://www.sci-hub.ren/10.5139/IJASS.2014.15.4.419>
2021-02-25 04:01:18 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-319-04364-7%5C_131>
2021-02-25 04:01:24 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.5209/rev%5C_JIGE.2015.v41.n3.51568>
2021-02-25 04:01:30 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-319-24987-2%5C_6>
2021-02-25 04:01:39 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-319-24987-2%5C_26>
2021-02-25 04:01:41 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v16/n2/p131-141/> from <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v16/n2/p131-141/>
2021-02-25 04:01:47 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> from <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/>
2021-02-25 04:01:55 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595> from <GET http://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595>
2021-02-25 04:02:01 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 04:02:06 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://bjg.siteoficial.ws/2013/n.3/d.pdf> from <GET https://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf>
2021-02-25 04:02:12 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> from <GET http://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm>
2021-02-25 04:02:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/> (referer: None)
2021-02-25 04:02:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 04:02:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 04:02:22 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v349/p23-32/> from <GET https://www.sci-hub.ren/10.3354/meps07087>
2021-02-25 04:02:30 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> from <GET http://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770>
2021-02-25 04:02:34 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf> from <GET http://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf>
2021-02-25 04:02:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page> from <GET http://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page>
2021-02-25 04:02:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://paleoitalia.org> from <GET https://www.sci-hub.ren/10.4435/BSPI.2016.09>
2021-02-25 04:02:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-25 04:02:54 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 04:02:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 04:03:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3391/ai.2016.11.3.04> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 04:03:01 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/> from <GET http://www.sci-hub.ren/>
2021-02-25 04:03:01 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 04:03:07 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/> from <GET http://www.sci-hub.ren/>
2021-02-25 04:03:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v16/n2/p131-141/> (referer: None)
2021-02-25 04:03:21 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 04:03:21 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 04:03:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> (referer: None)
2021-02-25 04:03:30 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 04:03:30 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 04:03:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://economicgeology.org/lookup/doi/10.2113/96.7.1595> from <GET https://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595>
2021-02-25 04:03:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 04:03:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://bjg.siteoficial.ws/2013/n.3/d.pdf> (referer: None)
2021-02-25 04:03:42 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 04:03:42 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 149
2021-02-25 04:03:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://bjg.siteoficial.ws/2013/n.3/d.pdf> (referer: None)
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/python.py", line 353, in __next__
    return next(self.data)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/python.py", line 353, in __next__
    return next(self.data)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/wos_crawl/wos_crawl/spiders/wos_spider.py", line 39, in parse
    detail_url_list = response.xpath('//*[@id="buttons"]/ul/li[2]/a/@onclick')
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/http/response/__init__.py", line 120, in xpath
    raise NotSupported("Response content isn't text")
scrapy.exceptions.NotSupported: Response content isn't text
2021-02-25 04:03:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.14241/asgp.2016.011> (referer: None)
2021-02-25 04:03:49 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 04:03:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 04:03:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v349/p23-32/> (referer: None)
2021-02-25 04:03:56 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 04:03:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 04:04:00 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> from <GET https://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm>
2021-02-25 04:04:01 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 04:04:09 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> from <GET https://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770>
2021-02-25 04:04:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page> (referer: None)
2021-02-25 04:04:13 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 04:04:13 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 04:04:19 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.publicacions.ub.edu/doi/documents/2051.pdf> from <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf>
2021-02-25 04:04:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.1055/s-0036-1596638> (referer: None)
2021-02-25 04:04:27 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 04:04:27 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 04:04:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://paleoitalia.org> from <GET http://www.sci-hub.ren/http://paleoitalia.org>
2021-02-25 04:04:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-25 04:04:39 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 04:04:39 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 04:04:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-25 04:04:44 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 04:04:44 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 149
2021-02-25 04:04:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3391/ai.2016.11.3.04> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 04:04:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://economicgeology.org/lookup/doi/10.2113/96.7.1595> (failed 1 times): 404 Not Found
2021-02-25 04:05:01 [scrapy.extensions.logstats] INFO: Crawled 13 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 04:05:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/meps12300> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 04:05:13 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://paleopolis.rediris.es/cg/18/08/index.html> from <GET https://www.sci-hub.ren/10.4267/2042/68182>
2021-02-25 04:05:22 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/> from <GET https://www.sci-hub.ren/10.3354/meps12741>
2021-02-25 04:05:24 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359> from <GET https://www.sci-hub.ren/10.3389/fmicb.2013.01359>
2021-02-25 04:05:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 04:05:35 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> from <GET https://www.sci-hub.ren/10.4072/rbp.2018.3.01>
2021-02-25 04:05:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 1 times): 404 Not Found
2021-02-25 04:05:43 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html> from <GET https://www.sci-hub.ren/10.1051/bsgf/2018019>
2021-02-25 04:05:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> (referer: None)
2021-02-25 04:05:51 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 04:05:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 04:06:01 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 04:06:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.5027/andgeoV46n1-3029> (referer: None)
2021-02-25 04:06:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 04:06:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 04:06:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.publicacions.ub.edu/doi/documents/2051.pdf> (referer: None)
2021-02-25 04:06:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 04:06:05 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 04:06:05 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.publicacions.ub.edu/doi/documents/2051.pdf> (referer: None)
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/python.py", line 353, in __next__
    return next(self.data)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/python.py", line 353, in __next__
    return next(self.data)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/wos_crawl/wos_crawl/spiders/wos_spider.py", line 39, in parse
    detail_url_list = response.xpath('//*[@id="buttons"]/ul/li[2]/a/@onclick')
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/http/response/__init__.py", line 120, in xpath
    raise NotSupported("Response content isn't text")
scrapy.exceptions.NotSupported: Response content isn't text
2021-02-25 04:06:05 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://paleoitalia.org/> from <GET https://www.sci-hub.ren/http://paleoitalia.org>
2021-02-25 04:06:10 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/ame/v82/n3/p253-264/> from <GET https://www.sci-hub.ren/10.3354/ame01895>
2021-02-25 04:06:17 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://doi.org/10.3390/min9100000> from <GET https://www.sci-hub.ren/10.3390/min9100000>
2021-02-25 04:06:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://paleopolis.rediris.es/cg/18/08/index.html> from <GET http://www.sci-hub.ren/http://paleopolis.rediris.es/cg/18/08/index.html>
2021-02-25 04:06:41 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/> from <GET https://www.sci-hub.ren/10.3354/meps12300>
2021-02-25 04:06:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://economicgeology.org/lookup/doi/10.2113/96.7.1595> (failed 2 times): 404 Not Found
2021-02-25 04:06:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3391/ai.2016.11.3.04> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 04:06:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/> (referer: None)
2021-02-25 04:06:49 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 04:06:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 04:07:01 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 04:07:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-02-25 04:07:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 2 times): 404 Not Found
2021-02-25 04:07:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2021-02-25 04:07:16 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> from <GET https://www.sci-hub.ren/https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf>
2021-02-25 04:07:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html> (referer: None)
2021-02-25 04:07:31 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 04:07:31 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 04:07:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.1089/ast.2019.2067> (referer: None)
2021-02-25 04:07:32 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 04:07:32 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 04:07:32 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded file from <GET https://cyber.bban.top/MTAuMTA4OS9hc3QuMjAxOS4yMDY3/10.1089%40ast.2019.2067.pdf?download=true> referred in <None>
2021-02-25 04:07:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.sci-hub.ren/10.1089/ast.2019.2067>
{'file_urls': ['https://cyber.bban.top/MTAuMTA4OS9hc3QuMjAxOS4yMDY3/10.1089%40ast.2019.2067.pdf?download=true'],
 'files': [{'checksum': '808358d065f4915b2156f3de1d6a1a24',
            'path': '000582254100001.pdf',
            'status': 'uptodate',
            'url': 'https://cyber.bban.top/MTAuMTA4OS9hc3QuMjAxOS4yMDY3/10.1089%40ast.2019.2067.pdf?download=true'}],
 'name': '000582254100001'}
2021-02-25 04:07:33 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-030-21614-6%5C_12>
2021-02-25 04:07:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://paleoitalia.org/> (referer: None)
2021-02-25 04:07:41 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 04:07:41 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 04:07:51 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://doi.org/10.3390/min9100000> from <GET http://www.sci-hub.ren/https://doi.org/10.3390/min9100000>
2021-02-25 04:07:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/ame/v82/n3/p253-264/> (referer: None)
2021-02-25 04:08:01 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 4 pages/min), scraped 1 items (at 1 items/min)
2021-02-25 04:08:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://economicgeology.org/lookup/doi/10.2113/96.7.1595> (failed 3 times): 404 Not Found
2021-02-25 04:08:19 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://paleopolis.rediris.es/cg/18/08/index.html> from <GET https://www.sci-hub.ren/http://paleopolis.rediris.es/cg/18/08/index.html>
2021-02-25 04:08:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 04:08:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.1155/2020/6959532> (referer: None)
2021-02-25 04:08:27 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded file from <GET https://cyber.bban.top/MTAuMTE1NS8yMDIwLzY5NTk1MzI=/10.1155%402020%406959532.pdf?download=true> referred in <None>
2021-02-25 04:08:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.sci-hub.ren/10.1155/2020/6959532>
{'file_urls': ['https://cyber.bban.top/MTAuMTE1NS8yMDIwLzY5NTk1MzI=/10.1155%402020%406959532.pdf?download=true'],
 'files': [{'checksum': '6c02fcee70c30afc9791e2e93ddc95f4',
            'path': '000588326000002.pdf',
            'status': 'uptodate',
            'url': 'https://cyber.bban.top/MTAuMTE1NS8yMDIwLzY5NTk1MzI=/10.1155%402020%406959532.pdf?download=true'}],
 'name': '000588326000002'}
2021-02-25 04:08:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 3 times): 404 Not Found
2021-02-25 04:08:40 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/10.3391/ai.2016.11.3.04> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 04:08:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/10.3391/ai.2016.11.3.04>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-25 04:08:51 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359> from <GET http://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359>
2021-02-25 04:08:53 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://www.sci-hub.ren/> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 04:08:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.sci-hub.ren/>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-25 04:08:55 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> from <GET https://www.sci-hub.ren/10.1111/1758-2229.12916>
2021-02-25 04:09:01 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 1 pages/min), scraped 2 items (at 1 items/min)
2021-02-25 04:09:10 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429> from <GET https://www.sci-hub.ren/10.1111/gbi.12429>
2021-02-25 04:09:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.7306/gq.1547> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 04:09:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 04:09:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://economicgeology.org/lookup/doi/10.2113/96.7.1595> (failed 4 times): 404 Not Found
2021-02-25 04:09:25 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://economicgeology.org/lookup/doi/10.2113/96.7.1595> (referer: None)
2021-02-25 04:09:25 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://economicgeology.org/lookup/doi/10.2113/96.7.1595>: HTTP status code is not handled or not allowed
2021-02-25 04:09:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://doi.org/10.3390/min9100000> (referer: None)
2021-02-25 04:09:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://paleopolis.rediris.es/cg/18/08/index.html> (referer: None)
2021-02-25 04:09:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 4 times): 404 Not Found
2021-02-25 04:09:47 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (referer: None)
2021-02-25 04:09:47 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.scichina.com/2004/yk/yd/0404/yd0347.stm>: HTTP status code is not handled or not allowed
2021-02-25 04:09:58 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> from <GET http://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916>
2021-02-25 04:09:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 04:10:01 [scrapy.extensions.logstats] INFO: Crawled 26 pages (at 4 pages/min), scraped 2 items (at 0 items/min)
2021-02-25 04:10:01 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2021-02-25 04:10:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>, <twisted.python.failure.Failure twisted.web.http._DataLoss: >]
2021-02-25 04:10:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429> (referer: None)
2021-02-25 04:10:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 04:10:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.5027/andgeoV47n1-3177> (failed 1 times): User timeout caused connection failure: Getting https://www.sci-hub.ren/10.5027/andgeoV47n1-3177 took longer than 180.0 seconds..
2021-02-25 04:10:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> (referer: None)
2021-02-25 04:10:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2021-02-25 04:10:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.7306/gq.1547> (referer: None)
2021-02-25 04:10:50 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 04:10:50 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-25 04:11:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 04:11:01 [scrapy.extensions.logstats] INFO: Crawled 29 pages (at 3 pages/min), scraped 2 items (at 0 items/min)
2021-02-25 04:11:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.5027/andgeoV47n1-3177> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 04:11:10 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/> from <GET http://www.sci-hub.ren/>
2021-02-25 04:11:22 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 04:11:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-25 04:11:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.5027/andgeoV47n1-3177> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 04:11:50 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/10.5027/andgeoV47n1-3177> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 04:11:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/10.5027/andgeoV47n1-3177>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-25 04:12:01 [scrapy.extensions.logstats] INFO: Crawled 29 pages (at 0 pages/min), scraped 2 items (at 0 items/min)
2021-02-25 04:13:01 [scrapy.extensions.logstats] INFO: Crawled 29 pages (at 0 pages/min), scraped 2 items (at 0 items/min)
2021-02-25 04:13:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> (referer: None)
2021-02-25 04:14:01 [scrapy.extensions.logstats] INFO: Crawled 30 pages (at 1 pages/min), scraped 2 items (at 0 items/min)
2021-02-25 04:14:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/> (failed 3 times): User timeout caused connection failure: Getting https://www.sci-hub.ren/ took longer than 180.0 seconds..
2021-02-25 04:14:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-25 04:14:19 [scrapy.core.engine] INFO: Closing spider (finished)
2021-02-25 04:14:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 26,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 19,
 'downloader/exception_type_count/twisted.internet.error.TimeoutError': 2,
 'downloader/exception_type_count/twisted.web._newclient.ResponseFailed': 1,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 4,
 'downloader/request_bytes': 46668,
 'downloader/request_count': 112,
 'downloader/request_method_count/GET': 112,
 'downloader/response_bytes': 22327408,
 'downloader/response_count': 86,
 'downloader/response_status_count/200': 29,
 'downloader/response_status_count/301': 15,
 'downloader/response_status_count/302': 34,
 'downloader/response_status_count/404': 8,
 'elapsed_time_seconds': 857.841615,
 'file_count': 2,
 'file_status_count/uptodate': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 2, 24, 20, 14, 19, 536902),
 'httperror/response_ignored_count': 2,
 'httperror/response_ignored_status_count/404': 2,
 'item_scraped_count': 2,
 'log_count/DEBUG': 183,
 'log_count/ERROR': 14,
 'log_count/INFO': 24,
 'log_count/WARNING': 2,
 'memusage/max': 756252672,
 'memusage/startup': 68055040,
 'response_received_count': 31,
 'retry/count': 27,
 'retry/max_reached': 7,
 'retry/reason_count/404 Not Found': 6,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 14,
 'retry/reason_count/twisted.internet.error.TimeoutError': 2,
 'retry/reason_count/twisted.web._newclient.ResponseFailed': 1,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 4,
 'scheduler/dequeued': 112,
 'scheduler/dequeued/memory': 112,
 'scheduler/enqueued': 112,
 'scheduler/enqueued/memory': 112,
 'spider_exceptions/NotSupported': 2,
 'start_time': datetime.datetime(2021, 2, 24, 20, 0, 1, 695287)}
2021-02-25 04:14:19 [scrapy.core.engine] INFO: Spider closed (finished)
2021-02-25 08:00:01 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: wos_crawl)
2021-02-25 08:00:01 [scrapy.utils.log] INFO: Versions: lxml 4.6.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.6.9 (default, Oct  8 2020, 12:12:24) - [GCC 8.4.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1i  8 Dec 2020), cryptography 3.3.1, Platform Linux-4.15.0-132-generic-x86_64-with-Ubuntu-18.04-bionic
2021-02-25 08:00:01 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2021-02-25 08:00:01 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wos_crawl',
 'COOKIES_ENABLED': False,
 'DOWNLOAD_DELAY': 5,
 'LOG_FILE': 'crawler.log',
 'NEWSPIDER_MODULE': 'wos_crawl.spiders',
 'RETRY_HTTP_CODES': [500, 503, 504, 400, 403, 404, 408],
 'RETRY_TIMES': 3,
 'SPIDER_MODULES': ['wos_crawl.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/88.0.4324.104 Safari/537.36'}
2021-02-25 08:00:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2021-02-25 08:00:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-02-25 08:00:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-02-25 08:00:02 [py.warnings] WARNING: /home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/pipelines/media.py:135: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2021-02-25 08:00:02 [scrapy.middleware] INFO: Enabled item pipelines:
['wos_crawl.pipelines.fileDown']
2021-02-25 08:00:02 [scrapy.core.engine] INFO: Spider opened
2021-02-25 08:00:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 08:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 08:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 08:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 08:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 08:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 08:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 08:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 08:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 08:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 08:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 08:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 08:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 08:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 08:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 08:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 08:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 08:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 08:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 08:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 08:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 08:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 08:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 08:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 08:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 08:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 08:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 144
2021-02-25 08:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 08:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 08:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 08:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 08:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 08:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 08:00:07 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v16/n2/p131-141/> from <GET https://www.sci-hub.ren/10.3354/ame016131>
2021-02-25 08:00:22 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf> from <GET https://www.sci-hub.ren/10.5327/Z2317-48892013000300004>
2021-02-25 08:00:27 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> from <GET https://www.sci-hub.ren/10.1360/02yd0178>
2021-02-25 08:00:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/ame021161> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 08:00:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.2113/96.7.1595> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 08:00:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v349/p23-32/> from <GET https://www.sci-hub.ren/10.3354/meps07087>
2021-02-25 08:00:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/ame048123> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 08:00:59 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf> from <GET https://www.sci-hub.ren/10.1344/105.000002051>
2021-02-25 08:01:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 08:01:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.2485/jhtb.20.339> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 08:01:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1344/105.000001770> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 08:01:15 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page> from <GET https://www.sci-hub.ren/10.5139/IJASS.2014.15.4.419>
2021-02-25 08:01:24 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.5209/rev%5C_JIGE.2015.v41.n3.51568>
2021-02-25 08:01:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.7306/gq.1131> (referer: None)
2021-02-25 08:01:34 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 08:01:34 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 08:01:35 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-319-24987-2%5C_26>
2021-02-25 08:01:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1007/978-3-319-04364-7%5C_131> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 08:01:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v16/n2/p131-141/> from <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v16/n2/p131-141/>
2021-02-25 08:01:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1007/978-3-319-24987-2%5C_6> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 08:01:51 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> from <GET https://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm>
2021-02-25 08:01:58 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf> from <GET http://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf>
2021-02-25 08:02:02 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 08:02:08 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595> from <GET https://www.sci-hub.ren/10.2113/96.7.1595>
2021-02-25 08:02:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v349/p23-32/> (referer: None)
2021-02-25 08:02:11 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 08:02:11 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 08:02:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/ame021161> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 08:02:25 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf> from <GET http://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf>
2021-02-25 08:02:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/ame048123> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 08:02:39 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> from <GET https://www.sci-hub.ren/10.1344/105.000001770>
2021-02-25 08:02:41 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page> from <GET http://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page>
2021-02-25 08:02:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-25 08:02:46 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 08:02:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 08:02:53 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html> from <GET https://www.sci-hub.ren/10.3391/ai.2016.11.3.04>
2021-02-25 08:02:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-25 08:02:59 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 08:02:59 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 08:03:02 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 08:03:11 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-319-04364-7%5C_131>
2021-02-25 08:03:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v16/n2/p131-141/> (referer: None)
2021-02-25 08:03:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 08:03:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 150
2021-02-25 08:03:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 1 times): 404 Not Found
2021-02-25 08:03:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1007/978-3-319-24987-2%5C_6> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 08:03:39 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://bjg.siteoficial.ws/2013/n.3/d.pdf> from <GET https://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf>
2021-02-25 08:03:47 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://paleoitalia.org> from <GET https://www.sci-hub.ren/10.4435/BSPI.2016.09>
2021-02-25 08:03:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 08:04:00 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.publicacions.ub.edu/doi/documents/2051.pdf> from <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf>
2021-02-25 08:04:02 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 08:04:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/ame021161> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 08:04:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page> (referer: None)
2021-02-25 08:04:20 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 08:04:20 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 08:04:24 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> from <GET http://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770>
2021-02-25 08:04:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/ame048123> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 08:04:34 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.aquaticinvasions.net/2016/issue3.html> from <GET https://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html>
2021-02-25 08:04:35 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://geojournals.pgi.gov.pl/asgp/article/view/25493> from <GET https://www.sci-hub.ren/10.14241/asgp.2016.011>
2021-02-25 08:04:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.1055/s-0036-1596638> (referer: None)
2021-02-25 08:04:38 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 08:04:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 149
2021-02-25 08:04:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/> from <GET http://www.sci-hub.ren/>
2021-02-25 08:04:51 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/> from <GET https://www.sci-hub.ren/10.3354/meps12300>
2021-02-25 08:04:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 2 times): 404 Not Found
2021-02-25 08:05:02 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 08:05:14 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://paleoitalia.org> from <GET http://www.sci-hub.ren/http://paleoitalia.org>
2021-02-25 08:05:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1007/978-3-319-24987-2%5C_6> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 08:05:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.publicacions.ub.edu/doi/documents/2051.pdf> (referer: None)
2021-02-25 08:05:28 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 08:05:28 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 08:05:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.publicacions.ub.edu/doi/documents/2051.pdf> (referer: None)
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/python.py", line 353, in __next__
    return next(self.data)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/python.py", line 353, in __next__
    return next(self.data)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/wos_crawl/wos_crawl/spiders/wos_spider.py", line 39, in parse
    detail_url_list = response.xpath('//*[@id="buttons"]/ul/li[2]/a/@onclick')
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/http/response/__init__.py", line 120, in xpath
    raise NotSupported("Response content isn't text")
scrapy.exceptions.NotSupported: Response content isn't text
2021-02-25 08:05:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bjg.siteoficial.ws/2013/n.3/d.pdf> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 08:05:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.2485/jhtb.20.339> (failed 2 times): User timeout caused connection failure: Getting https://www.sci-hub.ren/10.2485/jhtb.20.339 took longer than 180.0 seconds..
2021-02-25 08:05:34 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359> from <GET https://www.sci-hub.ren/10.3389/fmicb.2013.01359>
2021-02-25 08:05:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 08:05:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> from <GET https://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770>
2021-02-25 08:05:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/10.3354/ame021161> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 08:05:47 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 08:05:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 08:05:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/10.3354/ame021161>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-25 08:05:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.aquaticinvasions.net/2016/issue3.html> (failed 1 times): 403 Forbidden
2021-02-25 08:06:02 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 08:06:02 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://geojournals.pgi.gov.pl/asgp/article/view/25493> from <GET https://www.sci-hub.ren/https://geojournals.pgi.gov.pl/asgp/article/view/25493>
2021-02-25 08:06:06 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/10.3354/ame048123> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 08:06:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 08:06:06 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 08:06:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/10.3354/ame048123>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-25 08:06:09 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://paleopolis.rediris.es/cg/18/08/index.html> from <GET https://www.sci-hub.ren/10.4267/2042/68182>
2021-02-25 08:06:21 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/> from <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/>
2021-02-25 08:06:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 3 times): 404 Not Found
2021-02-25 08:06:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 08:06:35 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://paleoitalia.org/> from <GET https://www.sci-hub.ren/http://paleoitalia.org>
2021-02-25 08:06:46 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/> from <GET https://www.sci-hub.ren/10.3354/meps12741>
2021-02-25 08:07:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/10.1007/978-3-319-24987-2%5C_6> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 08:07:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 08:07:00 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 149
2021-02-25 08:07:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/10.1007/978-3-319-24987-2%5C_6>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-25 08:07:02 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 08:07:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359> (referer: None)
2021-02-25 08:07:07 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 08:07:07 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 149
2021-02-25 08:07:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://bjg.siteoficial.ws/2013/n.3/d.pdf> (referer: None)
2021-02-25 08:07:09 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 08:07:09 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 08:07:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://bjg.siteoficial.ws/2013/n.3/d.pdf> (referer: None)
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/python.py", line 353, in __next__
    return next(self.data)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/python.py", line 353, in __next__
    return next(self.data)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/wos_crawl/wos_crawl/spiders/wos_spider.py", line 39, in parse
    detail_url_list = response.xpath('//*[@id="buttons"]/ul/li[2]/a/@onclick')
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/http/response/__init__.py", line 120, in xpath
    raise NotSupported("Response content isn't text")
scrapy.exceptions.NotSupported: Response content isn't text
2021-02-25 08:07:27 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> from <GET https://www.sci-hub.ren/10.4072/rbp.2018.3.01>
2021-02-25 08:07:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.aquaticinvasions.net/2016/issue3.html> (failed 2 times): 403 Forbidden
2021-02-25 08:07:34 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 08:07:34 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 08:07:34 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 08:07:34 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-25 08:07:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 08:07:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://geojournals.pgi.gov.pl/asgp/article/view/25493> (referer: None)
2021-02-25 08:07:43 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 08:07:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 08:07:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html> from <GET https://www.sci-hub.ren/10.1051/bsgf/2018019>
2021-02-25 08:07:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://paleopolis.rediris.es/cg/18/08/index.html> from <GET https://www.sci-hub.ren/http://paleopolis.rediris.es/cg/18/08/index.html>
2021-02-25 08:07:57 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 4 times): 404 Not Found
2021-02-25 08:07:57 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (referer: None)
2021-02-25 08:07:57 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 08:07:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 08:07:57 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.scichina.com/2004/yk/yd/0404/yd0347.stm>: HTTP status code is not handled or not allowed
2021-02-25 08:08:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/> (referer: None)
2021-02-25 08:08:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 08:08:00 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 08:08:02 [scrapy.extensions.logstats] INFO: Crawled 13 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 08:08:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-25 08:08:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 08:08:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 08:08:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://paleoitalia.org/> (referer: None)
2021-02-25 08:08:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 08:08:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 08:08:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/> (referer: None)
2021-02-25 08:08:19 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 08:08:19 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 08:08:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.5027/andgeoV46n1-3029> (referer: None)
2021-02-25 08:08:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/ame/v82/n3/p253-264/> from <GET https://www.sci-hub.ren/10.3354/ame01895>
2021-02-25 08:08:43 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://doi.org/10.3390/min9100000> from <GET https://www.sci-hub.ren/10.3390/min9100000>
2021-02-25 08:08:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> from <GET https://www.sci-hub.ren/https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf>
2021-02-25 08:08:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.aquaticinvasions.net/2016/issue3.html> (failed 3 times): 403 Forbidden
2021-02-25 08:09:02 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 08:09:10 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-030-21614-6%5C_12>
2021-02-25 08:09:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.5027/andgeoV47n1-3177> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 08:09:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://paleopolis.rediris.es/cg/18/08/index.html> (referer: None)
2021-02-25 08:09:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 08:09:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.1089/ast.2019.2067> (referer: None)
2021-02-25 08:09:25 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded file from <GET https://cyber.bban.top/MTAuMTA4OS9hc3QuMjAxOS4yMDY3/10.1089%40ast.2019.2067.pdf?download=true> referred in <None>
2021-02-25 08:09:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.sci-hub.ren/10.1089/ast.2019.2067>
{'file_urls': ['https://cyber.bban.top/MTAuMTA4OS9hc3QuMjAxOS4yMDY3/10.1089%40ast.2019.2067.pdf?download=true'],
 'files': [{'checksum': '808358d065f4915b2156f3de1d6a1a24',
            'path': '000582254100001.pdf',
            'status': 'uptodate',
            'url': 'https://cyber.bban.top/MTAuMTA4OS9hc3QuMjAxOS4yMDY3/10.1089%40ast.2019.2067.pdf?download=true'}],
 'name': '000582254100001'}
2021-02-25 08:09:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html> (referer: None)
2021-02-25 08:09:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.1155/2020/6959532> (referer: None)
2021-02-25 08:09:29 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded file from <GET https://cyber.bban.top/MTAuMTE1NS8yMDIwLzY5NTk1MzI=/10.1155%402020%406959532.pdf?download=true> referred in <None>
2021-02-25 08:09:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.sci-hub.ren/10.1155/2020/6959532>
{'file_urls': ['https://cyber.bban.top/MTAuMTE1NS8yMDIwLzY5NTk1MzI=/10.1155%402020%406959532.pdf?download=true'],
 'files': [{'checksum': '6c02fcee70c30afc9791e2e93ddc95f4',
            'path': '000588326000002.pdf',
            'status': 'uptodate',
            'url': 'https://cyber.bban.top/MTAuMTE1NS8yMDIwLzY5NTk1MzI=/10.1155%402020%406959532.pdf?download=true'}],
 'name': '000588326000002'}
2021-02-25 08:09:36 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> from <GET https://www.sci-hub.ren/10.1111/1758-2229.12916>
2021-02-25 08:09:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429> from <GET https://www.sci-hub.ren/10.1111/gbi.12429>
2021-02-25 08:09:51 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486> from <GET https://www.sci-hub.ren/10.7306/gq.1547>
2021-02-25 08:09:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/ame/v82/n3/p253-264/> (referer: None)
2021-02-25 08:09:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.2485/jhtb.20.339> (failed 3 times): User timeout caused connection failure: Getting https://www.sci-hub.ren/10.2485/jhtb.20.339 took longer than 180.0 seconds..
2021-02-25 08:10:02 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 5 pages/min), scraped 2 items (at 2 items/min)
2021-02-25 08:10:03 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://doi.org/10.3390/min9100000> from <GET http://www.sci-hub.ren/https://doi.org/10.3390/min9100000>
2021-02-25 08:10:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://www.aquaticinvasions.net/2016/issue3.html> (failed 4 times): 403 Forbidden
2021-02-25 08:10:15 [scrapy.core.engine] DEBUG: Crawled (403) <GET http://www.aquaticinvasions.net/2016/issue3.html> (referer: None)
2021-02-25 08:10:15 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 http://www.aquaticinvasions.net/2016/issue3.html>: HTTP status code is not handled or not allowed
2021-02-25 08:10:20 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/> from <GET http://www.sci-hub.ren/>
2021-02-25 08:10:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> (referer: None)
2021-02-25 08:10:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.5027/andgeoV47n1-3177> (referer: None)
2021-02-25 08:10:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> (referer: None)
2021-02-25 08:10:52 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 08:10:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-25 08:10:59 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429?cookieSet=1> from <GET https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429>
2021-02-25 08:11:02 [scrapy.extensions.logstats] INFO: Crawled 26 pages (at 4 pages/min), scraped 2 items (at 0 items/min)
2021-02-25 08:11:02 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://gq.pgi.gov.pl/article/view/28486> from <GET https://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486>
2021-02-25 08:11:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://doi.org/10.3390/min9100000> (referer: None)
2021-02-25 08:11:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-25 08:11:18 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/10.2485/jhtb.20.339> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 08:11:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/10.2485/jhtb.20.339>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-25 08:11:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429?cookieSet=1> (referer: None)
2021-02-25 08:11:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://gq.pgi.gov.pl/article/view/28486> (referer: None)
2021-02-25 08:11:30 [scrapy.core.engine] INFO: Closing spider (finished)
2021-02-25 08:11:30 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 28,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 26,
 'downloader/exception_type_count/twisted.internet.error.TimeoutError': 2,
 'downloader/request_bytes': 46280,
 'downloader/request_count': 111,
 'downloader/request_method_count/GET': 111,
 'downloader/response_bytes': 22316351,
 'downloader/response_count': 83,
 'downloader/response_status_count/200': 28,
 'downloader/response_status_count/301': 10,
 'downloader/response_status_count/302': 37,
 'downloader/response_status_count/403': 4,
 'downloader/response_status_count/404': 4,
 'elapsed_time_seconds': 688.882145,
 'file_count': 2,
 'file_status_count/uptodate': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 2, 25, 0, 11, 30, 898679),
 'httperror/response_ignored_count': 2,
 'httperror/response_ignored_status_count/403': 1,
 'httperror/response_ignored_status_count/404': 1,
 'item_scraped_count': 2,
 'log_count/DEBUG': 181,
 'log_count/ERROR': 16,
 'log_count/INFO': 21,
 'log_count/WARNING': 1,
 'memusage/max': 757604352,
 'memusage/startup': 68218880,
 'response_received_count': 30,
 'retry/count': 28,
 'retry/max_reached': 8,
 'retry/reason_count/403 Forbidden': 3,
 'retry/reason_count/404 Not Found': 3,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 20,
 'retry/reason_count/twisted.internet.error.TimeoutError': 2,
 'scheduler/dequeued': 111,
 'scheduler/dequeued/memory': 111,
 'scheduler/enqueued': 111,
 'scheduler/enqueued/memory': 111,
 'spider_exceptions/NotSupported': 2,
 'start_time': datetime.datetime(2021, 2, 25, 0, 0, 2, 16534)}
2021-02-25 08:11:30 [scrapy.core.engine] INFO: Spider closed (finished)
2021-02-25 12:00:02 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: wos_crawl)
2021-02-25 12:00:02 [scrapy.utils.log] INFO: Versions: lxml 4.6.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.6.9 (default, Oct  8 2020, 12:12:24) - [GCC 8.4.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1i  8 Dec 2020), cryptography 3.3.1, Platform Linux-4.15.0-132-generic-x86_64-with-Ubuntu-18.04-bionic
2021-02-25 12:00:02 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2021-02-25 12:00:02 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wos_crawl',
 'COOKIES_ENABLED': False,
 'DOWNLOAD_DELAY': 5,
 'LOG_FILE': 'crawler.log',
 'NEWSPIDER_MODULE': 'wos_crawl.spiders',
 'RETRY_HTTP_CODES': [500, 503, 504, 400, 403, 404, 408],
 'RETRY_TIMES': 3,
 'SPIDER_MODULES': ['wos_crawl.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/88.0.4324.104 Safari/537.36'}
2021-02-25 12:00:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2021-02-25 12:00:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-02-25 12:00:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-02-25 12:00:02 [py.warnings] WARNING: /home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/pipelines/media.py:135: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2021-02-25 12:00:02 [scrapy.middleware] INFO: Enabled item pipelines:
['wos_crawl.pipelines.fileDown']
2021-02-25 12:00:02 [scrapy.core.engine] INFO: Spider opened
2021-02-25 12:00:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 12:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 12:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 12:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 12:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 12:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 12:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 12:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 12:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 12:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 12:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 12:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 12:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 12:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 12:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 12:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 12:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 144
2021-02-25 12:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 12:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 12:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 12:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 12:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 12:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 12:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 12:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 12:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 12:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 149
2021-02-25 12:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 12:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 12:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 12:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 12:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 12:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 12:00:14 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> from <GET https://www.sci-hub.ren/10.3354/ame021161>
2021-02-25 12:00:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/ame016131> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:00:27 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> from <GET https://www.sci-hub.ren/10.1360/02yd0178>
2021-02-25 12:00:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.2113/96.7.1595> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:00:37 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/> from <GET https://www.sci-hub.ren/10.3354/ame048123>
2021-02-25 12:00:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.5327/Z2317-48892013000300004> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:00:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.3354/meps07087> (referer: None)
2021-02-25 12:00:44 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 12:00:44 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 12:00:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.2485/jhtb.20.339> (referer: None)
2021-02-25 12:00:47 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 12:00:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 12:00:52 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> from <GET https://www.sci-hub.ren/10.1344/105.000001770>
2021-02-25 12:01:00 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf> from <GET https://www.sci-hub.ren/10.1344/105.000002051>
2021-02-25 12:01:02 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 12:01:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.7306/gq.1131> (referer: None)
2021-02-25 12:01:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 12:01:06 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 12:01:13 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page> from <GET https://www.sci-hub.ren/10.5139/IJASS.2014.15.4.419>
2021-02-25 12:01:20 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-319-04364-7%5C_131>
2021-02-25 12:01:23 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.5209/rev%5C_JIGE.2015.v41.n3.51568>
2021-02-25 12:01:36 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-319-24987-2%5C_6>
2021-02-25 12:01:36 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-319-24987-2%5C_26>
2021-02-25 12:01:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:01:51 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> from <GET https://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm>
2021-02-25 12:01:58 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595> from <GET https://www.sci-hub.ren/10.2113/96.7.1595>
2021-02-25 12:02:02 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 12:02:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/> from <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/>
2021-02-25 12:02:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/ame016131> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:02:25 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://paleoitalia.org> from <GET https://www.sci-hub.ren/10.4435/BSPI.2016.09>
2021-02-25 12:02:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.5327/Z2317-48892013000300004> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:02:34 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> from <GET https://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770>
2021-02-25 12:02:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3391/ai.2016.11.3.04> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:02:39 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf> from <GET http://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf>
2021-02-25 12:02:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.14241/asgp.2016.011> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-02-25 12:02:51 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://koreascience.or.kr/article/JAKO201404065095388.page> from <GET https://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page>
2021-02-25 12:02:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/> (failed 1 times): 403 Forbidden
2021-02-25 12:03:02 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 12:03:02 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/> from <GET http://www.sci-hub.ren/>
2021-02-25 12:03:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-25 12:03:14 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 12:03:14 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 12:03:23 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> from <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/>
2021-02-25 12:03:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 1 times): 404 Not Found
2021-02-25 12:03:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:03:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-02-25 12:03:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:03:56 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://paleoitalia.org/> from <GET https://www.sci-hub.ren/http://paleoitalia.org>
2021-02-25 12:04:02 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 12:04:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/ame016131> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:04:14 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf> from <GET https://www.sci-hub.ren/10.5327/Z2317-48892013000300004>
2021-02-25 12:04:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> (referer: None)
2021-02-25 12:04:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 12:04:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 144
2021-02-25 12:04:17 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html> from <GET https://www.sci-hub.ren/10.3391/ai.2016.11.3.04>
2021-02-25 12:04:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:04:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/> (failed 2 times): 403 Forbidden
2021-02-25 12:04:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.14241/asgp.2016.011> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:04:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://koreascience.or.kr/article/JAKO201404065095388.page> (referer: None)
2021-02-25 12:04:50 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 12:04:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 12:04:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.1055/s-0036-1596638> (referer: None)
2021-02-25 12:04:51 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 12:04:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 12:05:02 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 12:05:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> (referer: None)
2021-02-25 12:05:03 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 12:05:03 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 12:05:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 2 times): 404 Not Found
2021-02-25 12:05:13 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/> from <GET http://www.sci-hub.ren/>
2021-02-25 12:05:27 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595> from <GET http://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595>
2021-02-25 12:05:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://paleoitalia.org/> (failed 1 times): 403 Forbidden
2021-02-25 12:05:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:05:39 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v16/n2/p131-141/> from <GET https://www.sci-hub.ren/10.3354/ame016131>
2021-02-25 12:05:46 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/> from <GET https://www.sci-hub.ren/10.3354/meps12300>
2021-02-25 12:06:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/> (failed 3 times): 403 Forbidden
2021-02-25 12:06:02 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 12:06:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:06:16 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359> from <GET https://www.sci-hub.ren/10.3389/fmicb.2013.01359>
2021-02-25 12:06:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:06:18 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html> from <GET http://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html>
2021-02-25 12:06:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.14241/asgp.2016.011> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:06:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://paleopolis.rediris.es/cg/18/08/index.html> from <GET https://www.sci-hub.ren/10.4267/2042/68182>
2021-02-25 12:06:35 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/> from <GET https://www.sci-hub.ren/10.3354/meps12741>
2021-02-25 12:06:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 3 times): 404 Not Found
2021-02-25 12:06:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://paleoitalia.org/> (failed 2 times): 403 Forbidden
2021-02-25 12:07:02 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 12:07:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:07:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:07:15 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/> from <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/>
2021-02-25 12:07:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://www.sci-hub.ren/> (failed 4 times): 403 Forbidden
2021-02-25 12:07:19 [scrapy.core.engine] DEBUG: Crawled (403) <GET http://www.sci-hub.ren/> (referer: None)
2021-02-25 12:07:19 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 12:07:19 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 12:07:19 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 http://www.sci-hub.ren/>: HTTP status code is not handled or not allowed
2021-02-25 12:07:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:07:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v16/n2/p131-141/> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:07:28 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 12:07:28 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 149
2021-02-25 12:07:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v16/n2/p131-141/>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-25 12:07:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf> from <GET http://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf>
2021-02-25 12:07:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/> (failed 1 times): User timeout caused connection failure: Getting https://www.sci-hub.ren/ took longer than 180.0 seconds..
2021-02-25 12:07:53 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.aquaticinvasions.net/2016/issue3.html> from <GET https://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html>
2021-02-25 12:07:56 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://paleopolis.rediris.es/cg/18/08/index.html> from <GET https://www.sci-hub.ren/http://paleopolis.rediris.es/cg/18/08/index.html>
2021-02-25 12:08:02 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 12:08:04 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 4 times): 404 Not Found
2021-02-25 12:08:04 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (referer: None)
2021-02-25 12:08:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 12:08:04 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 12:08:04 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.scichina.com/2004/yk/yd/0404/yd0347.stm>: HTTP status code is not handled or not allowed
2021-02-25 12:08:06 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/10.14241/asgp.2016.011> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:08:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 12:08:06 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 12:08:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/10.14241/asgp.2016.011>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-25 12:08:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://paleoitalia.org/> (failed 3 times): 403 Forbidden
2021-02-25 12:08:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:08:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/> (referer: None)
2021-02-25 12:08:31 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 12:08:31 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 12:08:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:08:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> from <GET https://www.sci-hub.ren/10.4072/rbp.2018.3.01>
2021-02-25 12:08:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:08:45 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 12:08:45 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 149
2021-02-25 12:08:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-25 12:08:51 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html> from <GET https://www.sci-hub.ren/10.1051/bsgf/2018019>
2021-02-25 12:09:02 [scrapy.extensions.logstats] INFO: Crawled 11 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 12:09:03 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:09:03 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 12:09:03 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 12:09:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-25 12:09:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://paleopolis.rediris.es/cg/18/08/index.html> (referer: None)
2021-02-25 12:09:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 12:09:15 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 12:09:16 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:09:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 12:09:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 149
2021-02-25 12:09:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-25 12:09:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.5027/andgeoV46n1-3029> (referer: None)
2021-02-25 12:09:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 12:09:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 149
2021-02-25 12:09:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.aquaticinvasions.net/2016/issue3.html> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:09:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://paleoitalia.org/> (failed 4 times): 403 Forbidden
2021-02-25 12:09:29 [scrapy.core.engine] DEBUG: Crawled (403) <GET http://paleoitalia.org/> (referer: None)
2021-02-25 12:09:29 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 12:09:29 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 12:09:29 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 http://paleoitalia.org/>: HTTP status code is not handled or not allowed
2021-02-25 12:09:43 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://doi.org/10.3390/min9100000> from <GET https://www.sci-hub.ren/10.3390/min9100000>
2021-02-25 12:09:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:09:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> from <GET https://www.sci-hub.ren/https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf>
2021-02-25 12:10:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.5027/andgeoV47n1-3177> (referer: None)
2021-02-25 12:10:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 12:10:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 12:10:02 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 12:10:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:10:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-25 12:10:09 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html> from <GET http://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html>
2021-02-25 12:10:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.1089/ast.2019.2067> (referer: None)
2021-02-25 12:10:20 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded file from <GET https://cyber.bban.top/MTAuMTA4OS9hc3QuMjAxOS4yMDY3/10.1089%40ast.2019.2067.pdf?download=true> referred in <None>
2021-02-25 12:10:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.sci-hub.ren/10.1089/ast.2019.2067>
{'file_urls': ['https://cyber.bban.top/MTAuMTA4OS9hc3QuMjAxOS4yMDY3/10.1089%40ast.2019.2067.pdf?download=true'],
 'files': [{'checksum': '808358d065f4915b2156f3de1d6a1a24',
            'path': '000582254100001.pdf',
            'status': 'uptodate',
            'url': 'https://cyber.bban.top/MTAuMTA4OS9hc3QuMjAxOS4yMDY3/10.1089%40ast.2019.2067.pdf?download=true'}],
 'name': '000582254100001'}
2021-02-25 12:10:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.1155/2020/6959532> (referer: None)
2021-02-25 12:10:26 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded file from <GET https://cyber.bban.top/MTAuMTE1NS8yMDIwLzY5NTk1MzI=/10.1155%402020%406959532.pdf?download=true> referred in <None>
2021-02-25 12:10:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.sci-hub.ren/10.1155/2020/6959532>
{'file_urls': ['https://cyber.bban.top/MTAuMTE1NS8yMDIwLzY5NTk1MzI=/10.1155%402020%406959532.pdf?download=true'],
 'files': [{'checksum': '6c02fcee70c30afc9791e2e93ddc95f4',
            'path': '000588326000002.pdf',
            'status': 'uptodate',
            'url': 'https://cyber.bban.top/MTAuMTE1NS8yMDIwLzY5NTk1MzI=/10.1155%402020%406959532.pdf?download=true'}],
 'name': '000588326000002'}
2021-02-25 12:10:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359> (failed 1 times): User timeout caused connection failure: Getting https://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359 took longer than 180.0 seconds..
2021-02-25 12:10:34 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> from <GET https://www.sci-hub.ren/10.1111/1758-2229.12916>
2021-02-25 12:10:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf> (failed 3 times): User timeout caused connection failure: Getting https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf took longer than 180.0 seconds..
2021-02-25 12:10:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1007/978-3-030-21614-6%5C_12> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:10:43 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486> from <GET https://www.sci-hub.ren/10.7306/gq.1547>
2021-02-25 12:10:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://doi.org/10.3390/min9100000> (referer: None)
2021-02-25 12:10:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.aquaticinvasions.net/2016/issue3.html> (referer: None)
2021-02-25 12:11:01 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/> from <GET http://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/>
2021-02-25 12:11:02 [scrapy.extensions.logstats] INFO: Crawled 19 pages (at 4 pages/min), scraped 2 items (at 2 items/min)
2021-02-25 12:11:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> (referer: None)
2021-02-25 12:11:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359> (referer: None)
2021-02-25 12:11:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1111/gbi.12429> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:11:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> (failed 1 times): 403 Forbidden
2021-02-25 12:11:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html> (referer: None)
2021-02-25 12:11:57 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:11:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-25 12:11:59 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://gq.pgi.gov.pl/article/view/28486> from <GET https://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486>
2021-02-25 12:12:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/> (failed 2 times): User timeout caused connection failure: Getting https://www.sci-hub.ren/ took longer than 180.0 seconds..
2021-02-25 12:12:02 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 3 pages/min), scraped 2 items (at 0 items/min)
2021-02-25 12:12:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1007/978-3-030-21614-6%5C_12> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:12:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/> (referer: None)
2021-02-25 12:12:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> (failed 2 times): 403 Forbidden
2021-02-25 12:12:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/ame01895> (failed 1 times): User timeout caused connection failure: Getting https://www.sci-hub.ren/10.3354/ame01895 took longer than 180.0 seconds..
2021-02-25 12:12:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1111/gbi.12429> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:12:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> (failed 3 times): 403 Forbidden
2021-02-25 12:12:36 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/ame/v82/n3/p253-264/> from <GET https://www.sci-hub.ren/10.3354/ame01895>
2021-02-25 12:12:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:12:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://gq.pgi.gov.pl/article/view/28486> (referer: None)
2021-02-25 12:12:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1007/978-3-030-21614-6%5C_12> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:12:48 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> (failed 4 times): 403 Forbidden
2021-02-25 12:12:48 [scrapy.core.engine] DEBUG: Crawled (403) <GET http://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> (referer: None)
2021-02-25 12:12:48 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 http://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916>: HTTP status code is not handled or not allowed
2021-02-25 12:12:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/ame/v82/n3/p253-264/> (referer: None)
2021-02-25 12:13:02 [scrapy.extensions.logstats] INFO: Crawled 26 pages (at 4 pages/min), scraped 2 items (at 0 items/min)
2021-02-25 12:13:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1111/gbi.12429> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:13:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:13:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-25 12:13:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/10.1007/978-3-030-21614-6%5C_12> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:13:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/10.1007/978-3-030-21614-6%5C_12>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-25 12:13:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/10.1111/gbi.12429> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 12:13:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/10.1111/gbi.12429>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-25 12:13:33 [scrapy.core.engine] INFO: Closing spider (finished)
2021-02-25 12:13:33 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 47,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 40,
 'downloader/exception_type_count/twisted.internet.error.TimeoutError': 5,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 2,
 'downloader/request_bytes': 53841,
 'downloader/request_count': 129,
 'downloader/request_method_count/GET': 129,
 'downloader/response_bytes': 18014854,
 'downloader/response_count': 82,
 'downloader/response_status_count/200': 22,
 'downloader/response_status_count/301': 11,
 'downloader/response_status_count/302': 33,
 'downloader/response_status_count/403': 12,
 'downloader/response_status_count/404': 4,
 'elapsed_time_seconds': 811.314211,
 'file_count': 2,
 'file_status_count/uptodate': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 2, 25, 4, 13, 33, 375528),
 'httperror/response_ignored_count': 4,
 'httperror/response_ignored_status_count/403': 3,
 'httperror/response_ignored_status_count/404': 1,
 'item_scraped_count': 2,
 'log_count/DEBUG': 195,
 'log_count/ERROR': 24,
 'log_count/INFO': 25,
 'log_count/WARNING': 1,
 'memusage/max': 754884608,
 'memusage/startup': 68108288,
 'response_received_count': 26,
 'retry/count': 49,
 'retry/max_reached': 14,
 'retry/reason_count/403 Forbidden': 9,
 'retry/reason_count/404 Not Found': 3,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 30,
 'retry/reason_count/twisted.internet.error.TimeoutError': 5,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 2,
 'scheduler/dequeued': 129,
 'scheduler/dequeued/memory': 129,
 'scheduler/enqueued': 129,
 'scheduler/enqueued/memory': 129,
 'start_time': datetime.datetime(2021, 2, 25, 4, 0, 2, 61317)}
2021-02-25 12:13:33 [scrapy.core.engine] INFO: Spider closed (finished)
2021-02-25 16:00:02 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: wos_crawl)
2021-02-25 16:00:02 [scrapy.utils.log] INFO: Versions: lxml 4.6.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.6.9 (default, Oct  8 2020, 12:12:24) - [GCC 8.4.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1i  8 Dec 2020), cryptography 3.3.1, Platform Linux-4.15.0-132-generic-x86_64-with-Ubuntu-18.04-bionic
2021-02-25 16:00:02 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2021-02-25 16:00:02 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wos_crawl',
 'COOKIES_ENABLED': False,
 'DOWNLOAD_DELAY': 5,
 'LOG_FILE': 'crawler.log',
 'NEWSPIDER_MODULE': 'wos_crawl.spiders',
 'RETRY_HTTP_CODES': [500, 503, 504, 400, 403, 404, 408],
 'RETRY_TIMES': 3,
 'SPIDER_MODULES': ['wos_crawl.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/88.0.4324.104 Safari/537.36'}
2021-02-25 16:00:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2021-02-25 16:00:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-02-25 16:00:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-02-25 16:00:02 [py.warnings] WARNING: /home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/pipelines/media.py:135: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2021-02-25 16:00:02 [scrapy.middleware] INFO: Enabled item pipelines:
['wos_crawl.pipelines.fileDown']
2021-02-25 16:00:02 [scrapy.core.engine] INFO: Spider opened
2021-02-25 16:00:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 16:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 16:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 16:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 16:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 144
2021-02-25 16:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 16:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 16:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 16:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 16:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 16:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 16:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 16:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 16:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 16:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 16:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 16:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 16:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 16:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 16:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 16:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 16:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 16:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 16:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 16:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 16:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 16:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 16:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 16:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 16:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 16:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 16:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 16:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 16:00:03 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v16/n2/p131-141/> from <GET https://www.sci-hub.ren/10.3354/ame016131>
2021-02-25 16:00:10 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> from <GET https://www.sci-hub.ren/10.3354/ame021161>
2021-02-25 16:00:21 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf> from <GET https://www.sci-hub.ren/10.5327/Z2317-48892013000300004>
2021-02-25 16:00:31 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> from <GET https://www.sci-hub.ren/10.1360/02yd0178>
2021-02-25 16:00:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.2113/96.7.1595> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 16:00:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.3354/meps07087> (referer: None)
2021-02-25 16:00:40 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 16:00:40 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 16:00:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.2485/jhtb.20.339> (referer: None)
2021-02-25 16:00:48 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 16:00:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 16:00:58 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> from <GET https://www.sci-hub.ren/10.1344/105.000001770>
2021-02-25 16:00:59 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf> from <GET https://www.sci-hub.ren/10.1344/105.000002051>
2021-02-25 16:01:02 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 16:01:13 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page> from <GET https://www.sci-hub.ren/10.5139/IJASS.2014.15.4.419>
2021-02-25 16:01:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.7306/gq.1131> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-02-25 16:01:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.5209/rev%5C_JIGE.2015.v41.n3.51568>
2021-02-25 16:01:34 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-319-24987-2%5C_6>
2021-02-25 16:01:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1007/978-3-319-04364-7%5C_131> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 16:01:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v16/n2/p131-141/> (referer: None)
2021-02-25 16:01:51 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 16:01:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 16:01:52 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-319-24987-2%5C_26>
2021-02-25 16:01:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> (referer: None)
2021-02-25 16:01:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 16:01:58 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 16:02:02 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 16:02:06 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf> from <GET http://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf>
2021-02-25 16:02:09 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595> from <GET https://www.sci-hub.ren/10.2113/96.7.1595>
2021-02-25 16:02:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 16:02:27 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html> from <GET https://www.sci-hub.ren/10.3391/ai.2016.11.3.04>
2021-02-25 16:02:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> from <GET http://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770>
2021-02-25 16:02:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-02-25 16:02:36 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://paleoitalia.org> from <GET https://www.sci-hub.ren/10.4435/BSPI.2016.09>
2021-02-25 16:02:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://koreascience.or.kr/article/JAKO201404065095388.page> from <GET https://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page>
2021-02-25 16:02:54 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/> from <GET http://www.sci-hub.ren/>
2021-02-25 16:02:54 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/9274> from <GET https://www.sci-hub.ren/10.7306/gq.1131>
2021-02-25 16:02:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/> from <GET http://www.sci-hub.ren/>
2021-02-25 16:03:02 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 16:03:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1007/978-3-319-04364-7%5C_131> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 16:03:25 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://bjg.siteoficial.ws/2013/n.3/d.pdf> from <GET https://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf>
2021-02-25 16:03:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.14241/asgp.2016.011> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 16:03:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 16:03:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/ame048123> (failed 1 times): User timeout caused connection failure: Getting https://www.sci-hub.ren/10.3354/ame048123 took longer than 180.0 seconds..
2021-02-25 16:03:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1055/s-0036-1596638> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 16:03:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html> from <GET http://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html>
2021-02-25 16:03:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 16:03:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-02-25 16:03:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 16:04:02 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 16:04:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 16:04:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://koreascience.or.kr/article/JAKO201404065095388.page> (referer: None)
2021-02-25 16:04:07 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 16:04:07 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 143
2021-02-25 16:04:09 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://paleoitalia.org> from <GET http://www.sci-hub.ren/http://paleoitalia.org>
2021-02-25 16:04:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-25 16:04:22 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 16:04:22 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 16:04:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-25 16:04:22 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 16:04:22 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 16:04:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/9274> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-02-25 16:04:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1007/978-3-319-04364-7%5C_131> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 16:04:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.14241/asgp.2016.011> (referer: None)
2021-02-25 16:04:45 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 16:04:45 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 16:04:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://bjg.siteoficial.ws/2013/n.3/d.pdf> (referer: None)
2021-02-25 16:04:50 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 16:04:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 16:04:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://bjg.siteoficial.ws/2013/n.3/d.pdf> (referer: None)
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/python.py", line 353, in __next__
    return next(self.data)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/python.py", line 353, in __next__
    return next(self.data)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/wos_crawl/wos_crawl/spiders/wos_spider.py", line 39, in parse
    detail_url_list = response.xpath('//*[@id="buttons"]/ul/li[2]/a/@onclick')
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/http/response/__init__.py", line 120, in xpath
    raise NotSupported("Response content isn't text")
scrapy.exceptions.NotSupported: Response content isn't text
2021-02-25 16:04:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 16:05:02 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 16:05:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1055/s-0036-1596638> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 16:05:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-02-25 16:05:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 16:05:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 16:05:28 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/> from <GET https://www.sci-hub.ren/10.3354/meps12300>
2021-02-25 16:05:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 16:05:35 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://paleoitalia.org/> from <GET https://www.sci-hub.ren/http://paleoitalia.org>
2021-02-25 16:05:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359> from <GET https://www.sci-hub.ren/10.3389/fmicb.2013.01359>
2021-02-25 16:05:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 16:05:47 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://paleopolis.rediris.es/cg/18/08/index.html> from <GET https://www.sci-hub.ren/10.4267/2042/68182>
2021-02-25 16:06:02 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 16:06:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/9274> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-02-25 16:06:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/> from <GET https://www.sci-hub.ren/10.3354/meps12741>
2021-02-25 16:06:09 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-319-04364-7%5C_131>
2021-02-25 16:06:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.4072/rbp.2018.3.01> (referer: None)
2021-02-25 16:06:19 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 16:06:19 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 16:06:20 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/> from <GET http://www.sci-hub.ren/>
2021-02-25 16:06:31 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf> (failed 4 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-02-25 16:06:31 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 16:06:31 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 16:06:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-02-25 16:06:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1055/s-0036-1596638> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 16:06:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 16:06:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://paleoitalia.org/> (referer: None) ['partial']
2021-02-25 16:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 16:06:58 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 16:07:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 16:07:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 16:07:00 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 16:07:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-25 16:07:02 [scrapy.extensions.logstats] INFO: Crawled 11 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 16:07:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359> (referer: None)
2021-02-25 16:07:03 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 16:07:03 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 16:07:06 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> from <GET http://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm>
2021-02-25 16:07:15 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> from <GET https://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770>
2021-02-25 16:07:18 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://paleopolis.rediris.es/cg/18/08/index.html> from <GET https://www.sci-hub.ren/http://paleopolis.rediris.es/cg/18/08/index.html>
2021-02-25 16:07:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/> (referer: None)
2021-02-25 16:07:31 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 16:07:31 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 16:07:37 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/9274> (failed 4 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-02-25 16:07:37 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 16:07:37 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 149
2021-02-25 16:07:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/9274>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-02-25 16:07:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html> from <GET https://www.sci-hub.ren/10.1051/bsgf/2018019>
2021-02-25 16:07:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/ame048123> (failed 2 times): User timeout caused connection failure: Getting https://www.sci-hub.ren/10.3354/ame048123 took longer than 180.0 seconds..
2021-02-25 16:07:55 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://www.sci-hub.ren/> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 16:07:55 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 16:07:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 16:07:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.sci-hub.ren/>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-25 16:08:02 [scrapy.extensions.logstats] INFO: Crawled 13 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 16:08:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 16:08:12 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/ame/v82/n3/p253-264/> from <GET https://www.sci-hub.ren/10.3354/ame01895>
2021-02-25 16:08:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.5027/andgeoV46n1-3029> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 16:08:15 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://doi.org/10.3390/min9100000> from <GET https://www.sci-hub.ren/10.3390/min9100000>
2021-02-25 16:08:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/10.1055/s-0036-1596638> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 16:08:19 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 16:08:19 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 16:08:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/10.1055/s-0036-1596638>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-25 16:08:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 16:08:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://paleopolis.rediris.es/cg/18/08/index.html> (failed 1 times): 403 Forbidden
2021-02-25 16:08:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.5027/andgeoV47n1-3177> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 16:08:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 16:08:47 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 16:08:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 16:08:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-25 16:08:47 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-030-21614-6%5C_12>
2021-02-25 16:08:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.1089/ast.2019.2067> (referer: None)
2021-02-25 16:08:51 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 16:08:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 16:08:52 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded file from <GET https://cyber.bban.top/MTAuMTA4OS9hc3QuMjAxOS4yMDY3/10.1089%40ast.2019.2067.pdf?download=true> referred in <None>
2021-02-25 16:08:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.sci-hub.ren/10.1089/ast.2019.2067>
{'file_urls': ['https://cyber.bban.top/MTAuMTA4OS9hc3QuMjAxOS4yMDY3/10.1089%40ast.2019.2067.pdf?download=true'],
 'files': [{'checksum': '808358d065f4915b2156f3de1d6a1a24',
            'path': '000582254100001.pdf',
            'status': 'uptodate',
            'url': 'https://cyber.bban.top/MTAuMTA4OS9hc3QuMjAxOS4yMDY3/10.1089%40ast.2019.2067.pdf?download=true'}],
 'name': '000582254100001'}
2021-02-25 16:08:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 16:09:02 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2021-02-25 16:09:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html> (referer: None)
2021-02-25 16:09:16 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/> from <GET https://www.sci-hub.ren/10.3354/ame048123>
2021-02-25 16:09:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-25 16:09:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/ame/v82/n3/p253-264/> (referer: None)
2021-02-25 16:09:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1155/2020/6959532> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 16:09:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://doi.org/10.3390/min9100000> (referer: None)
2021-02-25 16:09:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.5027/andgeoV46n1-3029> (referer: None)
2021-02-25 16:09:43 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> from <GET https://www.sci-hub.ren/10.1111/1758-2229.12916>
2021-02-25 16:09:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/> (failed 1 times): User timeout caused connection failure: Getting https://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/ took longer than 180.0 seconds..
2021-02-25 16:09:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://paleopolis.rediris.es/cg/18/08/index.html> (failed 2 times): 403 Forbidden
2021-02-25 16:10:02 [scrapy.extensions.logstats] INFO: Crawled 19 pages (at 5 pages/min), scraped 1 items (at 0 items/min)
2021-02-25 16:10:06 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.aquaticinvasions.net/2016/issue3.html> from <GET https://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html>
2021-02-25 16:10:12 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486> from <GET https://www.sci-hub.ren/10.7306/gq.1547>
2021-02-25 16:10:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-25 16:10:19 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429> from <GET https://www.sci-hub.ren/10.1111/gbi.12429>
2021-02-25 16:10:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.1155/2020/6959532> (referer: None)
2021-02-25 16:10:38 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded file from <GET https://cyber.bban.top/MTAuMTE1NS8yMDIwLzY5NTk1MzI=/10.1155%402020%406959532.pdf?download=true> referred in <None>
2021-02-25 16:10:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.sci-hub.ren/10.1155/2020/6959532>
{'file_urls': ['https://cyber.bban.top/MTAuMTE1NS8yMDIwLzY5NTk1MzI=/10.1155%402020%406959532.pdf?download=true'],
 'files': [{'checksum': '6c02fcee70c30afc9791e2e93ddc95f4',
            'path': '000588326000002.pdf',
            'status': 'uptodate',
            'url': 'https://cyber.bban.top/MTAuMTE1NS8yMDIwLzY5NTk1MzI=/10.1155%402020%406959532.pdf?download=true'}],
 'name': '000588326000002'}
2021-02-25 16:10:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/> (referer: None)
2021-02-25 16:10:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> (referer: None)
2021-02-25 16:10:46 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> from <GET http://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916>
2021-02-25 16:10:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://paleopolis.rediris.es/cg/18/08/index.html> (failed 3 times): 403 Forbidden
2021-02-25 16:11:02 [scrapy.extensions.logstats] INFO: Crawled 23 pages (at 4 pages/min), scraped 2 items (at 1 items/min)
2021-02-25 16:11:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 16:11:22 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://www.aquaticinvasions.net/2016/issue3.html> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 16:11:22 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.aquaticinvasions.net/2016/issue3.html>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-25 16:11:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> (referer: None)
2021-02-25 16:11:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://paleopolis.rediris.es/cg/18/08/index.html> (failed 4 times): 403 Forbidden
2021-02-25 16:11:25 [scrapy.core.engine] DEBUG: Crawled (403) <GET http://paleopolis.rediris.es/cg/18/08/index.html> (referer: None)
2021-02-25 16:11:25 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 http://paleopolis.rediris.es/cg/18/08/index.html>: HTTP status code is not handled or not allowed
2021-02-25 16:11:27 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429> from <GET http://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429>
2021-02-25 16:11:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 16:11:41 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429?cookieSet=1> from <GET https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429>
2021-02-25 16:11:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 16:11:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/> (referer: None)
2021-02-25 16:12:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429?cookieSet=1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-02-25 16:12:02 [scrapy.extensions.logstats] INFO: Crawled 26 pages (at 3 pages/min), scraped 2 items (at 0 items/min)
2021-02-25 16:12:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429?cookieSet=1> from <GET http://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429?cookieSet=1>
2021-02-25 16:12:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 16:12:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429?cookieSet=1> (referer: None)
2021-02-25 16:12:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 16:12:46 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486> from <GET http://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486>
2021-02-25 16:12:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.5027/andgeoV47n1-3177> (failed 2 times): User timeout caused connection failure: Getting https://www.sci-hub.ren/10.5027/andgeoV47n1-3177 took longer than 180.0 seconds..
2021-02-25 16:13:02 [scrapy.extensions.logstats] INFO: Crawled 27 pages (at 1 pages/min), scraped 2 items (at 0 items/min)
2021-02-25 16:13:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.5027/andgeoV47n1-3177> (referer: None)
2021-02-25 16:13:07 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 16:13:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-25 16:13:07 [scrapy.core.engine] INFO: Closing spider (finished)
2021-02-25 16:13:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 49,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 36,
 'downloader/exception_type_count/twisted.internet.error.TimeoutError': 4,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 9,
 'downloader/request_bytes': 52907,
 'downloader/request_count': 126,
 'downloader/request_method_count/GET': 126,
 'downloader/response_bytes': 2327046,
 'downloader/response_count': 77,
 'downloader/response_status_count/200': 27,
 'downloader/response_status_count/301': 12,
 'downloader/response_status_count/302': 34,
 'downloader/response_status_count/403': 4,
 'elapsed_time_seconds': 785.223913,
 'file_count': 2,
 'file_status_count/uptodate': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 2, 25, 8, 13, 7, 447334),
 'httperror/response_ignored_count': 1,
 'httperror/response_ignored_status_count/403': 1,
 'item_scraped_count': 2,
 'log_count/DEBUG': 194,
 'log_count/ERROR': 18,
 'log_count/INFO': 22,
 'log_count/WARNING': 1,
 'memusage/max': 79020032,
 'memusage/startup': 68100096,
 'response_received_count': 28,
 'retry/count': 44,
 'retry/max_reached': 9,
 'retry/reason_count/403 Forbidden': 3,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 30,
 'retry/reason_count/twisted.internet.error.TimeoutError': 4,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 7,
 'scheduler/dequeued': 126,
 'scheduler/dequeued/memory': 126,
 'scheduler/enqueued': 126,
 'scheduler/enqueued/memory': 126,
 'spider_exceptions/NotSupported': 1,
 'start_time': datetime.datetime(2021, 2, 25, 8, 0, 2, 223421)}
2021-02-25 16:13:07 [scrapy.core.engine] INFO: Spider closed (finished)
2021-02-25 20:00:02 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: wos_crawl)
2021-02-25 20:00:02 [scrapy.utils.log] INFO: Versions: lxml 4.6.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.6.9 (default, Oct  8 2020, 12:12:24) - [GCC 8.4.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1i  8 Dec 2020), cryptography 3.3.1, Platform Linux-4.15.0-132-generic-x86_64-with-Ubuntu-18.04-bionic
2021-02-25 20:00:02 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2021-02-25 20:00:02 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wos_crawl',
 'COOKIES_ENABLED': False,
 'DOWNLOAD_DELAY': 5,
 'LOG_FILE': 'crawler.log',
 'NEWSPIDER_MODULE': 'wos_crawl.spiders',
 'RETRY_HTTP_CODES': [500, 503, 504, 400, 403, 404, 408],
 'RETRY_TIMES': 3,
 'SPIDER_MODULES': ['wos_crawl.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/88.0.4324.104 Safari/537.36'}
2021-02-25 20:00:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2021-02-25 20:00:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-02-25 20:00:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-02-25 20:00:02 [py.warnings] WARNING: /home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/pipelines/media.py:135: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2021-02-25 20:00:02 [scrapy.middleware] INFO: Enabled item pipelines:
['wos_crawl.pipelines.fileDown']
2021-02-25 20:00:02 [scrapy.core.engine] INFO: Spider opened
2021-02-25 20:00:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 20:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 20:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 20:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 20:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 20:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 20:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 144
2021-02-25 20:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 20:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 20:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 20:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 20:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 20:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 150
2021-02-25 20:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 20:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 144
2021-02-25 20:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 20:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 20:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 20:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 20:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 20:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-25 20:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 20:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 20:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 20:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 20:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 20:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 20:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 20:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 20:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 20:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 20:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 20:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 144
2021-02-25 20:00:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v16/n2/p131-141/> from <GET https://www.sci-hub.ren/10.3354/ame016131>
2021-02-25 20:00:08 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> from <GET https://www.sci-hub.ren/10.3354/ame021161>
2021-02-25 20:00:24 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf> from <GET https://www.sci-hub.ren/10.5327/Z2317-48892013000300004>
2021-02-25 20:00:24 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> from <GET https://www.sci-hub.ren/10.1360/02yd0178>
2021-02-25 20:00:33 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/> from <GET https://www.sci-hub.ren/10.3354/ame048123>
2021-02-25 20:00:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.3354/meps07087> (referer: None)
2021-02-25 20:00:39 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 20:00:39 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 144
2021-02-25 20:00:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.2485/jhtb.20.339> (referer: None)
2021-02-25 20:00:40 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 20:00:40 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 20:00:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf> from <GET https://www.sci-hub.ren/10.1344/105.000002051>
2021-02-25 20:00:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.7306/gq.1131> (referer: None)
2021-02-25 20:00:56 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 20:00:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 20:01:02 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 20:01:02 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page> from <GET https://www.sci-hub.ren/10.5139/IJASS.2014.15.4.419>
2021-02-25 20:01:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1344/105.000001770> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 20:01:09 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-319-04364-7%5C_131>
2021-02-25 20:01:16 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.5209/rev%5C_JIGE.2015.v41.n3.51568>
2021-02-25 20:01:22 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-319-24987-2%5C_6>
2021-02-25 20:01:27 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-319-24987-2%5C_26>
2021-02-25 20:01:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v16/n2/p131-141/> from <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v16/n2/p131-141/>
2021-02-25 20:01:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> (referer: None)
2021-02-25 20:01:38 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 20:01:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 20:01:45 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf> from <GET http://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf>
2021-02-25 20:01:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> from <GET https://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm>
2021-02-25 20:01:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/> from <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/>
2021-02-25 20:02:01 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html> from <GET https://www.sci-hub.ren/10.3391/ai.2016.11.3.04>
2021-02-25 20:02:02 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 20:02:12 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://paleoitalia.org> from <GET https://www.sci-hub.ren/10.4435/BSPI.2016.09>
2021-02-25 20:02:20 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://geojournals.pgi.gov.pl/asgp/article/view/25493> from <GET https://www.sci-hub.ren/10.14241/asgp.2016.011>
2021-02-25 20:02:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page> (failed 1 times): 403 Forbidden
2021-02-25 20:02:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf> from <GET http://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf>
2021-02-25 20:02:46 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/> from <GET http://www.sci-hub.ren/>
2021-02-25 20:02:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/> from <GET http://www.sci-hub.ren/>
2021-02-25 20:02:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1344/105.000001770> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 20:02:54 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/> from <GET http://www.sci-hub.ren/>
2021-02-25 20:03:02 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 20:03:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v16/n2/p131-141/> (referer: None)
2021-02-25 20:03:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 20:03:06 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 20:03:09 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/> from <GET http://www.sci-hub.ren/>
2021-02-25 20:03:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.2113/96.7.1595> (failed 1 times): User timeout caused connection failure: Getting https://www.sci-hub.ren/10.2113/96.7.1595 took longer than 180.0 seconds..
2021-02-25 20:03:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.1055/s-0036-1596638> (referer: None)
2021-02-25 20:03:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 20:03:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 20:03:20 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://bjg.siteoficial.ws/2013/n.3/d.pdf> from <GET https://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf>
2021-02-25 20:03:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 1 times): 404 Not Found
2021-02-25 20:03:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/> (referer: None)
2021-02-25 20:03:31 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 20:03:31 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 150
2021-02-25 20:03:43 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://paleoitalia.org> from <GET http://www.sci-hub.ren/http://paleoitalia.org>
2021-02-25 20:03:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-02-25 20:03:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://geojournals.pgi.gov.pl/asgp/article/view/25493> from <GET https://www.sci-hub.ren/https://geojournals.pgi.gov.pl/asgp/article/view/25493>
2021-02-25 20:03:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page> (failed 2 times): 403 Forbidden
2021-02-25 20:04:02 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 20:04:06 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.publicacions.ub.edu/doi/documents/2051.pdf> from <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf>
2021-02-25 20:04:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-25 20:04:11 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 20:04:11 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 150
2021-02-25 20:04:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-25 20:04:22 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 20:04:22 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 20:04:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-25 20:04:26 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 20:04:26 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 20:04:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1344/105.000001770> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 20:04:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-25 20:04:39 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 20:04:39 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 150
2021-02-25 20:04:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595> from <GET https://www.sci-hub.ren/10.2113/96.7.1595>
2021-02-25 20:04:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/meps12300> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 20:05:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 2 times): 404 Not Found
2021-02-25 20:05:02 [scrapy.extensions.logstats] INFO: Crawled 11 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 20:05:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3389/fmicb.2013.01359> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 20:05:21 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://paleoitalia.org/> from <GET https://www.sci-hub.ren/http://paleoitalia.org>
2021-02-25 20:05:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.4267/2042/68182> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 20:05:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page> (failed 3 times): 403 Forbidden
2021-02-25 20:05:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://geojournals.pgi.gov.pl/asgp/article/view/25493> (referer: None)
2021-02-25 20:05:34 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 20:05:34 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 150
2021-02-25 20:05:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 20:05:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> from <GET https://www.sci-hub.ren/10.4072/rbp.2018.3.01>
2021-02-25 20:05:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.publicacions.ub.edu/doi/documents/2051.pdf> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 20:06:02 [scrapy.extensions.logstats] INFO: Crawled 12 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 20:06:03 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html> from <GET https://www.sci-hub.ren/10.1051/bsgf/2018019>
2021-02-25 20:06:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/meps12741> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 20:06:16 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595> from <GET http://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595>
2021-02-25 20:06:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/10.1344/105.000001770> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 20:06:20 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 20:06:20 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 20:06:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/10.1344/105.000001770>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-25 20:06:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 3 times): 404 Not Found
2021-02-25 20:06:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.5027/andgeoV46n1-3029> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 20:06:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://paleoitalia.org/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 20:06:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/meps12300> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 20:06:48 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page> (failed 4 times): 403 Forbidden
2021-02-25 20:06:48 [scrapy.core.engine] DEBUG: Crawled (403) <GET http://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page> (referer: None)
2021-02-25 20:06:48 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 20:06:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 20:06:48 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 http://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page>: HTTP status code is not handled or not allowed
2021-02-25 20:06:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3389/fmicb.2013.01359> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 20:07:02 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html> from <GET http://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html>
2021-02-25 20:07:02 [scrapy.extensions.logstats] INFO: Crawled 13 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 20:07:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.4267/2042/68182> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 20:07:08 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> from <GET https://www.sci-hub.ren/https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf>
2021-02-25 20:07:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/ame01895> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 20:07:27 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/> from <GET https://www.sci-hub.ren/10.3354/meps12741>
2021-02-25 20:07:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.publicacions.ub.edu/doi/documents/2051.pdf> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 20:07:39 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 4 times): 404 Not Found
2021-02-25 20:07:39 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (referer: None)
2021-02-25 20:07:39 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 20:07:39 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 20:07:39 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.scichina.com/2004/yk/yd/0404/yd0347.stm>: HTTP status code is not handled or not allowed
2021-02-25 20:07:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.5027/andgeoV46n1-3029> (referer: None)
2021-02-25 20:07:46 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 20:07:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 20:07:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 20:07:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3390/min9100000> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 20:07:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bjg.siteoficial.ws/2013/n.3/d.pdf> (failed 1 times): User timeout caused connection failure: Getting http://bjg.siteoficial.ws/2013/n.3/d.pdf took longer than 180.0 seconds..
2021-02-25 20:08:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.5027/andgeoV47n1-3177> (referer: None)
2021-02-25 20:08:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 20:08:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-25 20:08:02 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 20:08:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://paleoitalia.org/> (referer: None)
2021-02-25 20:08:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 20:08:05 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 20:08:05 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html> from <GET http://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html>
2021-02-25 20:08:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/meps12300> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 20:08:24 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://paleopolis.rediris.es/cg/18/08/index.html> from <GET https://www.sci-hub.ren/10.4267/2042/68182>
2021-02-25 20:08:26 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359> from <GET https://www.sci-hub.ren/10.3389/fmicb.2013.01359>
2021-02-25 20:08:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 20:08:38 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://www.int-res.com/abstracts/ame/v82/n3/p253-264/> from <GET https://www.sci-hub.ren/10.3354/ame01895>
2021-02-25 20:08:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/> from <GET http://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/>
2021-02-25 20:08:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-030-21614-6%5C_12>
2021-02-25 20:09:02 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2021-02-25 20:09:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1089/ast.2019.2067> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 20:09:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.1155/2020/6959532> (referer: None)
2021-02-25 20:09:30 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 20:09:30 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-25 20:09:30 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded file from <GET https://cyber.bban.top/MTAuMTE1NS8yMDIwLzY5NTk1MzI=/10.1155%402020%406959532.pdf?download=true> referred in <None>
2021-02-25 20:09:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.sci-hub.ren/10.1155/2020/6959532>
{'file_urls': ['https://cyber.bban.top/MTAuMTE1NS8yMDIwLzY5NTk1MzI=/10.1155%402020%406959532.pdf?download=true'],
 'files': [{'checksum': '6c02fcee70c30afc9791e2e93ddc95f4',
            'path': '000588326000002.pdf',
            'status': 'uptodate',
            'url': 'https://cyber.bban.top/MTAuMTE1NS8yMDIwLzY5NTk1MzI=/10.1155%402020%406959532.pdf?download=true'}],
 'name': '000588326000002'}
2021-02-25 20:09:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 20:09:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> (referer: None)
2021-02-25 20:09:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3390/min9100000> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 20:09:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> from <GET https://www.sci-hub.ren/10.1111/1758-2229.12916>
2021-02-25 20:09:40 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-25 20:09:40 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-25 20:09:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html> (referer: None)
2021-02-25 20:09:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://paleopolis.rediris.es/cg/18/08/index.html> from <GET http://www.sci-hub.ren/http://paleopolis.rediris.es/cg/18/08/index.html>
2021-02-25 20:10:02 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 3 pages/min), scraped 1 items (at 1 items/min)
2021-02-25 20:10:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/10.3354/meps12300> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 20:10:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/10.3354/meps12300>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-25 20:10:15 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/ame/v82/n3/p253-264/> from <GET http://www.sci-hub.ren/https://www.int-res.com/abstracts/ame/v82/n3/p253-264/>
2021-02-25 20:10:18 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.aquaticinvasions.net/2016/issue3.html> from <GET https://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html>
2021-02-25 20:10:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/> (referer: None)
2021-02-25 20:10:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 20:10:27 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/> from <GET http://www.sci-hub.ren/>
2021-02-25 20:10:42 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486> from <GET https://www.sci-hub.ren/10.7306/gq.1547>
2021-02-25 20:10:47 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://economicgeology.org/lookup/doi/10.2113/96.7.1595> from <GET https://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595>
2021-02-25 20:10:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> (failed 1 times): 403 Forbidden
2021-02-25 20:10:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1089/ast.2019.2067> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 20:11:02 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 1 pages/min), scraped 1 items (at 0 items/min)
2021-02-25 20:11:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://doi.org/10.3390/min9100000> from <GET https://www.sci-hub.ren/10.3390/min9100000>
2021-02-25 20:11:13 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://paleopolis.rediris.es/cg/18/08/index.html> from <GET https://www.sci-hub.ren/http://paleopolis.rediris.es/cg/18/08/index.html>
2021-02-25 20:11:21 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429> from <GET https://www.sci-hub.ren/10.1111/gbi.12429>
2021-02-25 20:11:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/ame/v82/n3/p253-264/> (referer: None)
2021-02-25 20:11:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://www.aquaticinvasions.net/2016/issue3.html> (failed 4 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-02-25 20:11:29 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.aquaticinvasions.net/2016/issue3.html>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-02-25 20:11:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-25 20:11:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.publicacions.ub.edu/doi/documents/2051.pdf> (failed 3 times): User timeout caused connection failure: Getting http://www.publicacions.ub.edu/doi/documents/2051.pdf took longer than 180.0 seconds..
2021-02-25 20:11:52 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 20:11:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-25 20:11:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> (failed 2 times): 403 Forbidden
2021-02-25 20:11:55 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://economicgeology.org/lookup/doi/10.2113/96.7.1595> (failed 4 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-02-25 20:11:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://economicgeology.org/lookup/doi/10.2113/96.7.1595>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-02-25 20:12:01 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://gq.pgi.gov.pl/article/view/28486> from <GET https://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486>
2021-02-25 20:12:02 [scrapy.extensions.logstats] INFO: Crawled 23 pages (at 2 pages/min), scraped 1 items (at 0 items/min)
2021-02-25 20:12:06 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://doi.org/10.3390/min9100000> from <GET http://www.sci-hub.ren/https://doi.org/10.3390/min9100000>
2021-02-25 20:12:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://paleopolis.rediris.es/cg/18/08/index.html> (referer: None)
2021-02-25 20:12:17 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429?cookieSet=1> from <GET https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429>
2021-02-25 20:12:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1089/ast.2019.2067> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 20:12:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bjg.siteoficial.ws/2013/n.3/d.pdf> (failed 2 times): User timeout caused connection failure: Getting http://bjg.siteoficial.ws/2013/n.3/d.pdf took longer than 180.0 seconds..
2021-02-25 20:12:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> (failed 3 times): 403 Forbidden
2021-02-25 20:12:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://gq.pgi.gov.pl/article/view/28486> (referer: None)
2021-02-25 20:12:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://doi.org/10.3390/min9100000> (referer: None)
2021-02-25 20:12:44 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://www.publicacions.ub.edu/doi/documents/2051.pdf> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 20:12:44 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.publicacions.ub.edu/doi/documents/2051.pdf>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-25 20:12:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429?cookieSet=1> (referer: None)
2021-02-25 20:13:02 [scrapy.extensions.logstats] INFO: Crawled 27 pages (at 4 pages/min), scraped 1 items (at 0 items/min)
2021-02-25 20:13:05 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> (failed 4 times): 403 Forbidden
2021-02-25 20:13:05 [scrapy.core.engine] DEBUG: Crawled (403) <GET http://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> (referer: None)
2021-02-25 20:13:05 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 http://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916>: HTTP status code is not handled or not allowed
2021-02-25 20:13:13 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/10.1089/ast.2019.2067> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-25 20:13:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/10.1089/ast.2019.2067>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-25 20:14:02 [scrapy.extensions.logstats] INFO: Crawled 28 pages (at 1 pages/min), scraped 1 items (at 0 items/min)
2021-02-25 20:15:02 [scrapy.extensions.logstats] INFO: Crawled 28 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2021-02-25 20:15:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bjg.siteoficial.ws/2013/n.3/d.pdf> (failed 3 times): User timeout caused connection failure: Getting http://bjg.siteoficial.ws/2013/n.3/d.pdf took longer than 180.0 seconds..
2021-02-25 20:16:02 [scrapy.extensions.logstats] INFO: Crawled 28 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2021-02-25 20:17:02 [scrapy.extensions.logstats] INFO: Crawled 28 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2021-02-25 20:18:02 [scrapy.extensions.logstats] INFO: Crawled 28 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2021-02-25 20:18:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://bjg.siteoficial.ws/2013/n.3/d.pdf> (failed 4 times): User timeout caused connection failure: Getting http://bjg.siteoficial.ws/2013/n.3/d.pdf took longer than 180.0 seconds..
2021-02-25 20:18:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://bjg.siteoficial.ws/2013/n.3/d.pdf>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/twisted/internet/defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/twisted/python/failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py", line 375, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://bjg.siteoficial.ws/2013/n.3/d.pdf took longer than 180.0 seconds..
2021-02-25 20:18:59 [scrapy.core.engine] INFO: Closing spider (finished)
2021-02-25 20:18:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 40,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 31,
 'downloader/exception_type_count/twisted.internet.error.TimeoutError': 6,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 3,
 'downloader/request_bytes': 54716,
 'downloader/request_count': 131,
 'downloader/request_method_count/GET': 131,
 'downloader/response_bytes': 17953840,
 'downloader/response_count': 91,
 'downloader/response_status_count/200': 25,
 'downloader/response_status_count/301': 17,
 'downloader/response_status_count/302': 37,
 'downloader/response_status_count/403': 8,
 'downloader/response_status_count/404': 4,
 'elapsed_time_seconds': 1136.940624,
 'file_count': 1,
 'file_status_count/uptodate': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 2, 25, 12, 18, 59, 527449),
 'httperror/response_ignored_count': 3,
 'httperror/response_ignored_status_count/403': 2,
 'httperror/response_ignored_status_count/404': 1,
 'item_scraped_count': 1,
 'log_count/DEBUG': 197,
 'log_count/ERROR': 19,
 'log_count/INFO': 29,
 'log_count/WARNING': 1,
 'memusage/max': 755712000,
 'memusage/startup': 68218880,
 'response_received_count': 28,
 'retry/count': 41,
 'retry/max_reached': 11,
 'retry/reason_count/403 Forbidden': 6,
 'retry/reason_count/404 Not Found': 3,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 26,
 'retry/reason_count/twisted.internet.error.TimeoutError': 5,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 1,
 'scheduler/dequeued': 131,
 'scheduler/dequeued/memory': 131,
 'scheduler/enqueued': 131,
 'scheduler/enqueued/memory': 131,
 'start_time': datetime.datetime(2021, 2, 25, 12, 0, 2, 586825)}
2021-02-25 20:18:59 [scrapy.core.engine] INFO: Spider closed (finished)
2021-02-26 00:00:01 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: wos_crawl)
2021-02-26 00:00:01 [scrapy.utils.log] INFO: Versions: lxml 4.6.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.6.9 (default, Oct  8 2020, 12:12:24) - [GCC 8.4.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1i  8 Dec 2020), cryptography 3.3.1, Platform Linux-4.15.0-132-generic-x86_64-with-Ubuntu-18.04-bionic
2021-02-26 00:00:01 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2021-02-26 00:00:01 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wos_crawl',
 'COOKIES_ENABLED': False,
 'DOWNLOAD_DELAY': 5,
 'LOG_FILE': 'crawler.log',
 'NEWSPIDER_MODULE': 'wos_crawl.spiders',
 'RETRY_HTTP_CODES': [500, 503, 504, 400, 403, 404, 408],
 'RETRY_TIMES': 3,
 'SPIDER_MODULES': ['wos_crawl.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/88.0.4324.104 Safari/537.36'}
2021-02-26 00:00:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2021-02-26 00:00:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-02-26 00:00:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-02-26 00:00:01 [py.warnings] WARNING: /home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/pipelines/media.py:135: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2021-02-26 00:00:01 [scrapy.middleware] INFO: Enabled item pipelines:
['wos_crawl.pipelines.fileDown']
2021-02-26 00:00:01 [scrapy.core.engine] INFO: Spider opened
2021-02-26 00:00:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 00:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 00:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 00:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 00:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-26 00:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 00:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 00:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 00:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 00:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 00:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 00:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 00:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 00:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 00:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 00:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 00:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 149
2021-02-26 00:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 00:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 00:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 00:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 149
2021-02-26 00:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 00:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 149
2021-02-26 00:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 00:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 00:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 00:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 00:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 00:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 00:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 00:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 00:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 00:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 00:00:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v16/n2/p131-141/> from <GET https://www.sci-hub.ren/10.3354/ame016131>
2021-02-26 00:00:13 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> from <GET https://www.sci-hub.ren/10.3354/ame021161>
2021-02-26 00:00:22 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595> from <GET https://www.sci-hub.ren/10.2113/96.7.1595>
2021-02-26 00:00:28 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf> from <GET https://www.sci-hub.ren/10.5327/Z2317-48892013000300004>
2021-02-26 00:00:31 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> from <GET https://www.sci-hub.ren/10.1360/02yd0178>
2021-02-26 00:00:46 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v349/p23-32/> from <GET https://www.sci-hub.ren/10.3354/meps07087>
2021-02-26 00:00:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.2485/jhtb.20.339> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 00:00:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> from <GET https://www.sci-hub.ren/10.1344/105.000001770>
2021-02-26 00:00:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/ame048123> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 00:01:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 00:01:05 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf> from <GET https://www.sci-hub.ren/10.1344/105.000002051>
2021-02-26 00:01:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.7306/gq.1131> (referer: None)
2021-02-26 00:01:11 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 00:01:11 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 00:01:17 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page> from <GET https://www.sci-hub.ren/10.5139/IJASS.2014.15.4.419>
2021-02-26 00:01:25 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-319-04364-7%5C_131>
2021-02-26 00:01:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.5209/rev%5C_JIGE.2015.v41.n3.51568>
2021-02-26 00:01:41 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v16/n2/p131-141/> from <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v16/n2/p131-141/>
2021-02-26 00:01:46 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-319-24987-2%5C_26>
2021-02-26 00:01:46 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-319-24987-2%5C_6>
2021-02-26 00:01:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> from <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/>
2021-02-26 00:01:58 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595> from <GET http://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595>
2021-02-26 00:02:00 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf> from <GET http://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf>
2021-02-26 00:02:01 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 00:02:07 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> from <GET https://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm>
2021-02-26 00:02:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v349/p23-32/> (referer: None)
2021-02-26 00:02:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 00:02:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 00:02:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.2485/jhtb.20.339> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 00:02:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> (failed 1 times): 403 Forbidden
2021-02-26 00:02:35 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/> from <GET https://www.sci-hub.ren/10.3354/ame048123>
2021-02-26 00:02:38 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf> from <GET http://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf>
2021-02-26 00:02:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html> from <GET https://www.sci-hub.ren/10.3391/ai.2016.11.3.04>
2021-02-26 00:02:53 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://koreascience.or.kr/article/JAKO201404065095388.page> from <GET https://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page>
2021-02-26 00:02:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-26 00:02:59 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 00:02:59 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 00:03:01 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 00:03:09 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/> from <GET http://www.sci-hub.ren/>
2021-02-26 00:03:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v16/n2/p131-141/> (referer: None)
2021-02-26 00:03:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 00:03:12 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-26 00:03:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-26 00:03:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 00:03:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 00:03:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2021-02-26 00:03:38 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://economicgeology.org/lookup/doi/10.2113/96.7.1595> from <GET https://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595>
2021-02-26 00:03:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://bjg.siteoficial.ws/2013/n.3/d.pdf> from <GET https://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf>
2021-02-26 00:03:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 1 times): 404 Not Found
2021-02-26 00:03:48 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://paleoitalia.org> from <GET https://www.sci-hub.ren/10.4435/BSPI.2016.09>
2021-02-26 00:03:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 00:03:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.2485/jhtb.20.339> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 00:03:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> (failed 2 times): 403 Forbidden
2021-02-26 00:04:01 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 00:04:03 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/> from <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/>
2021-02-26 00:04:10 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.publicacions.ub.edu/doi/documents/2051.pdf> from <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf>
2021-02-26 00:04:18 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html> from <GET http://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html>
2021-02-26 00:04:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://koreascience.or.kr/article/JAKO201404065095388.page> (failed 1 times): 403 Forbidden
2021-02-26 00:04:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://geojournals.pgi.gov.pl/asgp/article/view/25493> from <GET https://www.sci-hub.ren/10.14241/asgp.2016.011>
2021-02-26 00:04:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-26 00:04:40 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 00:04:40 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 149
2021-02-26 00:04:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.1055/s-0036-1596638> (referer: None)
2021-02-26 00:04:42 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 00:04:42 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 00:04:52 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/> from <GET https://www.sci-hub.ren/10.3354/meps12300>
2021-02-26 00:05:01 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 00:05:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://economicgeology.org/lookup/doi/10.2113/96.7.1595> (failed 1 times): 404 Not Found
2021-02-26 00:05:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 2 times): 404 Not Found
2021-02-26 00:05:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 00:05:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://paleoitalia.org> (failed 1 times): 403 Forbidden
2021-02-26 00:05:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://bjg.siteoficial.ws/2013/n.3/d.pdf> (referer: None)
2021-02-26 00:05:14 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 00:05:14 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 00:05:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://bjg.siteoficial.ws/2013/n.3/d.pdf> (referer: None)
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/python.py", line 353, in __next__
    return next(self.data)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/python.py", line 353, in __next__
    return next(self.data)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/wos_crawl/wos_crawl/spiders/wos_spider.py", line 39, in parse
    detail_url_list = response.xpath('//*[@id="buttons"]/ul/li[2]/a/@onclick')
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/http/response/__init__.py", line 120, in xpath
    raise NotSupported("Response content isn't text")
scrapy.exceptions.NotSupported: Response content isn't text
2021-02-26 00:05:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> (referer: None)
2021-02-26 00:05:20 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 00:05:20 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 00:05:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.2485/jhtb.20.339> (referer: None)
2021-02-26 00:05:26 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 00:05:26 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 00:05:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> (failed 3 times): 403 Forbidden
2021-02-26 00:05:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/> (referer: None)
2021-02-26 00:05:43 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 00:05:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 00:05:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.aquaticinvasions.net/2016/issue3.html> from <GET https://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html>
2021-02-26 00:05:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://koreascience.or.kr/article/JAKO201404065095388.page> (failed 2 times): 403 Forbidden
2021-02-26 00:06:01 [scrapy.extensions.logstats] INFO: Crawled 11 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 00:06:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://geojournals.pgi.gov.pl/asgp/article/view/25493> from <GET https://www.sci-hub.ren/https://geojournals.pgi.gov.pl/asgp/article/view/25493>
2021-02-26 00:06:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.publicacions.ub.edu/doi/documents/2051.pdf> (referer: None)
2021-02-26 00:06:11 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 00:06:11 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-26 00:06:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.publicacions.ub.edu/doi/documents/2051.pdf> (referer: None)
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/python.py", line 353, in __next__
    return next(self.data)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/python.py", line 353, in __next__
    return next(self.data)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/wos_crawl/wos_crawl/spiders/wos_spider.py", line 39, in parse
    detail_url_list = response.xpath('//*[@id="buttons"]/ul/li[2]/a/@onclick')
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/http/response/__init__.py", line 120, in xpath
    raise NotSupported("Response content isn't text")
scrapy.exceptions.NotSupported: Response content isn't text
2021-02-26 00:06:12 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359> from <GET https://www.sci-hub.ren/10.3389/fmicb.2013.01359>
2021-02-26 00:06:16 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://paleopolis.rediris.es/cg/18/08/index.html> from <GET https://www.sci-hub.ren/10.4267/2042/68182>
2021-02-26 00:06:21 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/> from <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/>
2021-02-26 00:06:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://economicgeology.org/lookup/doi/10.2113/96.7.1595> (failed 2 times): 404 Not Found
2021-02-26 00:06:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 3 times): 404 Not Found
2021-02-26 00:06:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://paleoitalia.org> (failed 2 times): 403 Forbidden
2021-02-26 00:06:53 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/> from <GET http://www.sci-hub.ren/>
2021-02-26 00:06:56 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/> from <GET https://www.sci-hub.ren/10.3354/meps12741>
2021-02-26 00:07:01 [scrapy.extensions.logstats] INFO: Crawled 12 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 00:07:02 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> from <GET https://www.sci-hub.ren/10.4072/rbp.2018.3.01>
2021-02-26 00:07:06 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html> from <GET https://www.sci-hub.ren/10.1051/bsgf/2018019>
2021-02-26 00:07:13 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> (failed 4 times): 403 Forbidden
2021-02-26 00:07:13 [scrapy.core.engine] DEBUG: Crawled (403) <GET http://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> (referer: None)
2021-02-26 00:07:13 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 00:07:13 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 00:07:13 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 http://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770>: HTTP status code is not handled or not allowed
2021-02-26 00:07:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.5027/andgeoV46n1-3029> (referer: None)
2021-02-26 00:07:20 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 00:07:20 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 00:07:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.aquaticinvasions.net/2016/issue3.html> (referer: None)
2021-02-26 00:07:28 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 00:07:28 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 00:07:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://koreascience.or.kr/article/JAKO201404065095388.page> (failed 3 times): 403 Forbidden
2021-02-26 00:07:45 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/ame/v82/n3/p253-264/> from <GET https://www.sci-hub.ren/10.3354/ame01895>
2021-02-26 00:07:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359> from <GET http://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359>
2021-02-26 00:08:00 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://paleopolis.rediris.es/cg/18/08/index.html> from <GET https://www.sci-hub.ren/http://paleopolis.rediris.es/cg/18/08/index.html>
2021-02-26 00:08:01 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 00:08:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/> (referer: None)
2021-02-26 00:08:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 00:08:05 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 00:08:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://economicgeology.org/lookup/doi/10.2113/96.7.1595> (failed 3 times): 404 Not Found
2021-02-26 00:08:13 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 4 times): 404 Not Found
2021-02-26 00:08:13 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (referer: None)
2021-02-26 00:08:13 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 00:08:13 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 00:08:13 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.scichina.com/2004/yk/yd/0404/yd0347.stm>: HTTP status code is not handled or not allowed
2021-02-26 00:08:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://paleoitalia.org> (failed 3 times): 403 Forbidden
2021-02-26 00:08:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/> (referer: None)
2021-02-26 00:08:38 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 00:08:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 00:08:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://geojournals.pgi.gov.pl/asgp/article/view/25493> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-02-26 00:08:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-26 00:08:47 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 00:08:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 00:08:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 00:08:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.5027/andgeoV47n1-3177> (referer: None)
2021-02-26 00:08:59 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 00:08:59 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 00:08:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html> (referer: None)
2021-02-26 00:09:01 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 00:09:01 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-030-21614-6%5C_12>
2021-02-26 00:09:05 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://koreascience.or.kr/article/JAKO201404065095388.page> (failed 4 times): 403 Forbidden
2021-02-26 00:09:05 [scrapy.core.engine] DEBUG: Crawled (403) <GET http://koreascience.or.kr/article/JAKO201404065095388.page> (referer: None)
2021-02-26 00:09:06 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 http://koreascience.or.kr/article/JAKO201404065095388.page>: HTTP status code is not handled or not allowed
2021-02-26 00:09:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3390/min9100000> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 00:09:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/ame/v82/n3/p253-264/> (referer: None)
2021-02-26 00:09:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359> (referer: None)
2021-02-26 00:09:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://paleopolis.rediris.es/cg/18/08/index.html> (failed 1 times): 403 Forbidden
2021-02-26 00:09:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.1089/ast.2019.2067> (referer: None)
2021-02-26 00:09:29 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded file from <GET https://cyber.bban.top/MTAuMTA4OS9hc3QuMjAxOS4yMDY3/10.1089%40ast.2019.2067.pdf?download=true> referred in <None>
2021-02-26 00:09:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.sci-hub.ren/10.1089/ast.2019.2067>
{'file_urls': ['https://cyber.bban.top/MTAuMTA4OS9hc3QuMjAxOS4yMDY3/10.1089%40ast.2019.2067.pdf?download=true'],
 'files': [{'checksum': '808358d065f4915b2156f3de1d6a1a24',
            'path': '000582254100001.pdf',
            'status': 'uptodate',
            'url': 'https://cyber.bban.top/MTAuMTA4OS9hc3QuMjAxOS4yMDY3/10.1089%40ast.2019.2067.pdf?download=true'}],
 'name': '000582254100001'}
2021-02-26 00:09:37 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://economicgeology.org/lookup/doi/10.2113/96.7.1595> (failed 4 times): 404 Not Found
2021-02-26 00:09:37 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://economicgeology.org/lookup/doi/10.2113/96.7.1595> (referer: None)
2021-02-26 00:09:37 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://economicgeology.org/lookup/doi/10.2113/96.7.1595>: HTTP status code is not handled or not allowed
2021-02-26 00:09:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.1155/2020/6959532> (referer: None)
2021-02-26 00:09:44 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded file from <GET https://cyber.bban.top/MTAuMTE1NS8yMDIwLzY5NTk1MzI=/10.1155%402020%406959532.pdf?download=true> referred in <None>
2021-02-26 00:09:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.sci-hub.ren/10.1155/2020/6959532>
{'file_urls': ['https://cyber.bban.top/MTAuMTE1NS8yMDIwLzY5NTk1MzI=/10.1155%402020%406959532.pdf?download=true'],
 'files': [{'checksum': '6c02fcee70c30afc9791e2e93ddc95f4',
            'path': '000588326000002.pdf',
            'status': 'uptodate',
            'url': 'https://cyber.bban.top/MTAuMTE1NS8yMDIwLzY5NTk1MzI=/10.1155%402020%406959532.pdf?download=true'}],
 'name': '000588326000002'}
2021-02-26 00:09:50 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://www.sci-hub.ren/http://paleoitalia.org> (failed 4 times): 403 Forbidden
2021-02-26 00:09:50 [scrapy.core.engine] DEBUG: Crawled (403) <GET http://www.sci-hub.ren/http://paleoitalia.org> (referer: None)
2021-02-26 00:09:50 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 http://www.sci-hub.ren/http://paleoitalia.org>: HTTP status code is not handled or not allowed
2021-02-26 00:09:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> from <GET https://www.sci-hub.ren/10.1111/1758-2229.12916>
2021-02-26 00:10:01 [scrapy.extensions.logstats] INFO: Crawled 28 pages (at 7 pages/min), scraped 2 items (at 2 items/min)
2021-02-26 00:10:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://geojournals.pgi.gov.pl/asgp/article/view/25493> (referer: None)
2021-02-26 00:10:09 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486> from <GET https://www.sci-hub.ren/10.7306/gq.1547>
2021-02-26 00:10:14 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> from <GET https://www.sci-hub.ren/https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf>
2021-02-26 00:10:16 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429> from <GET https://www.sci-hub.ren/10.1111/gbi.12429>
2021-02-26 00:10:23 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/> from <GET http://www.sci-hub.ren/>
2021-02-26 00:10:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://paleopolis.rediris.es/cg/18/08/index.html> (failed 2 times): 403 Forbidden
2021-02-26 00:10:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> (referer: None)
2021-02-26 00:10:52 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429> from <GET http://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429>
2021-02-26 00:10:55 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://gq.pgi.gov.pl/article/view/28486> from <GET https://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486>
2021-02-26 00:11:01 [scrapy.extensions.logstats] INFO: Crawled 30 pages (at 2 pages/min), scraped 2 items (at 0 items/min)
2021-02-26 00:11:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-26 00:11:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://paleopolis.rediris.es/cg/18/08/index.html> (failed 3 times): 403 Forbidden
2021-02-26 00:11:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 00:11:11 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429?cookieSet=1> from <GET https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429>
2021-02-26 00:11:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://paleopolis.rediris.es/cg/18/08/index.html> (failed 4 times): 403 Forbidden
2021-02-26 00:11:20 [scrapy.core.engine] DEBUG: Crawled (403) <GET http://paleopolis.rediris.es/cg/18/08/index.html> (referer: None)
2021-02-26 00:11:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://gq.pgi.gov.pl/article/view/28486> (referer: None)
2021-02-26 00:11:21 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 http://paleopolis.rediris.es/cg/18/08/index.html>: HTTP status code is not handled or not allowed
2021-02-26 00:11:35 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429?cookieSet=1> from <GET http://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429?cookieSet=1>
2021-02-26 00:11:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429?cookieSet=1> (referer: None)
2021-02-26 00:12:01 [scrapy.extensions.logstats] INFO: Crawled 34 pages (at 4 pages/min), scraped 2 items (at 0 items/min)
2021-02-26 00:13:01 [scrapy.extensions.logstats] INFO: Crawled 34 pages (at 0 pages/min), scraped 2 items (at 0 items/min)
2021-02-26 00:13:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3390/min9100000> (failed 2 times): User timeout caused connection failure: Getting https://www.sci-hub.ren/10.3390/min9100000 took longer than 180.0 seconds..
2021-02-26 00:13:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3390/min9100000> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 00:13:58 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://doi.org/10.3390/min9100000> from <GET https://www.sci-hub.ren/10.3390/min9100000>
2021-02-26 00:14:01 [scrapy.extensions.logstats] INFO: Crawled 34 pages (at 0 pages/min), scraped 2 items (at 0 items/min)
2021-02-26 00:14:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://www.sci-hub.ren/https://doi.org/10.3390/min9100000> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 00:14:19 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.sci-hub.ren/https://doi.org/10.3390/min9100000>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-26 00:14:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> (failed 3 times): User timeout caused connection failure: Getting https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf took longer than 180.0 seconds..
2021-02-26 00:15:01 [scrapy.extensions.logstats] INFO: Crawled 34 pages (at 0 pages/min), scraped 2 items (at 0 items/min)
2021-02-26 00:16:01 [scrapy.extensions.logstats] INFO: Crawled 34 pages (at 0 pages/min), scraped 2 items (at 0 items/min)
2021-02-26 00:17:01 [scrapy.extensions.logstats] INFO: Crawled 34 pages (at 0 pages/min), scraped 2 items (at 0 items/min)
2021-02-26 00:17:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> (failed 4 times): User timeout caused connection failure: Getting https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf took longer than 180.0 seconds..
2021-02-26 00:17:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/twisted/internet/defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/twisted/python/failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py", line 375, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf took longer than 180.0 seconds..
2021-02-26 00:17:27 [scrapy.core.engine] INFO: Closing spider (finished)
2021-02-26 00:17:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 16,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 11,
 'downloader/exception_type_count/twisted.internet.error.TimeoutError': 3,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 2,
 'downloader/request_bytes': 51110,
 'downloader/request_count': 122,
 'downloader/request_method_count/GET': 122,
 'downloader/response_bytes': 4614214,
 'downloader/response_count': 106,
 'downloader/response_status_count/200': 28,
 'downloader/response_status_count/301': 14,
 'downloader/response_status_count/302': 40,
 'downloader/response_status_count/403': 16,
 'downloader/response_status_count/404': 8,
 'elapsed_time_seconds': 1046.003264,
 'file_count': 2,
 'file_status_count/uptodate': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 2, 25, 16, 17, 27, 704239),
 'httperror/response_ignored_count': 6,
 'httperror/response_ignored_status_count/403': 4,
 'httperror/response_ignored_status_count/404': 2,
 'item_scraped_count': 2,
 'log_count/DEBUG': 196,
 'log_count/ERROR': 12,
 'log_count/INFO': 31,
 'log_count/WARNING': 1,
 'memusage/max': 83542016,
 'memusage/startup': 68042752,
 'response_received_count': 34,
 'retry/count': 32,
 'retry/max_reached': 8,
 'retry/reason_count/403 Forbidden': 12,
 'retry/reason_count/404 Not Found': 6,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 10,
 'retry/reason_count/twisted.internet.error.TimeoutError': 2,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 2,
 'scheduler/dequeued': 122,
 'scheduler/dequeued/memory': 122,
 'scheduler/enqueued': 122,
 'scheduler/enqueued/memory': 122,
 'spider_exceptions/NotSupported': 2,
 'start_time': datetime.datetime(2021, 2, 25, 16, 0, 1, 700975)}
2021-02-26 00:17:27 [scrapy.core.engine] INFO: Spider closed (finished)
2021-02-26 04:00:01 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: wos_crawl)
2021-02-26 04:00:01 [scrapy.utils.log] INFO: Versions: lxml 4.6.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.6.9 (default, Oct  8 2020, 12:12:24) - [GCC 8.4.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1i  8 Dec 2020), cryptography 3.3.1, Platform Linux-4.15.0-132-generic-x86_64-with-Ubuntu-18.04-bionic
2021-02-26 04:00:01 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2021-02-26 04:00:01 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wos_crawl',
 'COOKIES_ENABLED': False,
 'DOWNLOAD_DELAY': 5,
 'LOG_FILE': 'crawler.log',
 'NEWSPIDER_MODULE': 'wos_crawl.spiders',
 'RETRY_HTTP_CODES': [500, 503, 504, 400, 403, 404, 408],
 'RETRY_TIMES': 3,
 'SPIDER_MODULES': ['wos_crawl.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/88.0.4324.104 Safari/537.36'}
2021-02-26 04:00:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2021-02-26 04:00:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-02-26 04:00:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-02-26 04:00:01 [py.warnings] WARNING: /home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/pipelines/media.py:135: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2021-02-26 04:00:01 [scrapy.middleware] INFO: Enabled item pipelines:
['wos_crawl.pipelines.fileDown']
2021-02-26 04:00:01 [scrapy.core.engine] INFO: Spider opened
2021-02-26 04:00:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 04:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 04:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-26 04:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 04:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-26 04:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 04:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 149
2021-02-26 04:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 04:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 04:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 04:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 149
2021-02-26 04:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 04:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-26 04:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 04:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-26 04:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 04:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 04:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 04:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 04:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 04:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 149
2021-02-26 04:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 04:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-26 04:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 04:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 04:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 04:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-26 04:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 04:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-26 04:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 04:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-26 04:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 04:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-26 04:00:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/ame016131> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:00:23 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> from <GET https://www.sci-hub.ren/10.3354/ame021161>
2021-02-26 04:00:27 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> from <GET https://www.sci-hub.ren/10.1360/02yd0178>
2021-02-26 04:00:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.2113/96.7.1595> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:00:36 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/> from <GET https://www.sci-hub.ren/10.3354/ame048123>
2021-02-26 04:00:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.3354/meps07087> (referer: None)
2021-02-26 04:00:38 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 04:00:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 144
2021-02-26 04:00:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.5327/Z2317-48892013000300004> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:00:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.2485/jhtb.20.339> (referer: None)
2021-02-26 04:00:45 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 04:00:45 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 149
2021-02-26 04:00:53 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> from <GET https://www.sci-hub.ren/10.1344/105.000001770>
2021-02-26 04:00:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf> from <GET https://www.sci-hub.ren/10.1344/105.000002051>
2021-02-26 04:01:01 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 04:01:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.7306/gq.1131> (referer: None)
2021-02-26 04:01:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 04:01:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 04:01:11 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page> from <GET https://www.sci-hub.ren/10.5139/IJASS.2014.15.4.419>
2021-02-26 04:01:12 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-319-04364-7%5C_131>
2021-02-26 04:01:20 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.5209/rev%5C_JIGE.2015.v41.n3.51568>
2021-02-26 04:01:28 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-319-24987-2%5C_6>
2021-02-26 04:01:33 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-319-24987-2%5C_26>
2021-02-26 04:01:36 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v16/n2/p131-141/> from <GET https://www.sci-hub.ren/10.3354/ame016131>
2021-02-26 04:01:43 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> from <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/>
2021-02-26 04:01:47 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> from <GET https://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm>
2021-02-26 04:02:01 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 04:02:14 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595> from <GET https://www.sci-hub.ren/10.2113/96.7.1595>
2021-02-26 04:02:16 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://paleoitalia.org> from <GET https://www.sci-hub.ren/10.4435/BSPI.2016.09>
2021-02-26 04:02:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:02:23 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> from <GET http://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770>
2021-02-26 04:02:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3391/ai.2016.11.3.04> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:02:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.5327/Z2317-48892013000300004> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:02:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.14241/asgp.2016.011> (referer: None)
2021-02-26 04:02:38 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 04:02:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-26 04:02:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.publicacions.ub.edu/doi/documents/2051.pdf> from <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf>
2021-02-26 04:02:43 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page> from <GET http://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page>
2021-02-26 04:02:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-26 04:02:48 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 04:02:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 04:02:54 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/> from <GET http://www.sci-hub.ren/>
2021-02-26 04:03:01 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 04:03:08 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/> from <GET http://www.sci-hub.ren/>
2021-02-26 04:03:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:03:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> (referer: None)
2021-02-26 04:03:23 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 04:03:23 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 04:03:23 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v16/n2/p131-141/> from <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v16/n2/p131-141/>
2021-02-26 04:03:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 1 times): 404 Not Found
2021-02-26 04:03:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-02-26 04:03:46 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://paleoitalia.org/> from <GET https://www.sci-hub.ren/http://paleoitalia.org>
2021-02-26 04:03:59 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> from <GET https://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770>
2021-02-26 04:04:02 [scrapy.extensions.logstats] INFO: Crawled 6 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 04:04:03 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/> from <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/>
2021-02-26 04:04:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.1055/s-0036-1596638> (referer: None)
2021-02-26 04:04:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 04:04:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 04:04:28 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://koreascience.or.kr/article/JAKO201404065095388.page> from <GET https://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page>
2021-02-26 04:04:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.5327/Z2317-48892013000300004> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:04:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.publicacions.ub.edu/doi/documents/2051.pdf> (referer: None)
2021-02-26 04:04:29 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 04:04:29 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-26 04:04:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.publicacions.ub.edu/doi/documents/2051.pdf> (referer: None)
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/python.py", line 353, in __next__
    return next(self.data)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/python.py", line 353, in __next__
    return next(self.data)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/wos_crawl/wos_crawl/spiders/wos_spider.py", line 39, in parse
    detail_url_list = response.xpath('//*[@id="buttons"]/ul/li[2]/a/@onclick')
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/http/response/__init__.py", line 120, in xpath
    raise NotSupported("Response content isn't text")
scrapy.exceptions.NotSupported: Response content isn't text
2021-02-26 04:04:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-26 04:04:37 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 04:04:37 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-26 04:04:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-26 04:04:48 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 04:04:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 04:04:51 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/> from <GET http://www.sci-hub.ren/>
2021-02-26 04:05:01 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 04:05:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 2 times): 404 Not Found
2021-02-26 04:05:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v16/n2/p131-141/> (referer: None)
2021-02-26 04:05:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 04:05:15 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-26 04:05:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3389/fmicb.2013.01359> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:05:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://paleoitalia.org/> (referer: None)
2021-02-26 04:05:22 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 04:05:22 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 04:05:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> (referer: None)
2021-02-26 04:05:28 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 04:05:28 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-26 04:05:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/> (referer: None)
2021-02-26 04:05:32 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 04:05:32 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 04:05:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:05:39 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://paleopolis.rediris.es/cg/18/08/index.html> from <GET https://www.sci-hub.ren/10.4267/2042/68182>
2021-02-26 04:05:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://koreascience.or.kr/article/JAKO201404065095388.page> (referer: None)
2021-02-26 04:05:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 04:05:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 04:06:00 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf> from <GET https://www.sci-hub.ren/10.5327/Z2317-48892013000300004>
2021-02-26 04:06:01 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 04:06:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> from <GET https://www.sci-hub.ren/10.4072/rbp.2018.3.01>
2021-02-26 04:06:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/> from <GET https://www.sci-hub.ren/10.3354/meps12741>
2021-02-26 04:06:11 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html> from <GET https://www.sci-hub.ren/10.1051/bsgf/2018019>
2021-02-26 04:06:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-26 04:06:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 04:06:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 04:06:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 3 times): 404 Not Found
2021-02-26 04:06:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://www.int-res.com/abstracts/ame/v82/n3/p253-264/> from <GET https://www.sci-hub.ren/10.3354/ame01895>
2021-02-26 04:06:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.5027/andgeoV46n1-3029> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:06:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3389/fmicb.2013.01359> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:07:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3391/ai.2016.11.3.04> (failed 2 times): User timeout caused connection failure: Getting https://www.sci-hub.ren/10.3391/ai.2016.11.3.04 took longer than 180.0 seconds..
2021-02-26 04:07:01 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 04:07:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3390/min9100000> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:07:07 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://paleopolis.rediris.es/cg/18/08/index.html> from <GET http://www.sci-hub.ren/http://paleopolis.rediris.es/cg/18/08/index.html>
2021-02-26 04:07:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.5027/andgeoV47n1-3177> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:07:15 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-030-21614-6%5C_12>
2021-02-26 04:07:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:07:19 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 04:07:19 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 04:07:19 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-26 04:07:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/meps12300> (failed 1 times): User timeout caused connection failure: Getting https://www.sci-hub.ren/10.3354/meps12300 took longer than 180.0 seconds..
2021-02-26 04:07:36 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html> from <GET http://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html>
2021-02-26 04:07:38 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:07:38 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 04:07:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 04:07:38 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-26 04:07:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.1089/ast.2019.2067> (referer: None)
2021-02-26 04:07:43 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 04:07:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 04:07:43 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded file from <GET https://cyber.bban.top/MTAuMTA4OS9hc3QuMjAxOS4yMDY3/10.1089%40ast.2019.2067.pdf?download=true> referred in <None>
2021-02-26 04:07:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.sci-hub.ren/10.1089/ast.2019.2067>
{'file_urls': ['https://cyber.bban.top/MTAuMTA4OS9hc3QuMjAxOS4yMDY3/10.1089%40ast.2019.2067.pdf?download=true'],
 'files': [{'checksum': '808358d065f4915b2156f3de1d6a1a24',
            'path': '000582254100001.pdf',
            'status': 'uptodate',
            'url': 'https://cyber.bban.top/MTAuMTA4OS9hc3QuMjAxOS4yMDY3/10.1089%40ast.2019.2067.pdf?download=true'}],
 'name': '000582254100001'}
2021-02-26 04:07:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:07:48 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 4 times): 404 Not Found
2021-02-26 04:07:48 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (referer: None)
2021-02-26 04:07:48 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 04:07:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 04:07:48 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.scichina.com/2004/yk/yd/0404/yd0347.stm>: HTTP status code is not handled or not allowed
2021-02-26 04:07:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:08:01 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 2 pages/min), scraped 1 items (at 1 items/min)
2021-02-26 04:08:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://www.int-res.com/abstracts/ame/v82/n3/p253-264/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:08:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.5027/andgeoV46n1-3029> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:08:27 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://paleopolis.rediris.es/cg/18/08/index.html> from <GET https://www.sci-hub.ren/http://paleopolis.rediris.es/cg/18/08/index.html>
2021-02-26 04:08:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3389/fmicb.2013.01359> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:08:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3391/ai.2016.11.3.04> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:08:41 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/> from <GET http://www.sci-hub.ren/>
2021-02-26 04:08:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3390/min9100000> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:08:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.1155/2020/6959532> (referer: None)
2021-02-26 04:08:46 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded file from <GET https://cyber.bban.top/MTAuMTE1NS8yMDIwLzY5NTk1MzI=/10.1155%402020%406959532.pdf?download=true> referred in <None>
2021-02-26 04:08:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.sci-hub.ren/10.1155/2020/6959532>
{'file_urls': ['https://cyber.bban.top/MTAuMTE1NS8yMDIwLzY5NTk1MzI=/10.1155%402020%406959532.pdf?download=true'],
 'files': [{'checksum': '6c02fcee70c30afc9791e2e93ddc95f4',
            'path': '000588326000002.pdf',
            'status': 'uptodate',
            'url': 'https://cyber.bban.top/MTAuMTE1NS8yMDIwLzY5NTk1MzI=/10.1155%402020%406959532.pdf?download=true'}],
 'name': '000588326000002'}
2021-02-26 04:08:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.5027/andgeoV47n1-3177> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:08:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html> (referer: None)
2021-02-26 04:09:01 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 2 pages/min), scraped 2 items (at 1 items/min)
2021-02-26 04:09:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> from <GET https://www.sci-hub.ren/10.1111/1758-2229.12916>
2021-02-26 04:09:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/meps12300> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:09:14 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486> from <GET https://www.sci-hub.ren/10.7306/gq.1547>
2021-02-26 04:09:17 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> from <GET https://www.sci-hub.ren/https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf>
2021-02-26 04:09:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1111/gbi.12429> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:09:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:09:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://paleopolis.rediris.es/cg/18/08/index.html> (referer: None)
2021-02-26 04:09:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://www.int-res.com/abstracts/ame/v82/n3/p253-264/> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:10:02 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 1 pages/min), scraped 2 items (at 0 items/min)
2021-02-26 04:10:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.5027/andgeoV46n1-3029> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:10:09 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359> from <GET https://www.sci-hub.ren/10.3389/fmicb.2013.01359>
2021-02-26 04:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-26 04:10:21 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/10.3391/ai.2016.11.3.04> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:10:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/10.3391/ai.2016.11.3.04>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-26 04:10:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.5027/andgeoV47n1-3177> (referer: None)
2021-02-26 04:10:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3390/min9100000> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:10:34 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> from <GET http://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916>
2021-02-26 04:10:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/meps12300> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:10:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:11:01 [scrapy.extensions.logstats] INFO: Crawled 23 pages (at 2 pages/min), scraped 2 items (at 0 items/min)
2021-02-26 04:11:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:11:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1111/gbi.12429> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:11:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:11:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://www.int-res.com/abstracts/ame/v82/n3/p253-264/> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:11:32 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/10.5027/andgeoV46n1-3029> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:11:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/10.5027/andgeoV46n1-3029>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-26 04:11:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> (referer: None)
2021-02-26 04:11:39 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:11:40 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-26 04:11:44 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/10.3390/min9100000> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:11:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/10.3390/min9100000>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-26 04:11:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/10.3354/meps12300> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:11:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/10.3354/meps12300>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-26 04:12:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> (referer: None)
2021-02-26 04:12:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:12:04 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 2 pages/min), scraped 2 items (at 0 items/min)
2021-02-26 04:12:15 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/> from <GET http://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/>
2021-02-26 04:12:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1111/gbi.12429> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:12:32 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://www.sci-hub.ren/https://www.int-res.com/abstracts/ame/v82/n3/p253-264/> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:12:32 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.sci-hub.ren/https://www.int-res.com/abstracts/ame/v82/n3/p253-264/>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-26 04:12:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:12:44 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:12:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-26 04:12:50 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/10.1111/gbi.12429> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:12:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/10.1111/gbi.12429>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-26 04:12:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 04:12:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-26 04:12:59 [scrapy.core.engine] INFO: Closing spider (finished)
2021-02-26 04:12:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 51,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 48,
 'downloader/exception_type_count/twisted.internet.error.TimeoutError': 2,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 1,
 'downloader/request_bytes': 50995,
 'downloader/request_count': 122,
 'downloader/request_method_count/GET': 122,
 'downloader/response_bytes': 20282803,
 'downloader/response_count': 71,
 'downloader/response_status_count/200': 24,
 'downloader/response_status_count/301': 13,
 'downloader/response_status_count/302': 30,
 'downloader/response_status_count/404': 4,
 'elapsed_time_seconds': 777.785641,
 'file_count': 2,
 'file_status_count/uptodate': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 2, 25, 20, 12, 59, 784010),
 'httperror/response_ignored_count': 1,
 'httperror/response_ignored_status_count/404': 1,
 'item_scraped_count': 2,
 'log_count/DEBUG': 187,
 'log_count/ERROR': 24,
 'log_count/INFO': 21,
 'log_count/WARNING': 1,
 'memusage/max': 757837824,
 'memusage/startup': 68210688,
 'response_received_count': 25,
 'retry/count': 43,
 'retry/max_reached': 12,
 'retry/reason_count/404 Not Found': 3,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 37,
 'retry/reason_count/twisted.internet.error.TimeoutError': 2,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 1,
 'scheduler/dequeued': 122,
 'scheduler/dequeued/memory': 122,
 'scheduler/enqueued': 122,
 'scheduler/enqueued/memory': 122,
 'spider_exceptions/NotSupported': 1,
 'start_time': datetime.datetime(2021, 2, 25, 20, 0, 1, 998369)}
2021-02-26 04:12:59 [scrapy.core.engine] INFO: Spider closed (finished)
2021-02-26 08:00:01 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: wos_crawl)
2021-02-26 08:00:01 [scrapy.utils.log] INFO: Versions: lxml 4.6.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.6.9 (default, Oct  8 2020, 12:12:24) - [GCC 8.4.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1i  8 Dec 2020), cryptography 3.3.1, Platform Linux-4.15.0-132-generic-x86_64-with-Ubuntu-18.04-bionic
2021-02-26 08:00:01 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2021-02-26 08:00:01 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wos_crawl',
 'COOKIES_ENABLED': False,
 'DOWNLOAD_DELAY': 5,
 'LOG_FILE': 'crawler.log',
 'NEWSPIDER_MODULE': 'wos_crawl.spiders',
 'RETRY_HTTP_CODES': [500, 503, 504, 400, 403, 404, 408],
 'RETRY_TIMES': 3,
 'SPIDER_MODULES': ['wos_crawl.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/88.0.4324.104 Safari/537.36'}
2021-02-26 08:00:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2021-02-26 08:00:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-02-26 08:00:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-02-26 08:00:01 [py.warnings] WARNING: /home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/pipelines/media.py:135: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2021-02-26 08:00:01 [scrapy.middleware] INFO: Enabled item pipelines:
['wos_crawl.pipelines.fileDown']
2021-02-26 08:00:01 [scrapy.core.engine] INFO: Spider opened
2021-02-26 08:00:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 08:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 08:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 08:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 08:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-26 08:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 08:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 08:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 08:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 08:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 08:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 149
2021-02-26 08:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 08:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 08:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 08:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-26 08:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 08:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 08:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 08:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 08:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 08:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 08:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 08:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 08:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 08:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 08:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 08:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 149
2021-02-26 08:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 08:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 08:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 08:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 08:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 08:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 08:00:02 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v16/n2/p131-141/> from <GET https://www.sci-hub.ren/10.3354/ame016131>
2021-02-26 08:00:18 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> from <GET https://www.sci-hub.ren/10.3354/ame021161>
2021-02-26 08:00:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.2113/96.7.1595> (referer: None)
2021-02-26 08:00:20 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 08:00:20 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-26 08:00:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> from <GET https://www.sci-hub.ren/10.1360/02yd0178>
2021-02-26 08:00:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf> from <GET https://www.sci-hub.ren/10.5327/Z2317-48892013000300004>
2021-02-26 08:00:35 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/> from <GET https://www.sci-hub.ren/10.3354/ame048123>
2021-02-26 08:00:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.3354/meps07087> (referer: None)
2021-02-26 08:00:44 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 08:00:44 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-26 08:00:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.2485/jhtb.20.339> (referer: None)
2021-02-26 08:00:47 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 08:00:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 08:00:55 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> from <GET https://www.sci-hub.ren/10.1344/105.000001770>
2021-02-26 08:01:01 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf> from <GET https://www.sci-hub.ren/10.1344/105.000002051>
2021-02-26 08:01:01 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 08:01:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.7306/gq.1131> (referer: None)
2021-02-26 08:01:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 08:01:06 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-26 08:01:12 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page> from <GET https://www.sci-hub.ren/10.5139/IJASS.2014.15.4.419>
2021-02-26 08:01:18 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-319-04364-7%5C_131>
2021-02-26 08:01:21 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.5209/rev%5C_JIGE.2015.v41.n3.51568>
2021-02-26 08:01:26 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-319-24987-2%5C_6>
2021-02-26 08:01:33 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-319-24987-2%5C_26>
2021-02-26 08:01:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v16/n2/p131-141/> (referer: None)
2021-02-26 08:01:41 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 08:01:41 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 149
2021-02-26 08:01:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> (referer: None)
2021-02-26 08:01:48 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 08:01:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 08:01:55 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html> from <GET https://www.sci-hub.ren/10.3391/ai.2016.11.3.04>
2021-02-26 08:02:01 [scrapy.extensions.logstats] INFO: Crawled 6 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 08:02:02 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> from <GET http://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm>
2021-02-26 08:02:12 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://bjg.siteoficial.ws/2013/n.3/d.pdf> from <GET https://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf>
2021-02-26 08:02:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/> (failed 1 times): 403 Forbidden
2021-02-26 08:02:19 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://paleoitalia.org> from <GET https://www.sci-hub.ren/10.4435/BSPI.2016.09>
2021-02-26 08:02:34 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> from <GET http://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770>
2021-02-26 08:02:37 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf> from <GET http://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf>
2021-02-26 08:02:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.1055/s-0036-1596638> (referer: None)
2021-02-26 08:02:45 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 08:02:45 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 08:02:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.14241/asgp.2016.011> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 08:02:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page> (failed 1 times): 403 Forbidden
2021-02-26 08:02:59 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/> from <GET http://www.sci-hub.ren/>
2021-02-26 08:03:01 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 08:03:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-26 08:03:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 08:03:05 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 08:03:11 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/> from <GET http://www.sci-hub.ren/>
2021-02-26 08:03:17 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/> from <GET http://www.sci-hub.ren/>
2021-02-26 08:03:25 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/> from <GET https://www.sci-hub.ren/10.3354/meps12300>
2021-02-26 08:03:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> from <GET https://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm>
2021-02-26 08:03:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bjg.siteoficial.ws/2013/n.3/d.pdf> (failed 1 times): 403 Forbidden
2021-02-26 08:03:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3389/fmicb.2013.01359> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 08:03:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/> (failed 2 times): 403 Forbidden
2021-02-26 08:03:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 08:03:58 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://paleoitalia.org> from <GET http://www.sci-hub.ren/http://paleoitalia.org>
2021-02-26 08:04:01 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 08:04:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> from <GET https://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770>
2021-02-26 08:04:12 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.publicacions.ub.edu/doi/documents/2051.pdf> from <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf>
2021-02-26 08:04:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page> (failed 2 times): 403 Forbidden
2021-02-26 08:04:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-26 08:04:35 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 08:04:35 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 08:04:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.14241/asgp.2016.011> (referer: None)
2021-02-26 08:04:35 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 08:04:35 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-26 08:04:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.4267/2042/68182> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 08:04:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-26 08:04:47 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 08:04:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 08:04:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-26 08:04:54 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 08:04:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 144
2021-02-26 08:05:01 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/> from <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/>
2021-02-26 08:05:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/meps12741> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 08:05:01 [scrapy.extensions.logstats] INFO: Crawled 12 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 08:05:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bjg.siteoficial.ws/2013/n.3/d.pdf> (failed 2 times): 403 Forbidden
2021-02-26 08:05:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 1 times): 404 Not Found
2021-02-26 08:05:18 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359> from <GET https://www.sci-hub.ren/10.3389/fmicb.2013.01359>
2021-02-26 08:05:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/> (failed 3 times): 403 Forbidden
2021-02-26 08:05:37 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://paleoitalia.org/> from <GET https://www.sci-hub.ren/http://paleoitalia.org>
2021-02-26 08:05:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 08:05:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page> (failed 3 times): 403 Forbidden
2021-02-26 08:06:01 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> from <GET https://www.sci-hub.ren/10.4072/rbp.2018.3.01>
2021-02-26 08:06:01 [scrapy.extensions.logstats] INFO: Crawled 12 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 08:06:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> (referer: None)
2021-02-26 08:06:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 08:06:04 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 08:06:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.publicacions.ub.edu/doi/documents/2051.pdf> (referer: None)
2021-02-26 08:06:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 08:06:06 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 08:06:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.publicacions.ub.edu/doi/documents/2051.pdf> (referer: None)
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/python.py", line 353, in __next__
    return next(self.data)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/python.py", line 353, in __next__
    return next(self.data)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/wos_crawl/wos_crawl/spiders/wos_spider.py", line 39, in parse
    detail_url_list = response.xpath('//*[@id="buttons"]/ul/li[2]/a/@onclick')
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/http/response/__init__.py", line 120, in xpath
    raise NotSupported("Response content isn't text")
scrapy.exceptions.NotSupported: Response content isn't text
2021-02-26 08:06:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1051/bsgf/2018019> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 08:06:23 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/ame/v82/n3/p253-264/> from <GET https://www.sci-hub.ren/10.3354/ame01895>
2021-02-26 08:06:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.5027/andgeoV46n1-3029> (referer: None)
2021-02-26 08:06:24 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 08:06:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 144
2021-02-26 08:06:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/> (referer: None)
2021-02-26 08:06:31 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 08:06:31 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 08:06:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.4267/2042/68182> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 08:06:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bjg.siteoficial.ws/2013/n.3/d.pdf> (failed 3 times): 403 Forbidden
2021-02-26 08:06:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 2 times): 404 Not Found
2021-02-26 08:06:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/meps12741> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 08:06:57 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/> (failed 4 times): 403 Forbidden
2021-02-26 08:06:57 [scrapy.core.engine] DEBUG: Crawled (403) <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/> (referer: None)
2021-02-26 08:06:57 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 08:06:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 08:06:57 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/>: HTTP status code is not handled or not allowed
2021-02-26 08:07:01 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 08:07:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://paleoitalia.org/> (referer: None) ['partial']
2021-02-26 08:07:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 08:07:06 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 08:07:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 08:07:16 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page> (failed 4 times): 403 Forbidden
2021-02-26 08:07:16 [scrapy.core.engine] DEBUG: Crawled (403) <GET http://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page> (referer: None)
2021-02-26 08:07:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 08:07:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 149
2021-02-26 08:07:16 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 http://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page>: HTTP status code is not handled or not allowed
2021-02-26 08:07:20 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.aquaticinvasions.net/2016/issue3.html> from <GET https://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html>
2021-02-26 08:07:30 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://doi.org/10.3390/min9100000> from <GET https://www.sci-hub.ren/10.3390/min9100000>
2021-02-26 08:07:35 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> from <GET https://www.sci-hub.ren/https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf>
2021-02-26 08:07:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.5027/andgeoV47n1-3177> (referer: None)
2021-02-26 08:07:39 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 08:07:39 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-26 08:07:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html> from <GET https://www.sci-hub.ren/10.1051/bsgf/2018019>
2021-02-26 08:07:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/ame/v82/n3/p253-264/> (referer: None)
2021-02-26 08:07:52 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-030-21614-6%5C_12>
2021-02-26 08:07:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.1089/ast.2019.2067> (referer: None)
2021-02-26 08:07:58 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded file from <GET https://cyber.bban.top/MTAuMTA4OS9hc3QuMjAxOS4yMDY3/10.1089%40ast.2019.2067.pdf?download=true> referred in <None>
2021-02-26 08:07:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.sci-hub.ren/10.1089/ast.2019.2067>
{'file_urls': ['https://cyber.bban.top/MTAuMTA4OS9hc3QuMjAxOS4yMDY3/10.1089%40ast.2019.2067.pdf?download=true'],
 'files': [{'checksum': '808358d065f4915b2156f3de1d6a1a24',
            'path': '000582254100001.pdf',
            'status': 'uptodate',
            'url': 'https://cyber.bban.top/MTAuMTA4OS9hc3QuMjAxOS4yMDY3/10.1089%40ast.2019.2067.pdf?download=true'}],
 'name': '000582254100001'}
2021-02-26 08:08:01 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 5 pages/min), scraped 1 items (at 1 items/min)
2021-02-26 08:08:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://bjg.siteoficial.ws/2013/n.3/d.pdf> (failed 4 times): 403 Forbidden
2021-02-26 08:08:08 [scrapy.core.engine] DEBUG: Crawled (403) <GET http://bjg.siteoficial.ws/2013/n.3/d.pdf> (referer: None)
2021-02-26 08:08:08 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 http://bjg.siteoficial.ws/2013/n.3/d.pdf>: HTTP status code is not handled or not allowed
2021-02-26 08:08:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 3 times): 404 Not Found
2021-02-26 08:08:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.4267/2042/68182> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 08:08:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> from <GET https://www.sci-hub.ren/10.1111/1758-2229.12916>
2021-02-26 08:08:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/meps12741> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 08:08:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1155/2020/6959532> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 08:08:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486> from <GET https://www.sci-hub.ren/10.7306/gq.1547>
2021-02-26 08:08:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 08:09:01 [scrapy.extensions.logstats] INFO: Crawled 23 pages (at 1 pages/min), scraped 1 items (at 0 items/min)
2021-02-26 08:09:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.aquaticinvasions.net/2016/issue3.html> (referer: None)
2021-02-26 08:09:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://doi.org/10.3390/min9100000> from <GET http://www.sci-hub.ren/https://doi.org/10.3390/min9100000>
2021-02-26 08:09:12 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429> from <GET https://www.sci-hub.ren/10.1111/gbi.12429>
2021-02-26 08:09:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 08:09:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-26 08:09:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> (referer: None)
2021-02-26 08:09:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 4 times): 404 Not Found
2021-02-26 08:09:33 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (referer: None)
2021-02-26 08:09:33 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.scichina.com/2004/yk/yd/0404/yd0347.stm>: HTTP status code is not handled or not allowed
2021-02-26 08:09:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> (referer: None)
2021-02-26 08:09:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/10.4267/2042/68182> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 08:09:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/10.4267/2042/68182>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-26 08:10:01 [scrapy.extensions.logstats] INFO: Crawled 28 pages (at 5 pages/min), scraped 1 items (at 0 items/min)
2021-02-26 08:10:02 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486> from <GET http://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486>
2021-02-26 08:10:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/10.3354/meps12741> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 08:10:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/10.3354/meps12741>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-26 08:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://doi.org/10.3390/min9100000> (referer: None)
2021-02-26 08:10:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1155/2020/6959532> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 08:10:18 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429?cookieSet=1> from <GET https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429>
2021-02-26 08:10:25 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html> from <GET http://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html>
2021-02-26 08:10:26 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 08:10:26 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-26 08:10:48 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://gq.pgi.gov.pl/article/view/28486> from <GET https://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486>
2021-02-26 08:10:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 08:10:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1155/2020/6959532> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 08:11:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 08:11:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-26 08:11:01 [scrapy.extensions.logstats] INFO: Crawled 29 pages (at 1 pages/min), scraped 1 items (at 0 items/min)
2021-02-26 08:11:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.1155/2020/6959532> (referer: None)
2021-02-26 08:11:11 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded file from <GET https://cyber.bban.top/MTAuMTE1NS8yMDIwLzY5NTk1MzI=/10.1155%402020%406959532.pdf?download=true> referred in <None>
2021-02-26 08:11:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.sci-hub.ren/10.1155/2020/6959532>
{'file_urls': ['https://cyber.bban.top/MTAuMTE1NS8yMDIwLzY5NTk1MzI=/10.1155%402020%406959532.pdf?download=true'],
 'files': [{'checksum': '6c02fcee70c30afc9791e2e93ddc95f4',
            'path': '000588326000002.pdf',
            'status': 'uptodate',
            'url': 'https://cyber.bban.top/MTAuMTE1NS8yMDIwLzY5NTk1MzI=/10.1155%402020%406959532.pdf?download=true'}],
 'name': '000588326000002'}
2021-02-26 08:11:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://gq.pgi.gov.pl/article/view/28486> (referer: None)
2021-02-26 08:12:01 [scrapy.extensions.logstats] INFO: Crawled 31 pages (at 2 pages/min), scraped 2 items (at 1 items/min)
2021-02-26 08:13:01 [scrapy.extensions.logstats] INFO: Crawled 31 pages (at 0 pages/min), scraped 2 items (at 0 items/min)
2021-02-26 08:13:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429?cookieSet=1> (failed 1 times): User timeout caused connection failure: Getting https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429?cookieSet=1 took longer than 180.0 seconds..
2021-02-26 08:13:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429?cookieSet=1> (referer: None)
2021-02-26 08:13:48 [scrapy.core.engine] INFO: Closing spider (finished)
2021-02-26 08:13:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 23,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 22,
 'downloader/exception_type_count/twisted.internet.error.TimeoutError': 1,
 'downloader/request_bytes': 46470,
 'downloader/request_count': 111,
 'downloader/request_method_count/GET': 111,
 'downloader/response_bytes': 20197279,
 'downloader/response_count': 88,
 'downloader/response_status_count/200': 28,
 'downloader/response_status_count/301': 11,
 'downloader/response_status_count/302': 33,
 'downloader/response_status_count/403': 12,
 'downloader/response_status_count/404': 4,
 'elapsed_time_seconds': 826.792152,
 'file_count': 2,
 'file_status_count/uptodate': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 2, 26, 0, 13, 48, 736139),
 'httperror/response_ignored_count': 4,
 'httperror/response_ignored_status_count/403': 3,
 'httperror/response_ignored_status_count/404': 1,
 'item_scraped_count': 2,
 'log_count/DEBUG': 183,
 'log_count/ERROR': 13,
 'log_count/INFO': 25,
 'log_count/WARNING': 1,
 'memusage/max': 754892800,
 'memusage/startup': 68075520,
 'response_received_count': 32,
 'retry/count': 31,
 'retry/max_reached': 8,
 'retry/reason_count/403 Forbidden': 9,
 'retry/reason_count/404 Not Found': 3,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 18,
 'retry/reason_count/twisted.internet.error.TimeoutError': 1,
 'scheduler/dequeued': 111,
 'scheduler/dequeued/memory': 111,
 'scheduler/enqueued': 111,
 'scheduler/enqueued/memory': 111,
 'spider_exceptions/NotSupported': 1,
 'start_time': datetime.datetime(2021, 2, 26, 0, 0, 1, 943987)}
2021-02-26 08:13:48 [scrapy.core.engine] INFO: Spider closed (finished)
2021-02-26 12:00:02 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: wos_crawl)
2021-02-26 12:00:02 [scrapy.utils.log] INFO: Versions: lxml 4.6.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.6.9 (default, Oct  8 2020, 12:12:24) - [GCC 8.4.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1i  8 Dec 2020), cryptography 3.3.1, Platform Linux-4.15.0-132-generic-x86_64-with-Ubuntu-18.04-bionic
2021-02-26 12:00:02 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2021-02-26 12:00:02 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wos_crawl',
 'COOKIES_ENABLED': False,
 'DOWNLOAD_DELAY': 5,
 'LOG_FILE': 'crawler.log',
 'NEWSPIDER_MODULE': 'wos_crawl.spiders',
 'RETRY_HTTP_CODES': [500, 503, 504, 400, 403, 404, 408],
 'RETRY_TIMES': 3,
 'SPIDER_MODULES': ['wos_crawl.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/88.0.4324.104 Safari/537.36'}
2021-02-26 12:00:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2021-02-26 12:00:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-02-26 12:00:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-02-26 12:00:02 [py.warnings] WARNING: /home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/pipelines/media.py:135: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2021-02-26 12:00:02 [scrapy.middleware] INFO: Enabled item pipelines:
['wos_crawl.pipelines.fileDown']
2021-02-26 12:00:02 [scrapy.core.engine] INFO: Spider opened
2021-02-26 12:00:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 12:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 12:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 144
2021-02-26 12:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 12:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 12:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 12:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 12:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 12:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 12:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 12:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 149
2021-02-26 12:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 12:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-26 12:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 12:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 12:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 12:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 12:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 12:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 12:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 12:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-26 12:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 12:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 12:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 12:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 149
2021-02-26 12:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 12:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-26 12:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 12:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-26 12:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 12:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-26 12:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 12:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 12:00:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.2113/96.7.1595> (referer: None)
2021-02-26 12:00:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 12:00:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 12:00:20 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> from <GET https://www.sci-hub.ren/10.3354/ame021161>
2021-02-26 12:00:23 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf> from <GET https://www.sci-hub.ren/10.5327/Z2317-48892013000300004>
2021-02-26 12:00:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/ame016131> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 12:00:30 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> from <GET https://www.sci-hub.ren/10.1360/02yd0178>
2021-02-26 12:00:41 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/> from <GET https://www.sci-hub.ren/10.3354/ame048123>
2021-02-26 12:00:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.2485/jhtb.20.339> (referer: None)
2021-02-26 12:00:54 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 12:00:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 12:00:59 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> from <GET https://www.sci-hub.ren/10.1344/105.000001770>
2021-02-26 12:00:59 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf> from <GET https://www.sci-hub.ren/10.1344/105.000002051>
2021-02-26 12:01:02 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 12:01:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/meps07087> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 12:01:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.7306/gq.1131> (referer: None)
2021-02-26 12:01:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 12:01:10 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 12:01:11 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page> from <GET https://www.sci-hub.ren/10.5139/IJASS.2014.15.4.419>
2021-02-26 12:01:24 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.5209/rev%5C_JIGE.2015.v41.n3.51568>
2021-02-26 12:01:37 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-319-24987-2%5C_26>
2021-02-26 12:01:39 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html> from <GET https://www.sci-hub.ren/10.3391/ai.2016.11.3.04>
2021-02-26 12:01:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1007/978-3-319-04364-7%5C_131> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 12:01:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1007/978-3-319-24987-2%5C_6> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 12:01:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf> (failed 1 times): 403 Forbidden
2021-02-26 12:02:02 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 12:02:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> from <GET http://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm>
2021-02-26 12:02:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 12:02:16 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://paleoitalia.org> from <GET https://www.sci-hub.ren/10.4435/BSPI.2016.09>
2021-02-26 12:02:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/ame016131> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 12:02:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-02-26 12:02:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 12:02:39 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page> from <GET http://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page>
2021-02-26 12:02:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-02-26 12:02:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.14241/asgp.2016.011> (referer: None)
2021-02-26 12:02:40 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 12:02:40 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 12:02:47 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/> from <GET http://www.sci-hub.ren/>
2021-02-26 12:02:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/meps07087> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 12:02:56 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/> from <GET http://www.sci-hub.ren/>
2021-02-26 12:03:00 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.aquaticinvasions.net/2016/issue3.html> from <GET https://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html>
2021-02-26 12:03:02 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 12:03:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-319-04364-7%5C_131>
2021-02-26 12:03:10 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-319-24987-2%5C_6>
2021-02-26 12:03:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf> (failed 2 times): 403 Forbidden
2021-02-26 12:03:25 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> from <GET https://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm>
2021-02-26 12:03:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://paleoitalia.org> (failed 1 times): 403 Forbidden
2021-02-26 12:03:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-02-26 12:03:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-02-26 12:03:58 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://koreascience.or.kr/article/JAKO201404065095388.page> from <GET https://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page>
2021-02-26 12:03:59 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/> from <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/>
2021-02-26 12:04:02 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 12:04:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/ame016131> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 12:04:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-26 12:04:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 12:04:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 149
2021-02-26 12:04:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.1055/s-0036-1596638> (referer: None)
2021-02-26 12:04:21 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 12:04:21 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 12:04:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 12:04:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-26 12:04:28 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 12:04:28 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-26 12:04:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.aquaticinvasions.net/2016/issue3.html> (referer: None)
2021-02-26 12:04:37 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 12:04:37 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 12:04:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/meps07087> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 12:04:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf> (failed 3 times): 403 Forbidden
2021-02-26 12:04:52 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/> from <GET http://www.sci-hub.ren/>
2021-02-26 12:04:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 12:05:02 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 12:05:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://paleoitalia.org> (failed 2 times): 403 Forbidden
2021-02-26 12:05:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 12:05:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-02-26 12:05:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 12:05:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://koreascience.or.kr/article/JAKO201404065095388.page> (referer: None)
2021-02-26 12:05:40 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 12:05:40 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-26 12:05:42 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/> from <GET https://www.sci-hub.ren/10.3354/meps12300>
2021-02-26 12:05:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 12:05:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359> from <GET https://www.sci-hub.ren/10.3389/fmicb.2013.01359>
2021-02-26 12:05:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/10.3354/ame016131> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 12:05:56 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 12:05:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 12:05:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/10.3354/ame016131>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-26 12:05:58 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://paleopolis.rediris.es/cg/18/08/index.html> from <GET https://www.sci-hub.ren/10.4267/2042/68182>
2021-02-26 12:06:02 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 12:06:05 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/> from <GET https://www.sci-hub.ren/10.3354/meps12741>
2021-02-26 12:06:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf> (failed 4 times): 403 Forbidden
2021-02-26 12:06:15 [scrapy.core.engine] DEBUG: Crawled (403) <GET http://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf> (referer: None)
2021-02-26 12:06:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 12:06:15 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 12:06:15 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 http://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf>: HTTP status code is not handled or not allowed
2021-02-26 12:06:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.3354/meps07087> (referer: None)
2021-02-26 12:06:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 12:06:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 12:06:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-02-26 12:06:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 2 times): 404 Not Found
2021-02-26 12:06:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://paleoitalia.org> (failed 3 times): 403 Forbidden
2021-02-26 12:06:49 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf> (failed 4 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-02-26 12:06:49 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 12:06:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 12:06:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-02-26 12:06:54 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> from <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/>
2021-02-26 12:06:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 12:07:00 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> from <GET https://www.sci-hub.ren/10.4072/rbp.2018.3.01>
2021-02-26 12:07:02 [scrapy.extensions.logstats] INFO: Crawled 11 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 12:07:05 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/> from <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/>
2021-02-26 12:07:23 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359> from <GET http://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359>
2021-02-26 12:07:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://paleopolis.rediris.es/cg/18/08/index.html> from <GET http://www.sci-hub.ren/http://paleopolis.rediris.es/cg/18/08/index.html>
2021-02-26 12:07:31 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html> from <GET https://www.sci-hub.ren/10.1051/bsgf/2018019>
2021-02-26 12:07:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 12:07:35 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/> from <GET http://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/>
2021-02-26 12:07:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 3 times): 404 Not Found
2021-02-26 12:08:00 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://www.int-res.com/abstracts/ame/v82/n3/p253-264/> from <GET https://www.sci-hub.ren/10.3354/ame01895>
2021-02-26 12:08:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.5027/andgeoV46n1-3029> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 12:08:02 [scrapy.extensions.logstats] INFO: Crawled 11 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 12:08:12 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://doi.org/10.3390/min9100000> from <GET https://www.sci-hub.ren/10.3390/min9100000>
2021-02-26 12:08:13 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 12:08:13 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 12:08:13 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-26 12:08:13 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-26 12:08:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://www.sci-hub.ren/http://paleoitalia.org> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 12:08:25 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 12:08:25 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-26 12:08:25 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.sci-hub.ren/http://paleoitalia.org>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-26 12:08:33 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> from <GET https://www.sci-hub.ren/https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf>
2021-02-26 12:08:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/> (referer: None)
2021-02-26 12:08:36 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 12:08:36 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 12:08:44 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://www.sci-hub.ren/> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 12:08:44 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 12:08:44 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 12:08:44 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.sci-hub.ren/>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-26 12:08:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359> (referer: None)
2021-02-26 12:08:46 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 12:08:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 12:08:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://paleopolis.rediris.es/cg/18/08/index.html> from <GET https://www.sci-hub.ren/http://paleopolis.rediris.es/cg/18/08/index.html>
2021-02-26 12:09:00 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html> from <GET http://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html>
2021-02-26 12:09:02 [scrapy.extensions.logstats] INFO: Crawled 13 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 12:09:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/> (referer: None)
2021-02-26 12:09:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 12:09:06 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 12:09:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 4 times): 404 Not Found
2021-02-26 12:09:12 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (referer: None)
2021-02-26 12:09:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 12:09:12 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 12:09:12 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.scichina.com/2004/yk/yd/0404/yd0347.stm>: HTTP status code is not handled or not allowed
2021-02-26 12:09:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 12:09:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-26 12:09:20 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/ame/v82/n3/p253-264/> from <GET http://www.sci-hub.ren/https://www.int-res.com/abstracts/ame/v82/n3/p253-264/>
2021-02-26 12:09:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/> (failed 2 times): User timeout caused connection failure: Getting https://www.sci-hub.ren/ took longer than 180.0 seconds..
2021-02-26 12:09:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://doi.org/10.3390/min9100000> (referer: None)
2021-02-26 12:09:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.5027/andgeoV46n1-3029> (referer: None)
2021-02-26 12:09:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.1089/ast.2019.2067> (referer: None)
2021-02-26 12:10:00 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded file from <GET https://cyber.bban.top/MTAuMTA4OS9hc3QuMjAxOS4yMDY3/10.1089%40ast.2019.2067.pdf?download=true> referred in <None>
2021-02-26 12:10:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.sci-hub.ren/10.1089/ast.2019.2067>
{'file_urls': ['https://cyber.bban.top/MTAuMTA4OS9hc3QuMjAxOS4yMDY3/10.1089%40ast.2019.2067.pdf?download=true'],
 'files': [{'checksum': '808358d065f4915b2156f3de1d6a1a24',
            'path': '000582254100001.pdf',
            'status': 'uptodate',
            'url': 'https://cyber.bban.top/MTAuMTA4OS9hc3QuMjAxOS4yMDY3/10.1089%40ast.2019.2067.pdf?download=true'}],
 'name': '000582254100001'}
2021-02-26 12:10:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.5027/andgeoV47n1-3177> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 12:10:02 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 5 pages/min), scraped 1 items (at 1 items/min)
2021-02-26 12:10:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.1155/2020/6959532> (referer: None)
2021-02-26 12:10:05 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded file from <GET https://cyber.bban.top/MTAuMTE1NS8yMDIwLzY5NTk1MzI=/10.1155%402020%406959532.pdf?download=true> referred in <None>
2021-02-26 12:10:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.sci-hub.ren/10.1155/2020/6959532>
{'file_urls': ['https://cyber.bban.top/MTAuMTE1NS8yMDIwLzY5NTk1MzI=/10.1155%402020%406959532.pdf?download=true'],
 'files': [{'checksum': '6c02fcee70c30afc9791e2e93ddc95f4',
            'path': '000588326000002.pdf',
            'status': 'uptodate',
            'url': 'https://cyber.bban.top/MTAuMTE1NS8yMDIwLzY5NTk1MzI=/10.1155%402020%406959532.pdf?download=true'}],
 'name': '000588326000002'}
2021-02-26 12:10:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1007/978-3-030-21614-6%5C_12> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 12:10:10 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> from <GET https://www.sci-hub.ren/10.1111/1758-2229.12916>
2021-02-26 12:10:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://paleopolis.rediris.es/cg/18/08/index.html> (referer: None)
2021-02-26 12:10:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html> (referer: None)
2021-02-26 12:10:28 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486> from <GET https://www.sci-hub.ren/10.7306/gq.1547>
2021-02-26 12:10:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429> from <GET https://www.sci-hub.ren/10.1111/gbi.12429>
2021-02-26 12:10:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/ame/v82/n3/p253-264/> (referer: None)
2021-02-26 12:11:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> (referer: None)
2021-02-26 12:11:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 12:11:02 [scrapy.extensions.logstats] INFO: Crawled 23 pages (at 5 pages/min), scraped 2 items (at 1 items/min)
2021-02-26 12:11:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.5027/andgeoV47n1-3177> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 12:11:07 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429?cookieSet=1> from <GET https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429>
2021-02-26 12:11:10 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://gq.pgi.gov.pl/article/view/28486> from <GET https://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486>
2021-02-26 12:11:16 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> (failed 4 times): User timeout caused connection failure: Getting https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/ took longer than 180.0 seconds..
2021-02-26 12:11:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/twisted/internet/defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/twisted/python/failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py", line 375, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/ took longer than 180.0 seconds..
2021-02-26 12:11:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.5027/andgeoV47n1-3177> (referer: None)
2021-02-26 12:11:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429?cookieSet=1> (referer: None)
2021-02-26 12:11:32 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 12:11:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-26 12:11:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://gq.pgi.gov.pl/article/view/28486> (referer: None)
2021-02-26 12:12:02 [scrapy.extensions.logstats] INFO: Crawled 26 pages (at 3 pages/min), scraped 2 items (at 0 items/min)
2021-02-26 12:12:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> (failed 1 times): User timeout caused connection failure: Getting https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf took longer than 180.0 seconds..
2021-02-26 12:13:02 [scrapy.extensions.logstats] INFO: Crawled 26 pages (at 0 pages/min), scraped 2 items (at 0 items/min)
2021-02-26 12:13:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1007/978-3-030-21614-6%5C_12> (failed 2 times): User timeout caused connection failure: Getting https://www.sci-hub.ren/10.1007/978-3-030-21614-6%5C_12 took longer than 180.0 seconds..
2021-02-26 12:14:02 [scrapy.extensions.logstats] INFO: Crawled 26 pages (at 0 pages/min), scraped 2 items (at 0 items/min)
2021-02-26 12:14:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1007/978-3-030-21614-6%5C_12> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 12:14:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/10.1007/978-3-030-21614-6%5C_12> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 12:14:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/10.1007/978-3-030-21614-6%5C_12>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-26 12:15:02 [scrapy.extensions.logstats] INFO: Crawled 26 pages (at 0 pages/min), scraped 2 items (at 0 items/min)
2021-02-26 12:15:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> (failed 2 times): User timeout caused connection failure: Getting https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf took longer than 180.0 seconds..
2021-02-26 12:16:02 [scrapy.extensions.logstats] INFO: Crawled 26 pages (at 0 pages/min), scraped 2 items (at 0 items/min)
2021-02-26 12:17:02 [scrapy.extensions.logstats] INFO: Crawled 26 pages (at 0 pages/min), scraped 2 items (at 0 items/min)
2021-02-26 12:18:02 [scrapy.extensions.logstats] INFO: Crawled 26 pages (at 0 pages/min), scraped 2 items (at 0 items/min)
2021-02-26 12:18:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> (failed 3 times): User timeout caused connection failure: Getting https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf took longer than 180.0 seconds..
2021-02-26 12:19:02 [scrapy.extensions.logstats] INFO: Crawled 26 pages (at 0 pages/min), scraped 2 items (at 0 items/min)
2021-02-26 12:20:02 [scrapy.extensions.logstats] INFO: Crawled 26 pages (at 0 pages/min), scraped 2 items (at 0 items/min)
2021-02-26 12:21:02 [scrapy.extensions.logstats] INFO: Crawled 26 pages (at 0 pages/min), scraped 2 items (at 0 items/min)
2021-02-26 12:21:53 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> (failed 4 times): User timeout caused connection failure: Getting https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf took longer than 180.0 seconds..
2021-02-26 12:21:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/twisted/internet/defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/twisted/python/failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py", line 375, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf took longer than 180.0 seconds..
2021-02-26 12:21:53 [scrapy.core.engine] INFO: Closing spider (finished)
2021-02-26 12:21:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 44,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 30,
 'downloader/exception_type_count/twisted.internet.error.TimeoutError': 7,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 7,
 'downloader/request_bytes': 51177,
 'downloader/request_count': 122,
 'downloader/request_method_count/GET': 122,
 'downloader/response_bytes': 326775,
 'downloader/response_count': 78,
 'downloader/response_status_count/200': 24,
 'downloader/response_status_count/301': 13,
 'downloader/response_status_count/302': 31,
 'downloader/response_status_count/403': 7,
 'downloader/response_status_count/404': 3,
 'elapsed_time_seconds': 1310.958293,
 'file_count': 2,
 'file_status_count/uptodate': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 2, 26, 4, 21, 53, 478995),
 'httperror/response_ignored_count': 2,
 'httperror/response_ignored_status_count/403': 1,
 'httperror/response_ignored_status_count/404': 1,
 'item_scraped_count': 2,
 'log_count/DEBUG': 188,
 'log_count/ERROR': 22,
 'log_count/INFO': 31,
 'log_count/WARNING': 1,
 'memusage/max': 76271616,
 'memusage/startup': 68055040,
 'response_received_count': 26,
 'retry/count': 42,
 'retry/max_reached': 12,
 'retry/reason_count/403 Forbidden': 6,
 'retry/reason_count/404 Not Found': 2,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 23,
 'retry/reason_count/twisted.internet.error.TimeoutError': 5,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 6,
 'scheduler/dequeued': 122,
 'scheduler/dequeued/memory': 122,
 'scheduler/enqueued': 122,
 'scheduler/enqueued/memory': 122,
 'start_time': datetime.datetime(2021, 2, 26, 4, 0, 2, 520702)}
2021-02-26 12:21:53 [scrapy.core.engine] INFO: Spider closed (finished)
2021-02-26 16:00:01 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: wos_crawl)
2021-02-26 16:00:01 [scrapy.utils.log] INFO: Versions: lxml 4.6.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.6.9 (default, Oct  8 2020, 12:12:24) - [GCC 8.4.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1i  8 Dec 2020), cryptography 3.3.1, Platform Linux-4.15.0-132-generic-x86_64-with-Ubuntu-18.04-bionic
2021-02-26 16:00:01 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2021-02-26 16:00:01 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wos_crawl',
 'COOKIES_ENABLED': False,
 'DOWNLOAD_DELAY': 5,
 'LOG_FILE': 'crawler.log',
 'NEWSPIDER_MODULE': 'wos_crawl.spiders',
 'RETRY_HTTP_CODES': [500, 503, 504, 400, 403, 404, 408],
 'RETRY_TIMES': 3,
 'SPIDER_MODULES': ['wos_crawl.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/88.0.4324.104 Safari/537.36'}
2021-02-26 16:00:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2021-02-26 16:00:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-02-26 16:00:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-02-26 16:00:01 [py.warnings] WARNING: /home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/pipelines/media.py:135: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2021-02-26 16:00:01 [scrapy.middleware] INFO: Enabled item pipelines:
['wos_crawl.pipelines.fileDown']
2021-02-26 16:00:01 [scrapy.core.engine] INFO: Spider opened
2021-02-26 16:00:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 16:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 16:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-26 16:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 16:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 16:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 16:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-26 16:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 16:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 144
2021-02-26 16:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 16:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 144
2021-02-26 16:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 16:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 16:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 16:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-26 16:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 16:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 16:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 16:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 144
2021-02-26 16:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 16:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 16:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 16:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-26 16:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 16:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 144
2021-02-26 16:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 16:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-26 16:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 16:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 16:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 16:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-26 16:00:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 16:00:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 16:00:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.2113/96.7.1595> (referer: None)
2021-02-26 16:00:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 16:00:15 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 16:00:20 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf> from <GET https://www.sci-hub.ren/10.5327/Z2317-48892013000300004>
2021-02-26 16:00:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/ame016131> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 16:00:27 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> from <GET https://www.sci-hub.ren/10.1360/02yd0178>
2021-02-26 16:00:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/ame021161> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 16:00:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v349/p23-32/> from <GET https://www.sci-hub.ren/10.3354/meps07087>
2021-02-26 16:00:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.2485/jhtb.20.339> (referer: None)
2021-02-26 16:00:46 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 16:00:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-26 16:00:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> from <GET https://www.sci-hub.ren/10.1344/105.000001770>
2021-02-26 16:00:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/ame048123> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 16:00:59 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf> from <GET https://www.sci-hub.ren/10.1344/105.000002051>
2021-02-26 16:01:01 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 16:01:09 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page> from <GET https://www.sci-hub.ren/10.5139/IJASS.2014.15.4.419>
2021-02-26 16:01:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.7306/gq.1131> (referer: None)
2021-02-26 16:01:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 16:01:10 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 16:01:21 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-319-04364-7%5C_131>
2021-02-26 16:01:28 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.5209/rev%5C_JIGE.2015.v41.n3.51568>
2021-02-26 16:01:38 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-319-24987-2%5C_26>
2021-02-26 16:01:43 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html> from <GET https://www.sci-hub.ren/10.3391/ai.2016.11.3.04>
2021-02-26 16:01:47 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf> from <GET http://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf>
2021-02-26 16:02:00 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> from <GET http://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm>
2021-02-26 16:02:01 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 16:02:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/ame016131> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 16:02:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v349/p23-32/> (referer: None)
2021-02-26 16:02:14 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 16:02:14 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 144
2021-02-26 16:02:19 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://paleoitalia.org> from <GET https://www.sci-hub.ren/10.4435/BSPI.2016.09>
2021-02-26 16:02:21 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> from <GET https://www.sci-hub.ren/10.3354/ame021161>
2021-02-26 16:02:23 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> from <GET http://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770>
2021-02-26 16:02:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page> from <GET http://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page>
2021-02-26 16:02:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://geojournals.pgi.gov.pl/asgp/article/view/25493> from <GET https://www.sci-hub.ren/10.14241/asgp.2016.011>
2021-02-26 16:02:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 16:03:01 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 16:03:02 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/> from <GET http://www.sci-hub.ren/>
2021-02-26 16:03:03 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/> from <GET http://www.sci-hub.ren/>
2021-02-26 16:03:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-26 16:03:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 16:03:12 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-26 16:03:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html> (failed 1 times): 403 Forbidden
2021-02-26 16:03:23 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://bjg.siteoficial.ws/2013/n.3/d.pdf> from <GET https://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf>
2021-02-26 16:03:27 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> from <GET https://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm>
2021-02-26 16:03:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.1055/s-0036-1596638> (referer: None)
2021-02-26 16:03:38 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 16:03:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-26 16:03:52 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://paleoitalia.org/> from <GET https://www.sci-hub.ren/http://paleoitalia.org>
2021-02-26 16:03:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/ame016131> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 16:03:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> from <GET https://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770>
2021-02-26 16:04:01 [scrapy.extensions.logstats] INFO: Crawled 6 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 16:04:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://koreascience.or.kr/article/JAKO201404065095388.page> from <GET https://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page>
2021-02-26 16:04:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 16:04:12 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://geojournals.pgi.gov.pl/asgp/article/view/25493> from <GET https://www.sci-hub.ren/https://geojournals.pgi.gov.pl/asgp/article/view/25493>
2021-02-26 16:04:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-26 16:04:23 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 16:04:23 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 16:04:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1007/978-3-319-24987-2%5C_6> (failed 1 times): User timeout caused connection failure: Getting https://www.sci-hub.ren/10.1007/978-3-319-24987-2%5C_6 took longer than 180.0 seconds..
2021-02-26 16:04:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-26 16:04:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 16:04:33 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-26 16:04:37 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/> from <GET https://www.sci-hub.ren/10.3354/meps12300>
2021-02-26 16:04:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html> (failed 2 times): 403 Forbidden
2021-02-26 16:04:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 1 times): 404 Not Found
2021-02-26 16:04:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://bjg.siteoficial.ws/2013/n.3/d.pdf> (referer: None)
2021-02-26 16:04:55 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 16:04:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 16:04:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://bjg.siteoficial.ws/2013/n.3/d.pdf> (referer: None)
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/python.py", line 353, in __next__
    return next(self.data)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/python.py", line 353, in __next__
    return next(self.data)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/wos_crawl/wos_crawl/spiders/wos_spider.py", line 39, in parse
    detail_url_list = response.xpath('//*[@id="buttons"]/ul/li[2]/a/@onclick')
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/http/response/__init__.py", line 120, in xpath
    raise NotSupported("Response content isn't text")
scrapy.exceptions.NotSupported: Response content isn't text
2021-02-26 16:04:58 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359> from <GET https://www.sci-hub.ren/10.3389/fmicb.2013.01359>
2021-02-26 16:05:01 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 16:05:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://paleoitalia.org/> (failed 1 times): 403 Forbidden
2021-02-26 16:05:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> (referer: None)
2021-02-26 16:05:20 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 16:05:20 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-26 16:05:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://koreascience.or.kr/article/JAKO201404065095388.page> (referer: None)
2021-02-26 16:05:25 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 16:05:25 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-26 16:05:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/ame048123> (failed 2 times): User timeout caused connection failure: Getting https://www.sci-hub.ren/10.3354/ame048123 took longer than 180.0 seconds..
2021-02-26 16:05:32 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/10.3354/ame016131> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 16:05:32 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 16:05:32 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 16:05:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/10.3354/ame016131>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-26 16:05:35 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> from <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/>
2021-02-26 16:05:41 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://paleopolis.rediris.es/cg/18/08/index.html> from <GET https://www.sci-hub.ren/10.4267/2042/68182>
2021-02-26 16:05:47 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-319-24987-2%5C_6>
2021-02-26 16:05:51 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/> from <GET https://www.sci-hub.ren/10.3354/meps12741>
2021-02-26 16:06:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/> (referer: None)
2021-02-26 16:06:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 16:06:00 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 144
2021-02-26 16:06:01 [scrapy.extensions.logstats] INFO: Crawled 12 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 16:06:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html> (failed 3 times): 403 Forbidden
2021-02-26 16:06:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 2 times): 404 Not Found
2021-02-26 16:06:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://geojournals.pgi.gov.pl/asgp/article/view/25493> (referer: None)
2021-02-26 16:06:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 16:06:12 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 144
2021-02-26 16:06:21 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> from <GET https://www.sci-hub.ren/10.4072/rbp.2018.3.01>
2021-02-26 16:06:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://paleoitalia.org/> (failed 2 times): 403 Forbidden
2021-02-26 16:06:36 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html> from <GET https://www.sci-hub.ren/10.1051/bsgf/2018019>
2021-02-26 16:06:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.5027/andgeoV46n1-3029> (referer: None)
2021-02-26 16:06:41 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 16:06:41 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 16:07:01 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 16:07:02 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://www.int-res.com/abstracts/ame/v82/n3/p253-264/> from <GET https://www.sci-hub.ren/10.3354/ame01895>
2021-02-26 16:07:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/ame048123> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 16:07:09 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://paleopolis.rediris.es/cg/18/08/index.html> from <GET https://www.sci-hub.ren/http://paleopolis.rediris.es/cg/18/08/index.html>
2021-02-26 16:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-26 16:07:14 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 16:07:14 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-26 16:07:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf> (failed 2 times): User timeout caused connection failure: Getting https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf took longer than 180.0 seconds..
2021-02-26 16:07:18 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/> from <GET http://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/>
2021-02-26 16:07:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 16:07:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html> (failed 4 times): 403 Forbidden
2021-02-26 16:07:28 [scrapy.core.engine] DEBUG: Crawled (403) <GET http://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html> (referer: None)
2021-02-26 16:07:28 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 16:07:28 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 144
2021-02-26 16:07:28 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 http://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html>: HTTP status code is not handled or not allowed
2021-02-26 16:07:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 3 times): 404 Not Found
2021-02-26 16:07:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.5027/andgeoV47n1-3177> (referer: None)
2021-02-26 16:07:43 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 16:07:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 16:07:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3390/min9100000> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 16:07:54 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> from <GET https://www.sci-hub.ren/https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf>
2021-02-26 16:07:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://paleoitalia.org/> (failed 3 times): 403 Forbidden
2021-02-26 16:08:01 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 16:08:02 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html> from <GET http://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html>
2021-02-26 16:08:09 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-030-21614-6%5C_12>
2021-02-26 16:08:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.1089/ast.2019.2067> (referer: None)
2021-02-26 16:08:32 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 16:08:32 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 16:08:32 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded file from <GET https://cyber.bban.top/MTAuMTA4OS9hc3QuMjAxOS4yMDY3/10.1089%40ast.2019.2067.pdf?download=true> referred in <None>
2021-02-26 16:08:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.sci-hub.ren/10.1089/ast.2019.2067>
{'file_urls': ['https://cyber.bban.top/MTAuMTA4OS9hc3QuMjAxOS4yMDY3/10.1089%40ast.2019.2067.pdf?download=true'],
 'files': [{'checksum': '808358d065f4915b2156f3de1d6a1a24',
            'path': '000582254100001.pdf',
            'status': 'uptodate',
            'url': 'https://cyber.bban.top/MTAuMTA4OS9hc3QuMjAxOS4yMDY3/10.1089%40ast.2019.2067.pdf?download=true'}],
 'name': '000582254100001'}
2021-02-26 16:08:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://paleopolis.rediris.es/cg/18/08/index.html> (referer: None)
2021-02-26 16:08:34 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 16:08:34 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 16:08:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://www.int-res.com/abstracts/ame/v82/n3/p253-264/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 16:08:41 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/10.3354/ame048123> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 16:08:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/10.3354/ame048123>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-26 16:08:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/> (referer: None)
2021-02-26 16:08:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.publicacions.ub.edu/doi/documents/2051.pdf> from <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf>
2021-02-26 16:08:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> (referer: None)
2021-02-26 16:08:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.1155/2020/6959532> (referer: None)
2021-02-26 16:08:55 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded file from <GET https://cyber.bban.top/MTAuMTE1NS8yMDIwLzY5NTk1MzI=/10.1155%402020%406959532.pdf?download=true> referred in <None>
2021-02-26 16:08:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.sci-hub.ren/10.1155/2020/6959532>
{'file_urls': ['https://cyber.bban.top/MTAuMTE1NS8yMDIwLzY5NTk1MzI=/10.1155%402020%406959532.pdf?download=true'],
 'files': [{'checksum': '6c02fcee70c30afc9791e2e93ddc95f4',
            'path': '000588326000002.pdf',
            'status': 'uptodate',
            'url': 'https://cyber.bban.top/MTAuMTE1NS8yMDIwLzY5NTk1MzI=/10.1155%402020%406959532.pdf?download=true'}],
 'name': '000588326000002'}
2021-02-26 16:08:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 4 times): 404 Not Found
2021-02-26 16:08:58 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (referer: None)
2021-02-26 16:08:58 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.scichina.com/2004/yk/yd/0404/yd0347.stm>: HTTP status code is not handled or not allowed
2021-02-26 16:09:01 [scrapy.extensions.logstats] INFO: Crawled 23 pages (at 6 pages/min), scraped 2 items (at 2 items/min)
2021-02-26 16:09:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> from <GET https://www.sci-hub.ren/10.1111/1758-2229.12916>
2021-02-26 16:09:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359> (failed 1 times): User timeout caused connection failure: Getting https://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359 took longer than 180.0 seconds..
2021-02-26 16:09:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html> (referer: None)
2021-02-26 16:09:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-26 16:09:44 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://paleoitalia.org/> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 16:09:44 [scrapy.core.scraper] ERROR: Error downloading <GET http://paleoitalia.org/>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-26 16:09:45 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://doi.org/10.3390/min9100000> from <GET https://www.sci-hub.ren/10.3390/min9100000>
2021-02-26 16:09:46 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486> from <GET https://www.sci-hub.ren/10.7306/gq.1547>
2021-02-26 16:09:54 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429> from <GET https://www.sci-hub.ren/10.1111/gbi.12429>
2021-02-26 16:10:01 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 2 pages/min), scraped 2 items (at 0 items/min)
2021-02-26 16:10:09 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/ame/v82/n3/p253-264/> from <GET http://www.sci-hub.ren/https://www.int-res.com/abstracts/ame/v82/n3/p253-264/>
2021-02-26 16:10:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> (referer: None)
2021-02-26 16:10:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359> (referer: None)
2021-02-26 16:10:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://doi.org/10.3390/min9100000> (referer: None)
2021-02-26 16:10:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486> (failed 1 times): 403 Forbidden
2021-02-26 16:10:41 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429> from <GET http://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429>
2021-02-26 16:10:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/ame/v82/n3/p253-264/> (referer: None)
2021-02-26 16:10:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486> (failed 2 times): 403 Forbidden
2021-02-26 16:11:00 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429?cookieSet=1> from <GET https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429>
2021-02-26 16:11:01 [scrapy.extensions.logstats] INFO: Crawled 29 pages (at 4 pages/min), scraped 2 items (at 0 items/min)
2021-02-26 16:11:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486> (failed 3 times): 403 Forbidden
2021-02-26 16:11:11 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429?cookieSet=1> from <GET http://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429?cookieSet=1>
2021-02-26 16:11:16 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486> (failed 4 times): 403 Forbidden
2021-02-26 16:11:16 [scrapy.core.engine] DEBUG: Crawled (403) <GET http://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486> (referer: None)
2021-02-26 16:11:17 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 http://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486>: HTTP status code is not handled or not allowed
2021-02-26 16:11:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.publicacions.ub.edu/doi/documents/2051.pdf> (referer: None)
2021-02-26 16:11:20 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.publicacions.ub.edu/doi/documents/2051.pdf> (referer: None)
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/python.py", line 353, in __next__
    return next(self.data)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/python.py", line 353, in __next__
    return next(self.data)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/wos_crawl/wos_crawl/spiders/wos_spider.py", line 39, in parse
    detail_url_list = response.xpath('//*[@id="buttons"]/ul/li[2]/a/@onclick')
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/http/response/__init__.py", line 120, in xpath
    raise NotSupported("Response content isn't text")
scrapy.exceptions.NotSupported: Response content isn't text
2021-02-26 16:11:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> (referer: None)
2021-02-26 16:11:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429?cookieSet=1> (referer: None)
2021-02-26 16:11:27 [scrapy.core.engine] INFO: Closing spider (finished)
2021-02-26 16:11:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 18,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 14,
 'downloader/exception_type_count/twisted.internet.error.TimeoutError': 4,
 'downloader/request_bytes': 46514,
 'downloader/request_count': 111,
 'downloader/request_method_count/GET': 111,
 'downloader/response_bytes': 22452603,
 'downloader/response_count': 93,
 'downloader/response_status_count/200': 30,
 'downloader/response_status_count/301': 12,
 'downloader/response_status_count/302': 36,
 'downloader/response_status_count/403': 11,
 'downloader/response_status_count/404': 4,
 'elapsed_time_seconds': 685.746534,
 'file_count': 2,
 'file_status_count/uptodate': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 2, 26, 8, 11, 27, 436630),
 'httperror/response_ignored_count': 3,
 'httperror/response_ignored_status_count/403': 2,
 'httperror/response_ignored_status_count/404': 1,
 'item_scraped_count': 2,
 'log_count/DEBUG': 184,
 'log_count/ERROR': 11,
 'log_count/INFO': 22,
 'log_count/WARNING': 1,
 'memusage/max': 92536832,
 'memusage/startup': 68063232,
 'response_received_count': 33,
 'retry/count': 27,
 'retry/max_reached': 6,
 'retry/reason_count/403 Forbidden': 9,
 'retry/reason_count/404 Not Found': 3,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 11,
 'retry/reason_count/twisted.internet.error.TimeoutError': 4,
 'scheduler/dequeued': 111,
 'scheduler/dequeued/memory': 111,
 'scheduler/enqueued': 111,
 'scheduler/enqueued/memory': 111,
 'spider_exceptions/NotSupported': 2,
 'start_time': datetime.datetime(2021, 2, 26, 8, 0, 1, 690096)}
2021-02-26 16:11:27 [scrapy.core.engine] INFO: Spider closed (finished)
2021-02-26 20:00:01 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: wos_crawl)
2021-02-26 20:00:01 [scrapy.utils.log] INFO: Versions: lxml 4.6.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.6.9 (default, Oct  8 2020, 12:12:24) - [GCC 8.4.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1i  8 Dec 2020), cryptography 3.3.1, Platform Linux-4.15.0-132-generic-x86_64-with-Ubuntu-18.04-bionic
2021-02-26 20:00:01 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2021-02-26 20:00:01 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wos_crawl',
 'COOKIES_ENABLED': False,
 'DOWNLOAD_DELAY': 5,
 'LOG_FILE': 'crawler.log',
 'NEWSPIDER_MODULE': 'wos_crawl.spiders',
 'RETRY_HTTP_CODES': [500, 503, 504, 400, 403, 404, 408],
 'RETRY_TIMES': 3,
 'SPIDER_MODULES': ['wos_crawl.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/88.0.4324.104 Safari/537.36'}
2021-02-26 20:00:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2021-02-26 20:00:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-02-26 20:00:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-02-26 20:00:02 [py.warnings] WARNING: /home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/pipelines/media.py:135: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2021-02-26 20:00:02 [scrapy.middleware] INFO: Enabled item pipelines:
['wos_crawl.pipelines.fileDown']
2021-02-26 20:00:02 [scrapy.core.engine] INFO: Spider opened
2021-02-26 20:00:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 20:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 20:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 20:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 20:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 20:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 20:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 20:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 20:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 20:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 20:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 20:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 20:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 20:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 20:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 20:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 20:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-26 20:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 20:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-26 20:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 20:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 20:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 20:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 20:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 20:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-26 20:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 20:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 20:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 20:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 20:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 20:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 20:00:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 20:00:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 144
2021-02-26 20:00:02 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v16/n2/p131-141/> from <GET https://www.sci-hub.ren/10.3354/ame016131>
2021-02-26 20:00:08 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> from <GET https://www.sci-hub.ren/10.3354/ame021161>
2021-02-26 20:00:14 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595> from <GET https://www.sci-hub.ren/10.2113/96.7.1595>
2021-02-26 20:00:20 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf> from <GET https://www.sci-hub.ren/10.5327/Z2317-48892013000300004>
2021-02-26 20:00:25 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> from <GET https://www.sci-hub.ren/10.1360/02yd0178>
2021-02-26 20:00:34 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/> from <GET https://www.sci-hub.ren/10.3354/ame048123>
2021-02-26 20:00:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/meps07087> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 20:00:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.2485/jhtb.20.339> (referer: None)
2021-02-26 20:00:45 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 20:00:45 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-26 20:00:55 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> from <GET https://www.sci-hub.ren/10.1344/105.000001770>
2021-02-26 20:00:59 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf> from <GET https://www.sci-hub.ren/10.1344/105.000002051>
2021-02-26 20:01:02 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 20:01:09 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page> from <GET https://www.sci-hub.ren/10.5139/IJASS.2014.15.4.419>
2021-02-26 20:01:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.7306/gq.1131> (referer: None)
2021-02-26 20:01:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 20:01:15 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-26 20:01:20 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-319-04364-7%5C_131>
2021-02-26 20:01:30 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.5209/rev%5C_JIGE.2015.v41.n3.51568>
2021-02-26 20:01:30 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-319-24987-2%5C_6>
2021-02-26 20:01:38 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-319-24987-2%5C_26>
2021-02-26 20:01:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v16/n2/p131-141/> (referer: None)
2021-02-26 20:01:43 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 20:01:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-26 20:01:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> (failed 1 times): 403 Forbidden
2021-02-26 20:01:58 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595> from <GET http://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595>
2021-02-26 20:02:02 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 20:02:06 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://bjg.siteoficial.ws/2013/n.3/d.pdf> from <GET https://www.sci-hub.ren/http://bjg.siteoficial.ws/2013/n.3/d.pdf>
2021-02-26 20:02:09 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> from <GET https://www.sci-hub.ren/https://www.scichina.com/2004/yk/yd/0404/yd0347.stm>
2021-02-26 20:02:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.3354/meps07087> (referer: None)
2021-02-26 20:02:21 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 20:02:21 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-26 20:02:30 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html> from <GET https://www.sci-hub.ren/10.3391/ai.2016.11.3.04>
2021-02-26 20:02:34 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> from <GET http://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770>
2021-02-26 20:02:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf> from <GET http://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf>
2021-02-26 20:02:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v48/n2/p123-130/> (referer: None)
2021-02-26 20:02:42 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 20:02:42 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-26 20:02:52 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://koreascience.or.kr/article/JAKO201404065095388.page> from <GET https://www.sci-hub.ren/http://koreascience.or.kr/article/JAKO201404065095388.page>
2021-02-26 20:02:54 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/http://paleoitalia.org> from <GET https://www.sci-hub.ren/10.4435/BSPI.2016.09>
2021-02-26 20:03:01 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/> from <GET http://www.sci-hub.ren/>
2021-02-26 20:03:02 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 20:03:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 20:03:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-26 20:03:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 20:03:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 20:03:21 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/> from <GET http://www.sci-hub.ren/>
2021-02-26 20:03:25 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://geojournals.pgi.gov.pl/asgp/article/view/25493> from <GET https://www.sci-hub.ren/10.14241/asgp.2016.011>
2021-02-26 20:03:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> (failed 2 times): 403 Forbidden
2021-02-26 20:03:37 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://economicgeology.org/lookup/doi/10.2113/96.7.1595> from <GET https://www.sci-hub.ren/http://economicgeology.org/lookup/doi/10.2113/96.7.1595>
2021-02-26 20:03:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 1 times): 404 Not Found
2021-02-26 20:03:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.1055/s-0036-1596638> (referer: None)
2021-02-26 20:03:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 20:03:58 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-26 20:03:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://bjg.siteoficial.ws/2013/n.3/d.pdf> (referer: None)
2021-02-26 20:03:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 20:03:58 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 20:03:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://bjg.siteoficial.ws/2013/n.3/d.pdf> (referer: None)
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/python.py", line 353, in __next__
    return next(self.data)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/python.py", line 353, in __next__
    return next(self.data)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/wos_crawl/wos_crawl/spiders/wos_spider.py", line 39, in parse
    detail_url_list = response.xpath('//*[@id="buttons"]/ul/li[2]/a/@onclick')
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/http/response/__init__.py", line 120, in xpath
    raise NotSupported("Response content isn't text")
scrapy.exceptions.NotSupported: Response content isn't text
2021-02-26 20:04:02 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 20:04:02 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html> from <GET http://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html>
2021-02-26 20:04:09 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> from <GET https://www.sci-hub.ren/https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770>
2021-02-26 20:04:17 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.publicacions.ub.edu/doi/documents/2051.pdf> from <GET https://www.sci-hub.ren/http://www.publicacions.ub.edu/doi/documents/2051.pdf>
2021-02-26 20:04:25 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/> from <GET https://www.sci-hub.ren/10.3354/meps12300>
2021-02-26 20:04:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://koreascience.or.kr/article/JAKO201404065095388.page> (failed 1 times): 403 Forbidden
2021-02-26 20:04:36 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://paleoitalia.org/> from <GET https://www.sci-hub.ren/http://paleoitalia.org>
2021-02-26 20:04:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-26 20:04:41 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 20:04:41 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 20:04:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 20:04:53 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359> from <GET https://www.sci-hub.ren/10.3389/fmicb.2013.01359>
2021-02-26 20:04:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-26 20:04:59 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 20:04:59 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 146
2021-02-26 20:05:02 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 20:05:07 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://geojournals.pgi.gov.pl/asgp/article/view/25493> from <GET https://www.sci-hub.ren/https://geojournals.pgi.gov.pl/asgp/article/view/25493>
2021-02-26 20:05:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> (failed 3 times): 403 Forbidden
2021-02-26 20:05:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://economicgeology.org/lookup/doi/10.2113/96.7.1595> (failed 1 times): 404 Not Found
2021-02-26 20:05:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 2 times): 404 Not Found
2021-02-26 20:05:37 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/http://paleopolis.rediris.es/cg/18/08/index.html> from <GET https://www.sci-hub.ren/10.4267/2042/68182>
2021-02-26 20:05:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.aquaticinvasions.net/2016/issue3.html> from <GET https://www.sci-hub.ren/http://www.aquaticinvasions.net/2016/issue3.html>
2021-02-26 20:05:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://revistes.ub.edu/index.php/GEOACTA/article/view/105.000001770> (referer: None)
2021-02-26 20:05:55 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 20:05:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 20:05:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/meps12741> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 20:06:02 [scrapy.extensions.logstats] INFO: Crawled 11 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 20:06:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/> from <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/>
2021-02-26 20:06:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.publicacions.ub.edu/doi/documents/2051.pdf> (referer: None)
2021-02-26 20:06:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 20:06:12 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 20:06:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.publicacions.ub.edu/doi/documents/2051.pdf> (referer: None)
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/python.py", line 353, in __next__
    return next(self.data)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/utils/python.py", line 353, in __next__
    return next(self.data)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/zxb/workspace/paper_down_server/wos_crawl/wos_crawl/spiders/wos_spider.py", line 39, in parse
    detail_url_list = response.xpath('//*[@id="buttons"]/ul/li[2]/a/@onclick')
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/http/response/__init__.py", line 120, in xpath
    raise NotSupported("Response content isn't text")
scrapy.exceptions.NotSupported: Response content isn't text
2021-02-26 20:06:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://paleoitalia.org/> (failed 1 times): 403 Forbidden
2021-02-26 20:06:22 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> from <GET https://www.sci-hub.ren/10.4072/rbp.2018.3.01>
2021-02-26 20:06:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://koreascience.or.kr/article/JAKO201404065095388.page> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 20:06:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/> from <GET http://www.sci-hub.ren/>
2021-02-26 20:06:35 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359> from <GET http://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359>
2021-02-26 20:06:42 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html> from <GET https://www.sci-hub.ren/10.1051/bsgf/2018019>
2021-02-26 20:06:52 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> (failed 4 times): 403 Forbidden
2021-02-26 20:06:52 [scrapy.core.engine] DEBUG: Crawled (403) <GET http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/> (referer: None)
2021-02-26 20:06:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 20:06:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-26 20:06:52 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 http://www.sci-hub.ren/http://www.int-res.com/abstracts/ame/v21/n2/p161-168/>: HTTP status code is not handled or not allowed
2021-02-26 20:06:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://geojournals.pgi.gov.pl/asgp/article/view/25493> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-02-26 20:06:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://economicgeology.org/lookup/doi/10.2113/96.7.1595> (failed 2 times): 404 Not Found
2021-02-26 20:07:02 [scrapy.extensions.logstats] INFO: Crawled 13 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 20:07:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 3 times): 404 Not Found
2021-02-26 20:07:11 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/http://paleopolis.rediris.es/cg/18/08/index.html> from <GET http://www.sci-hub.ren/http://paleopolis.rediris.es/cg/18/08/index.html>
2021-02-26 20:07:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.aquaticinvasions.net/2016/issue3.html> (referer: None)
2021-02-26 20:07:21 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 20:07:21 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 20:07:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/> from <GET https://www.sci-hub.ren/10.3354/meps12741>
2021-02-26 20:07:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/http://www.int-res.com/abstracts/meps/v580/p153-167/> (referer: None)
2021-02-26 20:07:37 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 20:07:37 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 20:07:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://paleoitalia.org/> (failed 2 times): 403 Forbidden
2021-02-26 20:07:58 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> from <GET https://www.sci-hub.ren/https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf>
2021-02-26 20:08:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/ame01895> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 20:08:02 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 20:08:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://koreascience.or.kr/article/JAKO201404065095388.page> (failed 3 times): 403 Forbidden
2021-02-26 20:08:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-26 20:08:11 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 20:08:11 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 20:08:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://doi.org/10.3389/fmicb.2013.01359> (referer: None)
2021-02-26 20:08:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 20:08:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 145
2021-02-26 20:08:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-02-26 20:08:30 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.sci-hub.ren/https://doi.org/10.3390/min9100000> from <GET https://www.sci-hub.ren/10.3390/min9100000>
2021-02-26 20:08:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://geojournals.pgi.gov.pl/asgp/article/view/25493> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-02-26 20:08:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://economicgeology.org/lookup/doi/10.2113/96.7.1595> (failed 3 times): 404 Not Found
2021-02-26 20:08:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (failed 4 times): 404 Not Found
2021-02-26 20:08:45 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.scichina.com/2004/yk/yd/0404/yd0347.stm> (referer: None)
2021-02-26 20:08:45 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 20:08:45 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 20:08:45 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.scichina.com/2004/yk/yd/0404/yd0347.stm>: HTTP status code is not handled or not allowed
2021-02-26 20:08:56 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://paleopolis.rediris.es/cg/18/08/index.html> from <GET https://www.sci-hub.ren/http://paleopolis.rediris.es/cg/18/08/index.html>
2021-02-26 20:09:02 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2021-02-26 20:09:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/> from <GET http://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/>
2021-02-26 20:09:10 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/> from <GET https://www.sci-hub.ren/10.1007/978-3-030-21614-6%5C_12>
2021-02-26 20:09:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://paleoitalia.org/> (failed 3 times): 403 Forbidden
2021-02-26 20:09:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.5027/andgeoV47n1-3177> (referer: None)
2021-02-26 20:09:18 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 20:09:18 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 147
2021-02-26 20:09:37 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://koreascience.or.kr/article/JAKO201404065095388.page> (failed 4 times): 403 Forbidden
2021-02-26 20:09:37 [scrapy.core.engine] DEBUG: Crawled (403) <GET http://koreascience.or.kr/article/JAKO201404065095388.page> (referer: None)
2021-02-26 20:09:37 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5010
2021-02-26 20:09:37 [urllib3.connectionpool] DEBUG: http://127.0.0.1:5010 "GET /get/ HTTP/1.1" 200 148
2021-02-26 20:09:37 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 http://koreascience.or.kr/article/JAKO201404065095388.page>: HTTP status code is not handled or not allowed
2021-02-26 20:09:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.1089/ast.2019.2067> (referer: None)
2021-02-26 20:09:44 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded file from <GET https://cyber.bban.top/MTAuMTA4OS9hc3QuMjAxOS4yMDY3/10.1089%40ast.2019.2067.pdf?download=true> referred in <None>
2021-02-26 20:09:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.sci-hub.ren/10.1089/ast.2019.2067>
{'file_urls': ['https://cyber.bban.top/MTAuMTA4OS9hc3QuMjAxOS4yMDY3/10.1089%40ast.2019.2067.pdf?download=true'],
 'files': [{'checksum': '808358d065f4915b2156f3de1d6a1a24',
            'path': '000582254100001.pdf',
            'status': 'uptodate',
            'url': 'https://cyber.bban.top/MTAuMTA4OS9hc3QuMjAxOS4yMDY3/10.1089%40ast.2019.2067.pdf?download=true'}],
 'name': '000582254100001'}
2021-02-26 20:09:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/ame01895> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 20:09:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.1155/2020/6959532> (referer: None)
2021-02-26 20:09:50 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded file from <GET https://cyber.bban.top/MTAuMTE1NS8yMDIwLzY5NTk1MzI=/10.1155%402020%406959532.pdf?download=true> referred in <None>
2021-02-26 20:09:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.sci-hub.ren/10.1155/2020/6959532>
{'file_urls': ['https://cyber.bban.top/MTAuMTE1NS8yMDIwLzY5NTk1MzI=/10.1155%402020%406959532.pdf?download=true'],
 'files': [{'checksum': '6c02fcee70c30afc9791e2e93ddc95f4',
            'path': '000588326000002.pdf',
            'status': 'uptodate',
            'url': 'https://cyber.bban.top/MTAuMTE1NS8yMDIwLzY5NTk1MzI=/10.1155%402020%406959532.pdf?download=true'}],
 'name': '000588326000002'}
2021-02-26 20:09:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-02-26 20:10:00 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.sci-hub.ren/https://doi.org/10.3390/min9100000> from <GET http://www.sci-hub.ren/https://doi.org/10.3390/min9100000>
2021-02-26 20:10:02 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 4 pages/min), scraped 2 items (at 2 items/min)
2021-02-26 20:10:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://geojournals.pgi.gov.pl/asgp/article/view/25493> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-02-26 20:10:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://economicgeology.org/lookup/doi/10.2113/96.7.1595> (failed 4 times): 404 Not Found
2021-02-26 20:10:09 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://economicgeology.org/lookup/doi/10.2113/96.7.1595> (referer: None)
2021-02-26 20:10:09 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://economicgeology.org/lookup/doi/10.2113/96.7.1595>: HTTP status code is not handled or not allowed
2021-02-26 20:10:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.5027/andgeoV46n1-3029> (failed 1 times): User timeout caused connection failure: Getting https://www.sci-hub.ren/10.5027/andgeoV46n1-3029 took longer than 180.0 seconds..
2021-02-26 20:10:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://www.int-res.com/abstracts/meps/v605/p37-47/> (referer: None)
2021-02-26 20:10:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://paleopolis.rediris.es/cg/18/08/index.html> (referer: None)
2021-02-26 20:10:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/> (referer: None)
2021-02-26 20:10:41 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://paleoitalia.org/> (failed 4 times): 403 Forbidden
2021-02-26 20:10:41 [scrapy.core.engine] DEBUG: Crawled (403) <GET http://paleoitalia.org/> (referer: None)
2021-02-26 20:10:41 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 http://paleoitalia.org/>: HTTP status code is not handled or not allowed
2021-02-26 20:11:02 [scrapy.extensions.logstats] INFO: Crawled 27 pages (at 5 pages/min), scraped 2 items (at 0 items/min)
2021-02-26 20:11:03 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486> from <GET https://www.sci-hub.ren/10.7306/gq.1547>
2021-02-26 20:11:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-02-26 20:11:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1111/1758-2229.12916> (failed 1 times): Could not open CONNECT tunnel with proxy 114.215.198.156:80 [{'status': 503, 'reason': b'Service Unavailable'}]
2021-02-26 20:11:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1111/gbi.12429> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 20:11:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://doi.org/10.3390/min9100000> (referer: None)
2021-02-26 20:11:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.3354/ame01895> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 20:11:26 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://geojournals.pgi.gov.pl/asgp/article/view/25493> (failed 4 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-02-26 20:11:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://geojournals.pgi.gov.pl/asgp/article/view/25493>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-02-26 20:11:40 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html> (failed 4 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-02-26 20:11:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/https://www.bsgf.fr/articles/bsgf/full_html/2018/04/bsgf180005/bsgf180005.html>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-02-26 20:11:42 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> from <GET https://www.sci-hub.ren/10.1111/1758-2229.12916>
2021-02-26 20:11:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.5027/andgeoV46n1-3029> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 20:12:02 [scrapy.extensions.logstats] INFO: Crawled 28 pages (at 1 pages/min), scraped 2 items (at 0 items/min)
2021-02-26 20:12:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/10.1111/gbi.12429> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 20:12:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/10.5027/andgeoV46n1-3029> (referer: None)
2021-02-26 20:12:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/10.3354/ame01895> (failed 4 times): Connection was refused by other side: 111: Connection refused.
2021-02-26 20:12:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/10.3354/ame01895>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2021-02-26 20:12:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> (failed 1 times): User timeout caused connection failure: Getting https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf took longer than 180.0 seconds..
2021-02-26 20:12:30 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429> from <GET https://www.sci-hub.ren/10.1111/gbi.12429>
2021-02-26 20:12:30 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429?cookieSet=1> from <GET https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429>
2021-02-26 20:12:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486> (failed 1 times): 504 Gateway Time-out
2021-02-26 20:12:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.sci-hub.ren/https://onlinelibrary.wiley.com/doi/10.1111/gbi.12429?cookieSet=1> (referer: None)
2021-02-26 20:13:02 [scrapy.extensions.logstats] INFO: Crawled 30 pages (at 2 pages/min), scraped 2 items (at 0 items/min)
2021-02-26 20:13:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486> (failed 2 times): 504 Gateway Time-out
2021-02-26 20:14:02 [scrapy.extensions.logstats] INFO: Crawled 30 pages (at 0 pages/min), scraped 2 items (at 0 items/min)
2021-02-26 20:14:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486> (failed 3 times): 504 Gateway Time-out
2021-02-26 20:15:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> (failed 2 times): User timeout caused connection failure: Getting https://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916 took longer than 180.0 seconds..
2021-02-26 20:15:02 [scrapy.extensions.logstats] INFO: Crawled 30 pages (at 0 pages/min), scraped 2 items (at 0 items/min)
2021-02-26 20:15:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> (failed 2 times): User timeout caused connection failure: Getting https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf took longer than 180.0 seconds..
2021-02-26 20:15:44 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486> (failed 4 times): 504 Gateway Time-out
2021-02-26 20:15:44 [scrapy.core.engine] DEBUG: Crawled (504) <GET https://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486> (referer: None)
2021-02-26 20:15:44 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <504 https://www.sci-hub.ren/https://gq.pgi.gov.pl/article/view/28486>: HTTP status code is not handled or not allowed
2021-02-26 20:16:02 [scrapy.extensions.logstats] INFO: Crawled 31 pages (at 1 pages/min), scraped 2 items (at 0 items/min)
2021-02-26 20:17:02 [scrapy.extensions.logstats] INFO: Crawled 31 pages (at 0 pages/min), scraped 2 items (at 0 items/min)
2021-02-26 20:18:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> (failed 3 times): User timeout caused connection failure: Getting https://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916 took longer than 180.0 seconds..
2021-02-26 20:18:02 [scrapy.extensions.logstats] INFO: Crawled 31 pages (at 0 pages/min), scraped 2 items (at 0 items/min)
2021-02-26 20:18:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> (failed 3 times): User timeout caused connection failure: Getting https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf took longer than 180.0 seconds..
2021-02-26 20:19:02 [scrapy.extensions.logstats] INFO: Crawled 31 pages (at 0 pages/min), scraped 2 items (at 0 items/min)
2021-02-26 20:20:02 [scrapy.extensions.logstats] INFO: Crawled 31 pages (at 0 pages/min), scraped 2 items (at 0 items/min)
2021-02-26 20:21:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916> (failed 4 times): User timeout caused connection failure: Getting https://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916 took longer than 180.0 seconds..
2021-02-26 20:21:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/twisted/internet/defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/twisted/python/failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py", line 375, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.sci-hub.ren/https://sfamjournals.onlinelibrary.wiley.com/doi/10.1111/1758-2229.12916 took longer than 180.0 seconds..
2021-02-26 20:21:02 [scrapy.extensions.logstats] INFO: Crawled 31 pages (at 0 pages/min), scraped 2 items (at 0 items/min)
2021-02-26 20:21:21 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf> (failed 4 times): User timeout caused connection failure: Getting https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf took longer than 180.0 seconds..
2021-02-26 20:21:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf>
Traceback (most recent call last):
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/twisted/internet/defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/twisted/python/failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/zxb/workspace/paper_down_server/venv/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py", line 375, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.sbpbrasil.org/assets/uploads/files/rbp2018301.pdf took longer than 180.0 seconds..
2021-02-26 20:21:22 [scrapy.core.engine] INFO: Closing spider (finished)
2021-02-26 20:21:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 29,
 'downloader/exception_type_count/scrapy.core.downloader.handlers.http11.TunnelError': 1,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 12,
 'downloader/exception_type_count/twisted.internet.error.TimeoutError': 8,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 8,
 'downloader/request_bytes': 53594,
 'downloader/request_count': 128,
 'downloader/request_method_count/GET': 128,
 'downloader/response_bytes': 4707017,
 'downloader/response_count': 99,
 'downloader/response_status_count/200': 25,
 'downloader/response_status_count/301': 12,
 'downloader/response_status_count/302': 39,
 'downloader/response_status_count/403': 11,
 'downloader/response_status_count/404': 8,
 'downloader/response_status_count/504': 4,
 'elapsed_time_seconds': 1280.085766,
 'file_count': 2,
 'file_status_count/uptodate': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 2, 26, 12, 21, 22, 102937),
 'httperror/response_ignored_count': 6,
 'httperror/response_ignored_status_count/403': 3,
 'httperror/response_ignored_status_count/404': 2,
 'httperror/response_ignored_status_count/504': 1,
 'item_scraped_count': 2,
 'log_count/DEBUG': 199,
 'log_count/ERROR': 18,
 'log_count/INFO': 35,
 'log_count/WARNING': 1,
 'memusage/max': 92254208,
 'memusage/startup': 68104192,
 'response_received_count': 31,
 'retry/count': 41,
 'retry/max_reached': 11,
 'retry/reason_count/403 Forbidden': 8,
 'retry/reason_count/404 Not Found': 6,
 'retry/reason_count/504 Gateway Time-out': 3,
 'retry/reason_count/scrapy.core.downloader.handlers.http11.TunnelError': 1,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 11,
 'retry/reason_count/twisted.internet.error.TimeoutError': 6,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 6,
 'scheduler/dequeued': 128,
 'scheduler/dequeued/memory': 128,
 'scheduler/enqueued': 128,
 'scheduler/enqueued/memory': 128,
 'spider_exceptions/NotSupported': 2,
 'start_time': datetime.datetime(2021, 2, 26, 12, 0, 2, 17171)}
2021-02-26 20:21:22 [scrapy.core.engine] INFO: Spider closed (finished)
